{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "root = Path(os.getcwd()).parent.parent\n",
    "sys.path.append(str(Path(os.getcwd()).parent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loader import Power, Weather\n",
    "from constant import FeatureType\n",
    "from keras.layers import LSTM, RepeatVector, TimeDistributed, Dense\n",
    "from tensorflow.python.keras.optimizer_v2.rmsprop import RMSProp\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import json\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "args = parser.parse_args(\"\")\n",
    "\n",
    "# ====== Path ====== #\n",
    "args.root = root\n",
    "\n",
    "# ====== Model ====== #\n",
    "args.frame_in = 72\n",
    "args.frame_out = 24\n",
    "args.batch_size = 64\n",
    "args.learning_rate = 0.001\n",
    "args.patience = 30\n",
    "args.shuffle = True\n",
    "\n",
    "# ====== Data ====== #\n",
    "args.years = [2017, 2018, 2019]\n",
    "args.region = \"Jindo\"\n",
    "args.station = 192\n",
    "args.ratio = [0.6, 0.2, 0.2]\n",
    "\n",
    "# ====== Features ====== #\n",
    "features = [FeatureType.SUNSHINE,\n",
    "            FeatureType.GROUND_TEMPERATURE,\n",
    "            FeatureType.HUMIDITY,\n",
    "            FeatureType.WIND_SPEED,\n",
    "            FeatureType.WIND_DIRECTION,\n",
    "            FeatureType.TEMPERATURE,\n",
    "            FeatureType.VISIBILITY,\n",
    "            FeatureType.PRECIPITATION,\n",
    "            FeatureType.STEAM_PRESSURE,\n",
    "            FeatureType.DEW_POINT_TEMPERATURE,\n",
    "            FeatureType.ATMOSPHERIC_PRESSURE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_decoder(args, dataset, budget):\n",
    "    print(\"train\")\n",
    "\n",
    "    X_train, y_train = dataset['train']\n",
    "    X_val, y_val = dataset['val']\n",
    "    X_test, y_test = dataset['test']\n",
    "\n",
    "    with tf.device('/GPU:0'):\n",
    "        model = Sequential()\n",
    "        optimizer = RMSProp(learning_rate=args.learning_rate)\n",
    "\n",
    "        model.add(LSTM(256, input_shape=(args.frame_in, args.feature_len)))\n",
    "        model.add(RepeatVector(args.frame_out))\n",
    "        model.add(LSTM(256, return_sequences=True))\n",
    "        model.add(TimeDistributed(Dense(256, activation='relu')))\n",
    "        model.add(TimeDistributed(Dense(1)))\n",
    "        model.compile(loss='mse', optimizer=optimizer)\n",
    "\n",
    "        print(\"model name: %s\" % args.name)\n",
    "        \n",
    "        model_root_path = os.path.join(root, 'models', args.name)\n",
    "        Path(model_root_path).mkdir(parents=True, exist_ok=True)\n",
    "        checkpoint_path = os.path.join(model_root_path, 'model-{epoch:03d}-{val_loss:03f}.h5')\n",
    "        model_path = os.path.join(model_root_path, 'model.h5')\n",
    "        \n",
    "        callback = EarlyStopping(monitor='val_loss', patience=args.patience)\n",
    "        checkpoint = ModelCheckpoint(checkpoint_path, verbose=1, monitor='val_loss', save_best_only=True)\n",
    "\n",
    "        history = model.fit(X_train, y_train, batch_size=args.batch_size, epochs=budget,\n",
    "                            validation_data=(X_val, y_val), callbacks=[callback, checkpoint], shuffle=args.shuffle)\n",
    "        model.save(model_path)\n",
    "        \n",
    "        return model\n",
    "    \n",
    "def predict(partition, model, scaler):\n",
    "    X_test, y_test = partition['test']\n",
    "    y_test = y_test.reshape((y_test.shape[0] * y_test.shape[1], y_test.shape[2]))\n",
    "    y_test = scaler.inverse_transform(y_test)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = y_pred.reshape((-1, 1))\n",
    "    y_pred = scaler.inverse_transform(y_pred)\n",
    "    \n",
    "    print(y_test.shape, y_pred.shape)\n",
    "    \n",
    "    zero_indices = np.where(y_test == 0)\n",
    "    y_test_adjusted = np.delete(y_test, zero_indices)\n",
    "    y_pred_adjusted = np.delete(y_pred, zero_indices)\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(y_test_adjusted, y_pred_adjusted))\n",
    "    max_min = np.max(y_test_adjusted) - np.min(y_test_adjusted)\n",
    "    nrmse = rmse / max_min\n",
    "    \n",
    "    print('rmse:', rmse)\n",
    "    print('nrmse:', nrmse)\n",
    "    \n",
    "    return y_test, y_pred, nrmse\n",
    "\n",
    "def save(y_pred_list, y_test, test_start, test_end, name='result.csv'):\n",
    "    df = pd.DataFrame()\n",
    "    for i in range(len(features)):\n",
    "        y_pred_list[i] = y_pred_list[i].reshape((y_pred_list[i].shape[0]))\n",
    "        df['%dth model' % (i + 1)] = y_pred_list[i].tolist()\n",
    "    y_test = y_test.reshape((y_test.shape[0]))\n",
    "    df['y_test'] = y_test.tolist()\n",
    "\n",
    "    full_idx = pd.date_range(start=test_start+timedelta(days=3), end=test_end, freq='H')\n",
    "    full_idx = full_idx[:y_test.shape[0]]\n",
    "    df['time'] = full_idx\n",
    "    df = df.set_index('time')\n",
    "\n",
    "    result_path = os.path.join(root, 'results')\n",
    "    result_name = os.path.join(result_path, name)\n",
    "    df.to_csv(result_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train start date: 2017-01-01 00:00:00\n",
      "train end date: 2018-10-19 23:00:00\n",
      "val start date: 2018-10-20 00:00:00\n",
      "val end date: 2019-05-26 23:00:00\n",
      "test start date: 2019-05-27 00:00:00\n",
      "test end date: 2019-12-31 23:00:00\n",
      "train start date: 2017-01-01 00:00:00\n",
      "train end date: 2018-10-19 23:00:00\n",
      "val start date: 2018-10-20 00:00:00\n",
      "val end date: 2019-05-26 23:00:00\n",
      "test start date: 2019-05-27 00:00:00\n",
      "test end date: 2019-12-31 23:00:00\n",
      "0 missing dates\n",
      "0 value(s) are not zero\n",
      "0 missing dates\n",
      "0 value(s) are not zero\n",
      "0 missing dates\n",
      "0 value(s) are not zero\n",
      "(15768,)\n",
      "(5256,)\n",
      "(5256,)\n",
      "missing dates: []\n",
      "missing dates: ['2018-01-13 09:00', '2018-01-13 10:00', '2018-01-13 11:00', '2018-01-13 12:00', '2018-01-13 13:00']\n",
      "missing dates: []\n",
      "(5184, 1) (5184, 1)\n",
      "rmse: 48.71345076573177\n",
      "nrmse: 0.1586757353932631\n",
      "missing dates: []\n",
      "missing dates: ['2018-01-13 09:00', '2018-01-13 10:00', '2018-01-13 11:00', '2018-01-13 12:00', '2018-01-13 13:00']\n",
      "missing dates: []\n",
      "(5184, 1) (5184, 1)\n",
      "rmse: 55.28152928440092\n",
      "nrmse: 0.18007012796221797\n",
      "missing dates: []\n",
      "missing dates: ['2018-01-13 09:00', '2018-01-13 10:00', '2018-01-13 11:00', '2018-01-13 12:00', '2018-01-13 13:00']\n",
      "missing dates: []\n",
      "(5184, 1) (5184, 1)\n",
      "rmse: 52.931859051833364\n",
      "nrmse: 0.17241647899619988\n",
      "missing dates: []\n",
      "missing dates: ['2018-01-13 09:00', '2018-01-13 10:00', '2018-01-13 11:00', '2018-01-13 12:00', '2018-01-13 13:00']\n",
      "missing dates: []\n",
      "(5184, 1) (5184, 1)\n",
      "rmse: 50.17243848574964\n",
      "nrmse: 0.16342813839006395\n",
      "missing dates: []\n",
      "missing dates: ['2018-01-13 09:00', '2018-01-13 10:00', '2018-01-13 11:00', '2018-01-13 12:00', '2018-01-13 13:00']\n",
      "missing dates: []\n",
      "(5184, 1) (5184, 1)\n",
      "rmse: 58.42490159108833\n",
      "nrmse: 0.1903091257038708\n",
      "missing dates: []\n",
      "missing dates: ['2018-01-13 09:00', '2018-01-13 10:00', '2018-01-13 11:00', '2018-01-13 12:00', '2018-01-13 13:00']\n",
      "missing dates: []\n",
      "(5184, 1) (5184, 1)\n",
      "rmse: 56.778602743115755\n",
      "nrmse: 0.18494658873979072\n",
      "missing dates: []\n",
      "missing dates: ['2018-01-13 09:00', '2018-01-13 10:00', '2018-01-13 11:00', '2018-01-13 12:00', '2018-01-13 13:00']\n",
      "missing dates: []\n",
      "(5184, 1) (5184, 1)\n",
      "rmse: 48.08368848290647\n",
      "nrmse: 0.15662439245246407\n",
      "missing dates: []\n",
      "missing dates: ['2018-01-13 09:00', '2018-01-13 10:00', '2018-01-13 11:00', '2018-01-13 12:00', '2018-01-13 13:00']\n",
      "missing dates: []\n",
      "(5184, 1) (5184, 1)\n",
      "rmse: 49.34437142987258\n",
      "nrmse: 0.16073085156310288\n",
      "missing dates: []\n",
      "missing dates: ['2018-01-13 09:00', '2018-01-13 10:00', '2018-01-13 11:00', '2018-01-13 12:00', '2018-01-13 13:00']\n",
      "missing dates: []\n",
      "(5184, 1) (5184, 1)\n",
      "rmse: 53.042067606855596\n",
      "nrmse: 0.17277546451744494\n",
      "missing dates: []\n",
      "missing dates: ['2018-01-13 09:00', '2018-01-13 10:00', '2018-01-13 11:00', '2018-01-13 12:00', '2018-01-13 13:00']\n",
      "missing dates: []\n",
      "(5184, 1) (5184, 1)\n",
      "rmse: 56.38254776156129\n",
      "nrmse: 0.18365650736664915\n",
      "missing dates: []\n",
      "missing dates: ['2018-01-13 09:00', '2018-01-13 10:00', '2018-01-13 11:00', '2018-01-13 12:00', '2018-01-13 13:00']\n",
      "missing dates: []\n",
      "(5184, 1) (5184, 1)\n",
      "rmse: 53.415187186411856\n",
      "nrmse: 0.17399083774075524\n"
     ]
    }
   ],
   "source": [
    "power = Power(args)\n",
    "weather = Weather(args, features)\n",
    "\n",
    "power_data = power.get_data()\n",
    "scaler = power_data['scaler']\n",
    "\n",
    "y_pred_list = []\n",
    "nrmse_list = []\n",
    "\n",
    "for i in range(len(features)):\n",
    "    weather_data = weather.get_data(i+1)\n",
    "    setattr(args, 'feature_len', i + 1)\n",
    "    setattr(args, 'name', 'normal_hp_model_%d' % (i + 1))\n",
    "\n",
    "    train = [weather_data['train'], power_data['train']]\n",
    "    val = [weather_data['val'], power_data['val']]\n",
    "    test = [weather_data['test'], power_data['test']]\n",
    "\n",
    "    dataset = {'train': train, 'val': val, 'test': test}\n",
    "    \n",
    "#     model = encoder_decoder(args, dataset, budget=256)\n",
    "    model_path = os.path.join(root, 'models', args.name, 'model.h5')\n",
    "    model = load_model(model_path)\n",
    "    y_test, y_pred, nrmse = predict(dataset, model, scaler)\n",
    "    y_pred_list.append(y_pred)\n",
    "    nrmse_list.append(nrmse)\n",
    "    \n",
    "save(y_pred_list, y_test, power.test_start, power.test_end, name='normal_setting.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.1586757353932631,\n",
       " 0.18007012796221797,\n",
       " 0.17241647899619988,\n",
       " 0.16342813839006395,\n",
       " 0.1903091257038708,\n",
       " 0.18494658873979072,\n",
       " 0.15662439245246407,\n",
       " 0.16073085156310288,\n",
       " 0.17277546451744494,\n",
       " 0.18365650736664915,\n",
       " 0.17399083774075524]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nrmse_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
