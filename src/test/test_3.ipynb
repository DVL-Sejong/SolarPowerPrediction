{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path(os.getcwd()).parent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loader import Loader\n",
    "from constant import FeatureType, FileType\n",
    "from copy import deepcopy\n",
    "from skimage.measure import compare_nrmse\n",
    "from keras.models import Model\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.layers import Input, LSTM, Dense, RepeatVector\n",
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import hashlib\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train, Validate, Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_decoder(partition, args):\n",
    "    X_train, y_train = partition['train']\n",
    "    X_val, y_val = partition['val']\n",
    "\n",
    "    batch_size = args.batch_size\n",
    "    epochs = args.epochs\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=args.early_stop)\n",
    "\n",
    "    with tf.device('/GPU:0'):        \n",
    "        encoder_inputs = Input(shape=(args.x_frames * 24, len(args.features)))\n",
    "\n",
    "        encoder = LSTM(args.hid_dim, return_state=True)\n",
    "        encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "        encoder_states = [state_h, state_c]\n",
    "\n",
    "        repeat_vector = RepeatVector(24)\n",
    "        repeat_vector_outputs = repeat_vector(encoder_outputs)\n",
    "\n",
    "        decoder_lstm = LSTM(args.hid_dim, return_sequences=True, return_state=True)\n",
    "        decoder_outputs, _, _ = decoder_lstm(repeat_vector_outputs, initial_state=encoder_states)\n",
    "\n",
    "        decoder_dense = Dense(1, activation=args.activation)\n",
    "        decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "        rmsprop = RMSprop(lr=args.lr)\n",
    "\n",
    "        model = Model(encoder_inputs, decoder_outputs)\n",
    "        model.compile(optimizer=rmsprop, loss=tf.keras.losses.MeanSquaredError(), metrics='accuracy')\n",
    "\n",
    "        history = model.fit(X_train, y_train, validation_data=(X_val, y_val),\n",
    "              batch_size=batch_size, epochs=epochs, callbacks=[callback])\n",
    "        \n",
    "        print(model.summary())\n",
    "\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(partition, model, args):\n",
    "    X_test, y_test = partition['test']\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = y_pred.reshape(y_test.shape[0], y_test.shape[1])\n",
    "\n",
    "    nrmse = compare_nrmse(y_test, y_pred)\n",
    "    return y_pred, nrmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(args):\n",
    "    loader = Loader(args)\n",
    "    partition = loader.get_dataset()\n",
    "    \n",
    "    ts = time.time()\n",
    "    model, history = encoder_decoder(partition, args)\n",
    "    te = time.time()\n",
    "    \n",
    "    print('Took {:2.2f} sec for training the model'.format(te-ts))\n",
    "    \n",
    "    y_pred, test_acc = test(partition, model, args)\n",
    "    \n",
    "    # ======= Add Result to Dictionary ======= #\n",
    "    result = {}\n",
    "    result['train_losses'] = history.history['loss']\n",
    "    result['val_losses'] = history.history['val_loss']\n",
    "    result['train_accs'] = history.history['accuracy']\n",
    "    result['val_accs'] = history.history['val_accuracy']\n",
    "    result['train_acc'] = np.mean(history.history['accuracy'])\n",
    "    result['val_acc'] = np.mean(history.history['val_accuracy'])\n",
    "    result['test_nrmse'] = test_acc\n",
    "    result['y_test'] = np.asarray(partition['test'][1]).tolist()\n",
    "    result['y_pred'] = np.asarray(y_pred).tolist()\n",
    "    \n",
    "    setattr(args, 'features', str(args.features))\n",
    "    return vars(args), model, result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manage Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filepath(setting, filetype):\n",
    "    exp_name = setting['exp_name']\n",
    "    hash_key = hashlib.sha1(str(setting).encode()).hexdigest()[:6]\n",
    "    \n",
    "    file_format = \"\"\n",
    "    directory = \"\"\n",
    "    if filetype == FileType.MODEL:\n",
    "        file_format = 'h5'\n",
    "        directory = 'models'\n",
    "    elif filetype == FileType.RESULT:\n",
    "        file_format = 'json'\n",
    "        directory = 'results'\n",
    "        \n",
    "    filename = \"%s-%s.%s\" % (exp_name, hash_key, file_format)\n",
    "    filepath = os.path.join(Path(os.getcwd()).parent.parent, directory, filename)\n",
    "    return filepath\n",
    "        \n",
    "def save_exp_model(setting, model):\n",
    "    filepath = get_filepath(setting, FileType.MODEL)\n",
    "    model.save(filepath)\n",
    "\n",
    "def save_exp_result(setting, result):\n",
    "    filepath = get_filepath(setting, FileType.RESULT)\n",
    "    \n",
    "    result.update(setting)\n",
    "    with open(filepath, 'w') as f:\n",
    "        json.dump(result, f)\n",
    "        \n",
    "def load_exp_result(exp_name):\n",
    "    dir_path = os.path.join(Path(os.getcwd()).parent.parent, \"results\")\n",
    "    filenames = [f for f in listdeir(dir_path) if isfile(join(dir_path, f)) if '.json' in f]\n",
    "    list_result = []\n",
    "    for filename in filenames:\n",
    "        if exp_name in filename:\n",
    "            with open(join(dir_path, filename), 'r') as infile:\n",
    "                results = json.load(infile)\n",
    "                list_result.append(results)\n",
    "    df = pd.DataFrame(list_result)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(activation='relu', batch_size=64, early_stop=30, end_date='20200809', epochs=256, evaluation='NRMSE', exp_name='solar power prediction using weather features', features=\"[<FeatureType.SUNSHINE: '일조(hr)'>]\", hid_dim=256, lr=0.001, lss='MSE', optim='RMSprop', plant=126, spot=174, start_date='20190820', x_frames=3, y_frames=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vislab/.conda/envs/tf-gpu/lib/python3.8/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/256\n",
      "5/5 [==============================] - 1s 110ms/step - loss: 1317137152.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 2/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1317137152.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 3/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1317137152.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 4/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1317137152.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 5/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1317137024.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 6/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1317137152.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 7/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1317137152.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 8/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1317137152.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 9/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1317137024.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 10/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1317137024.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 11/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1317137152.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 12/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1317137024.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 13/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1317137152.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 14/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1317137152.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 15/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1317137152.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 16/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1317137152.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 17/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1317137152.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 18/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1317137152.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 19/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1317137152.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 20/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1317137152.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 21/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1317137280.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 22/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1317137152.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 23/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1317137152.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 24/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1317137152.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 25/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1317137152.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 26/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1317137152.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 27/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1317137024.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 28/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1317137152.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 29/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1317137152.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 30/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1317137024.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 31/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1317137152.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 32/256\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1317137280.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 33/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1317137024.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 34/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1317137024.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 35/256\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1317137152.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 72, 1)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 256), (None, 264192      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector (RepeatVector)    (None, 24, 256)      0           lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 24, 256), (N 525312      repeat_vector[0][0]              \n",
      "                                                                 lstm[0][1]                       \n",
      "                                                                 lstm[0][2]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 24, 1)        257         lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 789,761\n",
      "Trainable params: 789,761\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Took 6.19 sec for training the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-2dfd02194b65>:7: UserWarning: DEPRECATED: skimage.measure.compare_nrmse has been moved to skimage.metrics.normalized_root_mse. It will be removed from skimage.measure in version 0.18.\n",
      "  nrmse = compare_nrmse(y_test, y_pred)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_losses': [1317137152.0, 1317137152.0, 1317137152.0, 1317137152.0, 1317137024.0, 1317137152.0, 1317137152.0, 1317137152.0, 1317137024.0, 1317137024.0, 1317137152.0, 1317137024.0, 1317137152.0, 1317137152.0, 1317137152.0, 1317137152.0, 1317137152.0, 1317137152.0, 1317137152.0, 1317137152.0, 1317137280.0, 1317137152.0, 1317137152.0, 1317137152.0, 1317137152.0, 1317137152.0, 1317137024.0, 1317137152.0, 1317137152.0, 1317137024.0, 1317137152.0, 1317137280.0, 1317137024.0, 1317137024.0, 1317137152.0], 'val_losses': [855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0], 'train_accs': [0.5380503535270691, 0.5380503535270691, 0.5380503535270691, 0.5380503535270691, 0.5380502939224243, 0.5380502939224243, 0.5380503535270691, 0.5380503535270691, 0.5380503535270691, 0.5380504131317139, 0.5380502939224243, 0.5380503535270691, 0.5380503535270691, 0.5380503535270691, 0.5380503535270691, 0.5380503535270691, 0.5380502939224243, 0.5380503535270691, 0.5380503535270691, 0.5380503535270691, 0.5380502939224243, 0.5380502939224243, 0.5380502939224243, 0.5380502939224243, 0.5380503535270691, 0.5380503535270691, 0.5380503535270691, 0.5380503535270691, 0.5380502939224243, 0.5380503535270691, 0.5380502939224243, 0.5380503535270691, 0.5380502939224243, 0.5380503535270691, 0.5380502939224243], 'val_accs': [0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024], 'train_acc': 0.5380503347941807, 'val_acc': 0.3859127163887024, 'test_nrmse': 1.0, 'y_test': [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1200.0, 2500.0, 3300.0, 11300.0, 13800.0, 12200.0, 8100.0, 4400.0, 2500.0, 3000.0, 3700.0, 300.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1300.0, 5800.0, 11300.0, 23400.0, 44600.0, 63500.0, 57800.0, 63900.0, 38600.0, 32400.0, 19400.0, 24300.0, 9700.0, 600.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 1100.0, 5000.0, 14500.0, 42800.0, 57800.0, 72500.0, 76200.0, 61500.0, 48100.0, 51700.0, 20400.0, 11100.0, 8400.0, 2000.0, 1100.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 700.0, 9100.0, 13200.0, 20300.0, 28900.0, 26800.0, 40600.0, 52300.0, 36200.0, 29900.0, 41400.0, 30500.0, 19300.0, 8300.0, 700.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2600.0, 4500.0, 6900.0, 6600.0, 17000.0, 16300.0, 32100.0, 22500.0, 14000.0, 9100.0, 5000.0, 4500.0, 400.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 400.0, 2800.0, 5100.0, 11700.0, 21900.0, 14800.0, 12900.0, 24100.0, 18200.0, 13200.0, 15500.0, 10600.0, 4700.0, 2100.0, 700.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 500.0, 7700.0, 18600.0, 14500.0, 22800.0, 34500.0, 23900.0, 46400.0, 25200.0, 20700.0, 19600.0, 28200.0, 14100.0, 6500.0, 1800.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1500.0, 4300.0, 6200.0, 17500.0, 11300.0, 9600.0, 10600.0, 11800.0, 7700.0, 3700.0, 3700.0, 3500.0, 2100.0, 900.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 400.0, 4100.0, 13300.0, 29500.0, 54500.0, 48100.0, 59800.0, 68100.0, 63900.0, 50800.0, 55000.0, 34800.0, 11000.0, 1600.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 400.0, 4600.0, 20100.0, 37100.0, 50200.0, 62400.0, 49300.0, 52100.0, 47400.0, 57700.0, 45600.0, 22000.0, 12600.0, 6500.0, 800.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 400.0, 4700.0, 7700.0, 29200.0, 28200.0, 29100.0, 42000.0, 41400.0, 26800.0, 13400.0, 6500.0, 3400.0, 900.0, 200.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 900.0, 4900.0, 9800.0, 13500.0, 25300.0, 29700.0, 41500.0, 24900.0, 8400.0, 17300.0, 14100.0, 2200.0, 500.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 300.0, 5600.0, 12200.0, 22100.0, 28200.0, 32800.0, 48700.0, 38200.0, 42600.0, 30200.0, 28600.0, 21100.0, 16000.0, 8000.0, 400.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 100.0, 700.0, 1900.0, 4000.0, 5500.0, 2700.0, 4300.0, 4600.0, 4100.0, 3800.0, 1800.0, 1000.0, 1000.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 400.0, 1200.0, 4300.0, 4300.0, 6000.0, 3700.0, 2000.0, 5300.0, 2800.0, 1200.0, 400.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 400.0, 3200.0, 6900.0, 12100.0, 31800.0, 31700.0, 44200.0, 34900.0, 24800.0, 32300.0, 21000.0, 16600.0, 7000.0, 3300.0, 200.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1400.0, 5100.0, 12300.0, 13700.0, 13200.0, 9700.0, 15500.0, 12700.0, 8200.0, 11100.0, 8300.0, 5200.0, 1200.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5200.0, 14100.0, 17500.0, 8400.0, 9800.0, 26200.0, 48100.0, 63700.0, 46200.0, 38200.0, 26100.0, 14000.0, 7200.0, 700.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1500.0, 8100.0, 19000.0, 22500.0, 22100.0, 53000.0, 41900.0, 33200.0, 50300.0, 43700.0, 35100.0, 20800.0, 6100.0, 800.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2000.0, 8200.0, 8100.0, 14400.0, 35800.0, 27800.0, 25000.0, 23000.0, 9000.0, 12300.0, 22200.0, 9800.0, 2200.0, 100.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 700.0, 2000.0, 4800.0, 5800.0, 7500.0, 6200.0, 8800.0, 9800.0, 7300.0, 6000.0, 4100.0, 1300.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 100.0, 600.0, 6400.0, 9800.0, 5400.0, 22000.0, 29800.0, 34600.0, 34400.0, 27500.0, 16100.0, 6300.0, 3500.0, 800.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 400.0, 8400.0, 7500.0, 8500.0, 22200.0, 28400.0, 30500.0, 34800.0, 40100.0, 52300.0, 32100.0, 26000.0, 9800.0, 2100.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1500.0, 5200.0, 6200.0, 8400.0, 10800.0, 10700.0, 10700.0, 12900.0, 14000.0, 10700.0, 14700.0, 7300.0, 3900.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 700.0, 500.0, 4700.0, 3200.0, 2400.0, 2100.0, 2100.0, 3100.0, 2000.0, 1400.0, 2100.0, 400.0, 400.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1200.0, 2100.0, 2600.0, 6900.0, 8100.0, 11100.0, 6500.0, 3000.0, 11400.0, 16600.0, 8100.0, 4700.0, 5000.0, 700.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 100.0, 2300.0, 4300.0, 15000.0, 15100.0, 27600.0, 32000.0, 56800.0, 19500.0, 32900.0, 25600.0, 9600.0, 20500.0, 2500.0, 100.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4200.0, 11100.0, 29600.0, 40300.0, 50900.0, 28700.0, 50700.0, 27300.0, 32500.0, 37200.0, 22900.0, 17800.0, 4000.0, 200.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1400.0, 4600.0, 6900.0, 11400.0, 15900.0, 23200.0, 19200.0, 15300.0, 5200.0, 5200.0, 1100.0, 1200.0, 200.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1700.0, 7700.0, 12500.0, 14000.0, 18700.0, 14500.0, 14300.0, 17900.0, 10400.0, 5900.0, 11400.0, 4200.0, 700.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 100.0, 2500.0, 6000.0, 19200.0, 20500.0, 16900.0, 15900.0, 18400.0, 9800.0, 8100.0, 7400.0, 8500.0, 3600.0, 6900.0, 100.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1700.0, 6000.0, 6400.0, 22200.0, 41100.0, 27600.0, 25900.0, 29600.0, 18500.0, 6900.0, 2500.0, 4000.0, 3900.0, 100.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3600.0, 11800.0, 29000.0, 39600.0, 58800.0, 61400.0, 44100.0, 45200.0, 46000.0, 28000.0, 29900.0, 8200.0, 2700.0, 400.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2600.0, 10400.0, 26400.0, 42400.0, 54500.0, 57900.0, 49900.0, 35700.0, 20600.0, 17300.0, 10700.0, 8500.0, 3900.0, 300.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1400.0, 11900.0, 21100.0, 22900.0, 46500.0, 35400.0, 44000.0, 43200.0, 31300.0, 20700.0, 13300.0, 8500.0, 4100.0, 300.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2100.0, 12700.0, 8700.0, 19600.0, 17900.0, 17800.0, 33400.0, 34900.0, 28400.0, 13700.0, 7700.0, 10900.0, 3000.0, 100.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3200.0, 10600.0, 19700.0, 21300.0, 34300.0, 35200.0, 36900.0, 38900.0, 40000.0, 15700.0, 8400.0, 6900.0, 2800.0, 100.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1500.0, 7600.0, 13000.0, 12000.0, 6000.0, 11000.0, 13900.0, 15300.0, 10200.0, 21100.0, 10200.0, 6100.0, 1300.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 800.0, 900.0, 1000.0, 2000.0, 2400.0, 4400.0, 3200.0, 2000.0, 3300.0, 3000.0, 5700.0, 1000.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 500.0, 2200.0, 1900.0, 3400.0, 4600.0, 5200.0, 3700.0, 3900.0, 400.0, 100.0, 100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 900.0, 6600.0, 100.0, 800.0, 1800.0, 10500.0, 4200.0, 7000.0, 2400.0, 2700.0, 1900.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3100.0, 10400.0, 23800.0, 30300.0, 67400.0, 36400.0, 34800.0, 56300.0, 31600.0, 25100.0, 14500.0, 7700.0, 1300.0, 650.0, 0.0, 0.0, 0.0, 0.0]], 'y_pred': [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]], 'exp_name': 'solar power prediction using weather features', 'plant': 126, 'spot': 174, 'start_date': '20190820', 'end_date': '20200809', 'batch_size': 64, 'x_frames': 3, 'y_frames': 1, 'hid_dim': 256, 'optim': 'RMSprop', 'activation': 'relu', 'lss': 'MSE', 'lr': 0.001, 'epochs': 256, 'early_stop': 30, 'evaluation': 'NRMSE', 'features': \"[<FeatureType.SUNSHINE: '일조(hr)'>]\"}\n",
      "\n",
      "Namespace(activation='relu', batch_size=64, early_stop=30, end_date='20200809', epochs=256, evaluation='NRMSE', exp_name='solar power prediction using weather features', features=\"[<FeatureType.SUNSHINE: '일조(hr)'>, <FeatureType.HUMIDITY: '습도(%)'>]\", hid_dim=256, lr=0.001, lss='MSE', optim='RMSprop', plant=126, spot=174, start_date='20190820', x_frames=3, y_frames=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/256\n",
      "5/5 [==============================] - 1s 123ms/step - loss: 1316883840.0000 - accuracy: 0.1410 - val_loss: 855033984.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1316423424.0000 - accuracy: 0.0000e+00 - val_loss: 854911360.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1316328192.0000 - accuracy: 0.0000e+00 - val_loss: 854844352.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1316265344.0000 - accuracy: 0.0000e+00 - val_loss: 854793664.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1316216704.0000 - accuracy: 0.0000e+00 - val_loss: 854745472.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1316169600.0000 - accuracy: 0.0000e+00 - val_loss: 854700416.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1316125440.0000 - accuracy: 0.0000e+00 - val_loss: 854659072.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1316083840.0000 - accuracy: 0.0000e+00 - val_loss: 854616640.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1316041088.0000 - accuracy: 0.0000e+00 - val_loss: 854571392.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315996416.0000 - accuracy: 0.0000e+00 - val_loss: 854526912.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315952640.0000 - accuracy: 0.0000e+00 - val_loss: 854482432.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315908608.0000 - accuracy: 0.0000e+00 - val_loss: 854438208.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315864448.0000 - accuracy: 0.0000e+00 - val_loss: 854393408.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1315820288.0000 - accuracy: 0.0000e+00 - val_loss: 854348160.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315775744.0000 - accuracy: 0.0000e+00 - val_loss: 854307776.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315735296.0000 - accuracy: 0.0000e+00 - val_loss: 854266240.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315693568.0000 - accuracy: 0.0000e+00 - val_loss: 854220992.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315649024.0000 - accuracy: 0.0000e+00 - val_loss: 854181376.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315609088.0000 - accuracy: 0.0000e+00 - val_loss: 854140352.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315567872.0000 - accuracy: 0.0000e+00 - val_loss: 854099072.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315556864.0000 - accuracy: 0.0000e+00 - val_loss: 854055296.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315482240.0000 - accuracy: 0.0000e+00 - val_loss: 854012480.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315440640.0000 - accuracy: 0.0000e+00 - val_loss: 853965120.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1315394304.0000 - accuracy: 0.0000e+00 - val_loss: 853922304.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315351680.0000 - accuracy: 0.0000e+00 - val_loss: 853881216.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315310336.0000 - accuracy: 0.0000e+00 - val_loss: 853835456.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315265536.0000 - accuracy: 0.0000e+00 - val_loss: 853789760.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315220736.0000 - accuracy: 0.0000e+00 - val_loss: 853747136.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315177984.0000 - accuracy: 0.0000e+00 - val_loss: 853707648.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315137792.0000 - accuracy: 0.0000e+00 - val_loss: 853663872.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315094272.0000 - accuracy: 0.0000e+00 - val_loss: 853620736.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315051520.0000 - accuracy: 0.0000e+00 - val_loss: 853577408.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/256\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1315008384.0000 - accuracy: 0.0000e+00 - val_loss: 853533568.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314964736.0000 - accuracy: 0.0000e+00 - val_loss: 853490368.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314921600.0000 - accuracy: 0.0000e+00 - val_loss: 853448384.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314878976.0000 - accuracy: 0.0000e+00 - val_loss: 853403328.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1314834688.0000 - accuracy: 0.0000e+00 - val_loss: 853356352.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314788608.0000 - accuracy: 0.0000e+00 - val_loss: 853314240.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314746368.0000 - accuracy: 0.0000e+00 - val_loss: 853268160.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1314700544.0000 - accuracy: 0.0000e+00 - val_loss: 853225280.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1314657152.0000 - accuracy: 0.0000e+00 - val_loss: 853180544.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1314613120.0000 - accuracy: 0.0000e+00 - val_loss: 853132032.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1314566272.0000 - accuracy: 0.0000e+00 - val_loss: 853092672.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314526464.0000 - accuracy: 0.0000e+00 - val_loss: 853048256.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314481920.0000 - accuracy: 0.0000e+00 - val_loss: 853000000.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314435328.0000 - accuracy: 0.0000e+00 - val_loss: 852959936.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314395136.0000 - accuracy: 0.0000e+00 - val_loss: 852917568.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314352640.0000 - accuracy: 0.0000e+00 - val_loss: 852873408.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314308608.0000 - accuracy: 0.0000e+00 - val_loss: 852833792.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 11ms/step - loss: 1314268800.0000 - accuracy: 0.0000e+00 - val_loss: 852788672.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314224384.0000 - accuracy: 0.0000e+00 - val_loss: 852746752.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1314182400.0000 - accuracy: 0.0000e+00 - val_loss: 852703552.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314138880.0000 - accuracy: 0.0000e+00 - val_loss: 852656128.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314092800.0000 - accuracy: 0.0000e+00 - val_loss: 852614080.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314050816.0000 - accuracy: 0.0000e+00 - val_loss: 852570496.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314007168.0000 - accuracy: 0.0000e+00 - val_loss: 852524544.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313962240.0000 - accuracy: 0.0000e+00 - val_loss: 852481536.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1313919360.0000 - accuracy: 0.0000e+00 - val_loss: 852439168.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313876480.0000 - accuracy: 0.0000e+00 - val_loss: 852393664.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313831424.0000 - accuracy: 0.0000e+00 - val_loss: 852349504.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313787776.0000 - accuracy: 0.0000e+00 - val_loss: 852307584.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1313745920.0000 - accuracy: 0.0000e+00 - val_loss: 852266688.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313704576.0000 - accuracy: 0.0000e+00 - val_loss: 852217728.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313657344.0000 - accuracy: 0.0000e+00 - val_loss: 852177856.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313617664.0000 - accuracy: 0.0000e+00 - val_loss: 852136832.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313575936.0000 - accuracy: 0.0000e+00 - val_loss: 852094784.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1313533952.0000 - accuracy: 0.0000e+00 - val_loss: 852049216.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313488896.0000 - accuracy: 0.0000e+00 - val_loss: 852007808.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313447040.0000 - accuracy: 0.0000e+00 - val_loss: 851960576.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313400960.0000 - accuracy: 0.0000e+00 - val_loss: 851917568.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1313357952.0000 - accuracy: 0.0000e+00 - val_loss: 851876352.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313316480.0000 - accuracy: 0.0000e+00 - val_loss: 851831104.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313272064.0000 - accuracy: 0.0000e+00 - val_loss: 851785344.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313226240.0000 - accuracy: 0.0000e+00 - val_loss: 851739008.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313180928.0000 - accuracy: 0.0000e+00 - val_loss: 851700480.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313141760.0000 - accuracy: 0.0000e+00 - val_loss: 851655936.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313097728.0000 - accuracy: 0.0000e+00 - val_loss: 851611328.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313053440.0000 - accuracy: 0.0000e+00 - val_loss: 851568448.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313010688.0000 - accuracy: 0.0000e+00 - val_loss: 851522304.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312965248.0000 - accuracy: 0.0000e+00 - val_loss: 851480704.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1312923776.0000 - accuracy: 0.0000e+00 - val_loss: 851437248.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312880896.0000 - accuracy: 0.0000e+00 - val_loss: 851394048.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312837376.0000 - accuracy: 0.0000e+00 - val_loss: 851350848.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312794496.0000 - accuracy: 0.0000e+00 - val_loss: 851304640.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312749312.0000 - accuracy: 0.0000e+00 - val_loss: 851264192.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1312708096.0000 - accuracy: 0.0000e+00 - val_loss: 851217920.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312662528.0000 - accuracy: 0.0000e+00 - val_loss: 851174656.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1312619520.0000 - accuracy: 0.0000e+00 - val_loss: 851130880.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312576128.0000 - accuracy: 0.0000e+00 - val_loss: 851085184.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1312531200.0000 - accuracy: 0.0000e+00 - val_loss: 851042112.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312488320.0000 - accuracy: 0.0000e+00 - val_loss: 850999872.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312446208.0000 - accuracy: 0.0000e+00 - val_loss: 850957184.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312404480.0000 - accuracy: 0.0513 - val_loss: 850913600.0000 - val_accuracy: 0.0417\n",
      "Epoch 94/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312359808.0000 - accuracy: 0.0314 - val_loss: 850867456.0000 - val_accuracy: 0.0417\n",
      "Epoch 95/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1312314112.0000 - accuracy: 0.0184 - val_loss: 850821824.0000 - val_accuracy: 0.0417\n",
      "Epoch 96/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1312269440.0000 - accuracy: 0.0415 - val_loss: 850780288.0000 - val_accuracy: 0.0417\n",
      "Epoch 97/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1312227584.0000 - accuracy: 0.0214 - val_loss: 850734016.0000 - val_accuracy: 0.0417\n",
      "Epoch 98/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1312182528.0000 - accuracy: 0.0409 - val_loss: 850691200.0000 - val_accuracy: 0.0417\n",
      "Epoch 99/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1312139648.0000 - accuracy: 0.0308 - val_loss: 850648576.0000 - val_accuracy: 0.0417\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/256\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1312097152.0000 - accuracy: 0.0415 - val_loss: 850606272.0000 - val_accuracy: 0.0417\n",
      "Epoch 101/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312054912.0000 - accuracy: 0.0407 - val_loss: 850560512.0000 - val_accuracy: 0.0417\n",
      "Epoch 102/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312009600.0000 - accuracy: 0.0401 - val_loss: 850518592.0000 - val_accuracy: 0.0417\n",
      "Epoch 103/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311967872.0000 - accuracy: 0.0099 - val_loss: 850475136.0000 - val_accuracy: 0.0417\n",
      "Epoch 104/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311924480.0000 - accuracy: 0.0209 - val_loss: 850432128.0000 - val_accuracy: 0.0417\n",
      "Epoch 105/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311881856.0000 - accuracy: 0.0112 - val_loss: 850388096.0000 - val_accuracy: 0.0417\n",
      "Epoch 106/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311838464.0000 - accuracy: 0.0414 - val_loss: 850345408.0000 - val_accuracy: 0.0417\n",
      "Epoch 107/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311795200.0000 - accuracy: 0.0200 - val_loss: 850296960.0000 - val_accuracy: 0.0417\n",
      "Epoch 108/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311748480.0000 - accuracy: 0.0197 - val_loss: 850255360.0000 - val_accuracy: 0.0417\n",
      "Epoch 109/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1311706624.0000 - accuracy: 0.0107 - val_loss: 850212160.0000 - val_accuracy: 0.0417\n",
      "Epoch 110/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311664256.0000 - accuracy: 0.0393 - val_loss: 850171136.0000 - val_accuracy: 0.0417\n",
      "Epoch 111/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311622400.0000 - accuracy: 0.0099 - val_loss: 850129024.0000 - val_accuracy: 0.0288\n",
      "Epoch 112/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311580288.0000 - accuracy: 0.0344 - val_loss: 850081792.0000 - val_accuracy: 0.0417\n",
      "Epoch 113/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311533824.0000 - accuracy: 0.0300 - val_loss: 850038784.0000 - val_accuracy: 0.0327\n",
      "Epoch 114/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311491072.0000 - accuracy: 0.0063 - val_loss: 849997248.0000 - val_accuracy: 0.0208\n",
      "Epoch 115/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311449984.0000 - accuracy: 0.0335 - val_loss: 849953536.0000 - val_accuracy: 0.0417\n",
      "Epoch 116/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311405952.0000 - accuracy: 0.0113 - val_loss: 849908672.0000 - val_accuracy: 0.0417\n",
      "Epoch 117/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311361920.0000 - accuracy: 0.0302 - val_loss: 849867136.0000 - val_accuracy: 0.0417\n",
      "Epoch 118/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1311320192.0000 - accuracy: 0.0297 - val_loss: 849822464.0000 - val_accuracy: 0.0417\n",
      "Epoch 119/256\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1311275520.0000 - accuracy: 0.0107 - val_loss: 849776256.0000 - val_accuracy: 0.0417\n",
      "Epoch 120/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1311230336.0000 - accuracy: 0.0300 - val_loss: 849733952.0000 - val_accuracy: 0.0417\n",
      "Epoch 121/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311189888.0000 - accuracy: 0.0514 - val_loss: 849690112.0000 - val_accuracy: 0.0417\n",
      "Epoch 122/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311144576.0000 - accuracy: 0.0415 - val_loss: 849647040.0000 - val_accuracy: 0.0417\n",
      "Epoch 123/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311101440.0000 - accuracy: 0.0414 - val_loss: 849601216.0000 - val_accuracy: 0.0417\n",
      "Epoch 124/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311056512.0000 - accuracy: 0.0415 - val_loss: 849556608.0000 - val_accuracy: 0.0417\n",
      "Epoch 125/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311012480.0000 - accuracy: 0.0415 - val_loss: 849515456.0000 - val_accuracy: 0.0417\n",
      "Epoch 126/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310970880.0000 - accuracy: 0.0415 - val_loss: 849469120.0000 - val_accuracy: 0.0417\n",
      "Epoch 127/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310925312.0000 - accuracy: 0.0415 - val_loss: 849424768.0000 - val_accuracy: 0.0417\n",
      "Epoch 128/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1310881280.0000 - accuracy: 0.0368 - val_loss: 849383552.0000 - val_accuracy: 0.0417\n",
      "Epoch 129/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1310839936.0000 - accuracy: 0.0415 - val_loss: 849337024.0000 - val_accuracy: 0.0417\n",
      "Epoch 130/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1310794240.0000 - accuracy: 0.0415 - val_loss: 849294848.0000 - val_accuracy: 0.0417\n",
      "Epoch 131/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1310751872.0000 - accuracy: 0.0379 - val_loss: 849251968.0000 - val_accuracy: 0.0417\n",
      "Epoch 132/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1310709760.0000 - accuracy: 0.0409 - val_loss: 849211200.0000 - val_accuracy: 0.0417\n",
      "Epoch 133/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310668160.0000 - accuracy: 0.0335 - val_loss: 849167104.0000 - val_accuracy: 0.0417\n",
      "Epoch 134/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310625152.0000 - accuracy: 0.0407 - val_loss: 849123520.0000 - val_accuracy: 0.0417\n",
      "Epoch 135/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310581248.0000 - accuracy: 0.0377 - val_loss: 849079360.0000 - val_accuracy: 0.0417\n",
      "Epoch 136/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310538496.0000 - accuracy: 0.0417 - val_loss: 849032640.0000 - val_accuracy: 0.0417\n",
      "Epoch 137/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310491904.0000 - accuracy: 0.0415 - val_loss: 848990528.0000 - val_accuracy: 0.0417\n",
      "Epoch 138/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1310449536.0000 - accuracy: 0.0415 - val_loss: 848945280.0000 - val_accuracy: 0.0417\n",
      "Epoch 139/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310404992.0000 - accuracy: 0.0414 - val_loss: 848903424.0000 - val_accuracy: 0.0417\n",
      "Epoch 140/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310362880.0000 - accuracy: 0.0396 - val_loss: 848859904.0000 - val_accuracy: 0.0417\n",
      "Epoch 141/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310320000.0000 - accuracy: 0.0409 - val_loss: 848815552.0000 - val_accuracy: 0.0417\n",
      "Epoch 142/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310276608.0000 - accuracy: 0.0415 - val_loss: 848775360.0000 - val_accuracy: 0.0417\n",
      "Epoch 143/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310235392.0000 - accuracy: 0.0404 - val_loss: 848733440.0000 - val_accuracy: 0.0417\n",
      "Epoch 144/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310193920.0000 - accuracy: 0.0415 - val_loss: 848689280.0000 - val_accuracy: 0.0417\n",
      "Epoch 145/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310150144.0000 - accuracy: 0.0407 - val_loss: 848647104.0000 - val_accuracy: 0.0417\n",
      "Epoch 146/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310107520.0000 - accuracy: 0.0404 - val_loss: 848599808.0000 - val_accuracy: 0.0417\n",
      "Epoch 147/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1310061696.0000 - accuracy: 0.0415 - val_loss: 848554496.0000 - val_accuracy: 0.0417\n",
      "Epoch 148/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310016384.0000 - accuracy: 0.0415 - val_loss: 848511552.0000 - val_accuracy: 0.0417\n",
      "Epoch 149/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309973504.0000 - accuracy: 0.0415 - val_loss: 848465344.0000 - val_accuracy: 0.0417\n",
      "Epoch 150/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309928576.0000 - accuracy: 0.0415 - val_loss: 848424064.0000 - val_accuracy: 0.0387\n",
      "Epoch 151/256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 11ms/step - loss: 1309886080.0000 - accuracy: 0.0285 - val_loss: 848380480.0000 - val_accuracy: 0.0377\n",
      "Epoch 152/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309842944.0000 - accuracy: 0.0283 - val_loss: 848336192.0000 - val_accuracy: 0.0367\n",
      "Epoch 153/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309798784.0000 - accuracy: 0.0289 - val_loss: 848289792.0000 - val_accuracy: 0.0387\n",
      "Epoch 154/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309753344.0000 - accuracy: 0.0292 - val_loss: 848249408.0000 - val_accuracy: 0.0417\n",
      "Epoch 155/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309714432.0000 - accuracy: 0.0347 - val_loss: 848211776.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 156/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1309673344.0000 - accuracy: 0.0275 - val_loss: 848167488.0000 - val_accuracy: 0.0417\n",
      "Epoch 157/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1309630848.0000 - accuracy: 0.0381 - val_loss: 848120512.0000 - val_accuracy: 0.0417\n",
      "Epoch 158/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309585152.0000 - accuracy: 0.0415 - val_loss: 848077504.0000 - val_accuracy: 0.0417\n",
      "Epoch 159/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309542144.0000 - accuracy: 0.0404 - val_loss: 848034944.0000 - val_accuracy: 0.0417\n",
      "Epoch 160/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309500032.0000 - accuracy: 0.0398 - val_loss: 847990656.0000 - val_accuracy: 0.0417\n",
      "Epoch 161/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309455872.0000 - accuracy: 0.0275 - val_loss: 847953024.0000 - val_accuracy: 0.0317\n",
      "Epoch 162/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309414656.0000 - accuracy: 0.0335 - val_loss: 847904576.0000 - val_accuracy: 0.0417\n",
      "Epoch 163/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309371008.0000 - accuracy: 0.0352 - val_loss: 847861440.0000 - val_accuracy: 0.0417\n",
      "Epoch 164/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309327744.0000 - accuracy: 0.0358 - val_loss: 847815424.0000 - val_accuracy: 0.0417\n",
      "Epoch 165/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309282176.0000 - accuracy: 0.0381 - val_loss: 847773120.0000 - val_accuracy: 0.0417\n",
      "Epoch 166/256\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1309239808.0000 - accuracy: 0.0387 - val_loss: 847725824.0000 - val_accuracy: 0.0407\n",
      "Epoch 167/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1309193472.0000 - accuracy: 0.0362 - val_loss: 847686400.0000 - val_accuracy: 0.0417\n",
      "Epoch 168/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309153664.0000 - accuracy: 0.0330 - val_loss: 847653952.0000 - val_accuracy: 0.0387\n",
      "Epoch 169/256\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1309114496.0000 - accuracy: 0.0388 - val_loss: 847605376.0000 - val_accuracy: 0.0417\n",
      "Epoch 170/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1309072128.0000 - accuracy: 0.0384 - val_loss: 847557696.0000 - val_accuracy: 0.0417\n",
      "Epoch 171/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309748480.0000 - accuracy: 0.0909 - val_loss: 847516160.0000 - val_accuracy: 0.0417\n",
      "Epoch 172/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308983680.0000 - accuracy: 0.0399 - val_loss: 847474176.0000 - val_accuracy: 0.0417\n",
      "Epoch 173/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308941696.0000 - accuracy: 0.0399 - val_loss: 847429248.0000 - val_accuracy: 0.0417\n",
      "Epoch 174/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308897152.0000 - accuracy: 0.0399 - val_loss: 847388096.0000 - val_accuracy: 0.0417\n",
      "Epoch 175/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1308855680.0000 - accuracy: 0.0401 - val_loss: 847341568.0000 - val_accuracy: 0.0417\n",
      "Epoch 176/256\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1308810240.0000 - accuracy: 0.0401 - val_loss: 847298368.0000 - val_accuracy: 0.0417\n",
      "Epoch 177/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1308767232.0000 - accuracy: 0.0401 - val_loss: 847257280.0000 - val_accuracy: 0.0417\n",
      "Epoch 178/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1308726016.0000 - accuracy: 0.0401 - val_loss: 847213504.0000 - val_accuracy: 0.0417\n",
      "Epoch 179/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308682624.0000 - accuracy: 0.0401 - val_loss: 847173952.0000 - val_accuracy: 0.0417\n",
      "Epoch 180/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308642560.0000 - accuracy: 0.0403 - val_loss: 847131200.0000 - val_accuracy: 0.0417\n",
      "Epoch 181/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308599296.0000 - accuracy: 0.0404 - val_loss: 847085760.0000 - val_accuracy: 0.0417\n",
      "Epoch 182/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308554752.0000 - accuracy: 0.0395 - val_loss: 847039744.0000 - val_accuracy: 0.0417\n",
      "Epoch 183/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308509312.0000 - accuracy: 0.0409 - val_loss: 846995264.0000 - val_accuracy: 0.0417\n",
      "Epoch 184/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1308465280.0000 - accuracy: 0.0392 - val_loss: 846952256.0000 - val_accuracy: 0.0417\n",
      "Epoch 185/256\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1308422144.0000 - accuracy: 0.0395 - val_loss: 846910784.0000 - val_accuracy: 0.0417\n",
      "Epoch 186/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1308380032.0000 - accuracy: 0.0406 - val_loss: 846864000.0000 - val_accuracy: 0.0417\n",
      "Epoch 187/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308334848.0000 - accuracy: 0.0398 - val_loss: 846816896.0000 - val_accuracy: 0.0417\n",
      "Epoch 188/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1308289024.0000 - accuracy: 0.0393 - val_loss: 846775744.0000 - val_accuracy: 0.0417\n",
      "Epoch 189/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308247168.0000 - accuracy: 0.0363 - val_loss: 846737792.0000 - val_accuracy: 0.0417\n",
      "Epoch 190/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308204672.0000 - accuracy: 0.0368 - val_loss: 846692736.0000 - val_accuracy: 0.0417\n",
      "Epoch 191/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308162048.0000 - accuracy: 0.0338 - val_loss: 846645568.0000 - val_accuracy: 0.0407\n",
      "Epoch 192/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308118784.0000 - accuracy: 0.0381 - val_loss: 846610432.0000 - val_accuracy: 0.0417\n",
      "Epoch 193/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308077184.0000 - accuracy: 0.0373 - val_loss: 846561664.0000 - val_accuracy: 0.0417\n",
      "Epoch 194/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308034944.0000 - accuracy: 0.0401 - val_loss: 846519552.0000 - val_accuracy: 0.0417\n",
      "Epoch 195/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1307991296.0000 - accuracy: 0.0410 - val_loss: 846480320.0000 - val_accuracy: 0.0417\n",
      "Epoch 196/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307951616.0000 - accuracy: 0.0461 - val_loss: 846435072.0000 - val_accuracy: 0.0575\n",
      "Epoch 197/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307908224.0000 - accuracy: 0.0412 - val_loss: 846388864.0000 - val_accuracy: 0.0417\n",
      "Epoch 198/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307862784.0000 - accuracy: 0.0401 - val_loss: 846352960.0000 - val_accuracy: 0.0417\n",
      "Epoch 199/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307822336.0000 - accuracy: 0.0349 - val_loss: 846307520.0000 - val_accuracy: 0.0417\n",
      "Epoch 200/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307781760.0000 - accuracy: 0.0414 - val_loss: 846267072.0000 - val_accuracy: 0.0675\n",
      "Epoch 201/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307737600.0000 - accuracy: 0.0451 - val_loss: 846219072.0000 - val_accuracy: 0.0417\n",
      "Epoch 202/256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 11ms/step - loss: 1307693056.0000 - accuracy: 0.0412 - val_loss: 846172480.0000 - val_accuracy: 0.0397\n",
      "Epoch 203/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307647360.0000 - accuracy: 0.0303 - val_loss: 846128960.0000 - val_accuracy: 0.0417\n",
      "Epoch 204/256\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1307605760.0000 - accuracy: 0.0358 - val_loss: 846089856.0000 - val_accuracy: 0.0437\n",
      "Epoch 205/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307563904.0000 - accuracy: 0.0429 - val_loss: 846042752.0000 - val_accuracy: 0.0417\n",
      "Epoch 206/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307518464.0000 - accuracy: 0.0355 - val_loss: 846003072.0000 - val_accuracy: 0.0506\n",
      "Epoch 207/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1307475456.0000 - accuracy: 0.0506 - val_loss: 845964800.0000 - val_accuracy: 0.0804\n",
      "Epoch 208/256\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1307434240.0000 - accuracy: 0.0701 - val_loss: 845913024.0000 - val_accuracy: 0.0417\n",
      "Epoch 209/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307389824.0000 - accuracy: 0.0415 - val_loss: 845870144.0000 - val_accuracy: 0.0417\n",
      "Epoch 210/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307347072.0000 - accuracy: 0.0418 - val_loss: 845821056.0000 - val_accuracy: 0.0417\n",
      "Epoch 211/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307300736.0000 - accuracy: 0.0388 - val_loss: 845776000.0000 - val_accuracy: 0.0417\n",
      "Epoch 212/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307256320.0000 - accuracy: 0.0418 - val_loss: 845738368.0000 - val_accuracy: 0.0427\n",
      "Epoch 213/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307218432.0000 - accuracy: 0.0407 - val_loss: 845697792.0000 - val_accuracy: 0.0417\n",
      "Epoch 214/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1307177344.0000 - accuracy: 0.0473 - val_loss: 845657216.0000 - val_accuracy: 0.0417\n",
      "Epoch 215/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307136384.0000 - accuracy: 0.0365 - val_loss: 845611200.0000 - val_accuracy: 0.0417\n",
      "Epoch 216/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307090944.0000 - accuracy: 0.0373 - val_loss: 845569280.0000 - val_accuracy: 0.0417\n",
      "Epoch 217/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307048576.0000 - accuracy: 0.0362 - val_loss: 845534848.0000 - val_accuracy: 0.0417\n",
      "Epoch 218/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307008256.0000 - accuracy: 0.0355 - val_loss: 845498048.0000 - val_accuracy: 0.0456\n",
      "Epoch 219/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306966016.0000 - accuracy: 0.0330 - val_loss: 845438656.0000 - val_accuracy: 0.0407\n",
      "Epoch 220/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306919424.0000 - accuracy: 0.0379 - val_loss: 845395072.0000 - val_accuracy: 0.0417\n",
      "Epoch 221/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306874240.0000 - accuracy: 0.0393 - val_loss: 845357248.0000 - val_accuracy: 0.0556\n",
      "Epoch 222/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306832000.0000 - accuracy: 0.0506 - val_loss: 845307584.0000 - val_accuracy: 0.0476\n",
      "Epoch 223/256\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1306787840.0000 - accuracy: 0.0520 - val_loss: 845262528.0000 - val_accuracy: 0.0407\n",
      "Epoch 224/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1306745216.0000 - accuracy: 0.0352 - val_loss: 845216512.0000 - val_accuracy: 0.0407\n",
      "Epoch 225/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306699136.0000 - accuracy: 0.0387 - val_loss: 845184320.0000 - val_accuracy: 0.0526\n",
      "Epoch 226/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306656640.0000 - accuracy: 0.0487 - val_loss: 845167168.0000 - val_accuracy: 0.0952\n",
      "Epoch 227/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1306620032.0000 - accuracy: 0.0513 - val_loss: 845089664.0000 - val_accuracy: 0.0427\n",
      "Epoch 228/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306572288.0000 - accuracy: 0.0423 - val_loss: 845050560.0000 - val_accuracy: 0.0496\n",
      "Epoch 229/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306530176.0000 - accuracy: 0.0497 - val_loss: 845002880.0000 - val_accuracy: 0.0635\n",
      "Epoch 230/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306487424.0000 - accuracy: 0.0678 - val_loss: 844960448.0000 - val_accuracy: 0.0506\n",
      "Epoch 231/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306442240.0000 - accuracy: 0.0571 - val_loss: 844920448.0000 - val_accuracy: 0.0804\n",
      "Epoch 232/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1306406272.0000 - accuracy: 0.0796 - val_loss: 844877696.0000 - val_accuracy: 0.0635\n",
      "Epoch 233/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1306363520.0000 - accuracy: 0.0607 - val_loss: 844834048.0000 - val_accuracy: 0.0764\n",
      "Epoch 234/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306320256.0000 - accuracy: 0.0653 - val_loss: 844792128.0000 - val_accuracy: 0.0724\n",
      "Epoch 235/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306277760.0000 - accuracy: 0.0712 - val_loss: 844752192.0000 - val_accuracy: 0.0526\n",
      "Epoch 236/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306237568.0000 - accuracy: 0.0431 - val_loss: 844714688.0000 - val_accuracy: 0.0635\n",
      "Epoch 237/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306195328.0000 - accuracy: 0.0627 - val_loss: 844667008.0000 - val_accuracy: 0.0476\n",
      "Epoch 238/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1306150912.0000 - accuracy: 0.0478 - val_loss: 844623680.0000 - val_accuracy: 0.0635\n",
      "Epoch 239/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306108032.0000 - accuracy: 0.0579 - val_loss: 844579904.0000 - val_accuracy: 0.0506\n",
      "Epoch 240/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1306063360.0000 - accuracy: 0.0436 - val_loss: 844534464.0000 - val_accuracy: 0.0427\n",
      "Epoch 241/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1306021376.0000 - accuracy: 0.0437 - val_loss: 844489472.0000 - val_accuracy: 0.0506\n",
      "Epoch 242/256\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1305975040.0000 - accuracy: 0.0514 - val_loss: 844444224.0000 - val_accuracy: 0.0427\n",
      "Epoch 243/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1305931392.0000 - accuracy: 0.0516 - val_loss: 844404352.0000 - val_accuracy: 0.0585\n",
      "Epoch 244/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1305889280.0000 - accuracy: 0.0440 - val_loss: 844385408.0000 - val_accuracy: 0.0794\n",
      "Epoch 245/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1305848576.0000 - accuracy: 0.0616 - val_loss: 844317440.0000 - val_accuracy: 0.0625\n",
      "Epoch 246/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1305803264.0000 - accuracy: 0.0569 - val_loss: 844286656.0000 - val_accuracy: 0.0734\n",
      "Epoch 247/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1305758208.0000 - accuracy: 0.0648 - val_loss: 844227264.0000 - val_accuracy: 0.0694\n",
      "Epoch 248/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1305712128.0000 - accuracy: 0.0719 - val_loss: 844187328.0000 - val_accuracy: 0.0327\n",
      "Epoch 249/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1305675520.0000 - accuracy: 0.0605 - val_loss: 844139776.0000 - val_accuracy: 0.0635\n",
      "Epoch 250/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1305625344.0000 - accuracy: 0.0668 - val_loss: 844134528.0000 - val_accuracy: 0.0843\n",
      "Epoch 251/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1305587072.0000 - accuracy: 0.0596 - val_loss: 844075200.0000 - val_accuracy: 0.0883\n",
      "Epoch 252/256\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1305544448.0000 - accuracy: 0.0791 - val_loss: 844020224.0000 - val_accuracy: 0.1012\n",
      "Epoch 253/256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 11ms/step - loss: 1305501440.0000 - accuracy: 0.0849 - val_loss: 843969280.0000 - val_accuracy: 0.0605\n",
      "Epoch 254/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1305456896.0000 - accuracy: 0.0624 - val_loss: 843925312.0000 - val_accuracy: 0.0883\n",
      "Epoch 255/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1305411584.0000 - accuracy: 0.0851 - val_loss: 843886592.0000 - val_accuracy: 0.0913\n",
      "Epoch 256/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1305367680.0000 - accuracy: 0.0736 - val_loss: 843844352.0000 - val_accuracy: 0.0893\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 72, 2)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 256), (None, 265216      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_1 (RepeatVector)  (None, 24, 256)      0           lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, 24, 256), (N 525312      repeat_vector_1[0][0]            \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 24, 1)        257         lstm_3[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 790,785\n",
      "Trainable params: 790,785\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Took 19.98 sec for training the model\n",
      "{'train_losses': [1316883840.0, 1316423424.0, 1316328192.0, 1316265344.0, 1316216704.0, 1316169600.0, 1316125440.0, 1316083840.0, 1316041088.0, 1315996416.0, 1315952640.0, 1315908608.0, 1315864448.0, 1315820288.0, 1315775744.0, 1315735296.0, 1315693568.0, 1315649024.0, 1315609088.0, 1315567872.0, 1315556864.0, 1315482240.0, 1315440640.0, 1315394304.0, 1315351680.0, 1315310336.0, 1315265536.0, 1315220736.0, 1315177984.0, 1315137792.0, 1315094272.0, 1315051520.0, 1315008384.0, 1314964736.0, 1314921600.0, 1314878976.0, 1314834688.0, 1314788608.0, 1314746368.0, 1314700544.0, 1314657152.0, 1314613120.0, 1314566272.0, 1314526464.0, 1314481920.0, 1314435328.0, 1314395136.0, 1314352640.0, 1314308608.0, 1314268800.0, 1314224384.0, 1314182400.0, 1314138880.0, 1314092800.0, 1314050816.0, 1314007168.0, 1313962240.0, 1313919360.0, 1313876480.0, 1313831424.0, 1313787776.0, 1313745920.0, 1313704576.0, 1313657344.0, 1313617664.0, 1313575936.0, 1313533952.0, 1313488896.0, 1313447040.0, 1313400960.0, 1313357952.0, 1313316480.0, 1313272064.0, 1313226240.0, 1313180928.0, 1313141760.0, 1313097728.0, 1313053440.0, 1313010688.0, 1312965248.0, 1312923776.0, 1312880896.0, 1312837376.0, 1312794496.0, 1312749312.0, 1312708096.0, 1312662528.0, 1312619520.0, 1312576128.0, 1312531200.0, 1312488320.0, 1312446208.0, 1312404480.0, 1312359808.0, 1312314112.0, 1312269440.0, 1312227584.0, 1312182528.0, 1312139648.0, 1312097152.0, 1312054912.0, 1312009600.0, 1311967872.0, 1311924480.0, 1311881856.0, 1311838464.0, 1311795200.0, 1311748480.0, 1311706624.0, 1311664256.0, 1311622400.0, 1311580288.0, 1311533824.0, 1311491072.0, 1311449984.0, 1311405952.0, 1311361920.0, 1311320192.0, 1311275520.0, 1311230336.0, 1311189888.0, 1311144576.0, 1311101440.0, 1311056512.0, 1311012480.0, 1310970880.0, 1310925312.0, 1310881280.0, 1310839936.0, 1310794240.0, 1310751872.0, 1310709760.0, 1310668160.0, 1310625152.0, 1310581248.0, 1310538496.0, 1310491904.0, 1310449536.0, 1310404992.0, 1310362880.0, 1310320000.0, 1310276608.0, 1310235392.0, 1310193920.0, 1310150144.0, 1310107520.0, 1310061696.0, 1310016384.0, 1309973504.0, 1309928576.0, 1309886080.0, 1309842944.0, 1309798784.0, 1309753344.0, 1309714432.0, 1309673344.0, 1309630848.0, 1309585152.0, 1309542144.0, 1309500032.0, 1309455872.0, 1309414656.0, 1309371008.0, 1309327744.0, 1309282176.0, 1309239808.0, 1309193472.0, 1309153664.0, 1309114496.0, 1309072128.0, 1309748480.0, 1308983680.0, 1308941696.0, 1308897152.0, 1308855680.0, 1308810240.0, 1308767232.0, 1308726016.0, 1308682624.0, 1308642560.0, 1308599296.0, 1308554752.0, 1308509312.0, 1308465280.0, 1308422144.0, 1308380032.0, 1308334848.0, 1308289024.0, 1308247168.0, 1308204672.0, 1308162048.0, 1308118784.0, 1308077184.0, 1308034944.0, 1307991296.0, 1307951616.0, 1307908224.0, 1307862784.0, 1307822336.0, 1307781760.0, 1307737600.0, 1307693056.0, 1307647360.0, 1307605760.0, 1307563904.0, 1307518464.0, 1307475456.0, 1307434240.0, 1307389824.0, 1307347072.0, 1307300736.0, 1307256320.0, 1307218432.0, 1307177344.0, 1307136384.0, 1307090944.0, 1307048576.0, 1307008256.0, 1306966016.0, 1306919424.0, 1306874240.0, 1306832000.0, 1306787840.0, 1306745216.0, 1306699136.0, 1306656640.0, 1306620032.0, 1306572288.0, 1306530176.0, 1306487424.0, 1306442240.0, 1306406272.0, 1306363520.0, 1306320256.0, 1306277760.0, 1306237568.0, 1306195328.0, 1306150912.0, 1306108032.0, 1306063360.0, 1306021376.0, 1305975040.0, 1305931392.0, 1305889280.0, 1305848576.0, 1305803264.0, 1305758208.0, 1305712128.0, 1305675520.0, 1305625344.0, 1305587072.0, 1305544448.0, 1305501440.0, 1305456896.0, 1305411584.0, 1305367680.0], 'val_losses': [855033984.0, 854911360.0, 854844352.0, 854793664.0, 854745472.0, 854700416.0, 854659072.0, 854616640.0, 854571392.0, 854526912.0, 854482432.0, 854438208.0, 854393408.0, 854348160.0, 854307776.0, 854266240.0, 854220992.0, 854181376.0, 854140352.0, 854099072.0, 854055296.0, 854012480.0, 853965120.0, 853922304.0, 853881216.0, 853835456.0, 853789760.0, 853747136.0, 853707648.0, 853663872.0, 853620736.0, 853577408.0, 853533568.0, 853490368.0, 853448384.0, 853403328.0, 853356352.0, 853314240.0, 853268160.0, 853225280.0, 853180544.0, 853132032.0, 853092672.0, 853048256.0, 853000000.0, 852959936.0, 852917568.0, 852873408.0, 852833792.0, 852788672.0, 852746752.0, 852703552.0, 852656128.0, 852614080.0, 852570496.0, 852524544.0, 852481536.0, 852439168.0, 852393664.0, 852349504.0, 852307584.0, 852266688.0, 852217728.0, 852177856.0, 852136832.0, 852094784.0, 852049216.0, 852007808.0, 851960576.0, 851917568.0, 851876352.0, 851831104.0, 851785344.0, 851739008.0, 851700480.0, 851655936.0, 851611328.0, 851568448.0, 851522304.0, 851480704.0, 851437248.0, 851394048.0, 851350848.0, 851304640.0, 851264192.0, 851217920.0, 851174656.0, 851130880.0, 851085184.0, 851042112.0, 850999872.0, 850957184.0, 850913600.0, 850867456.0, 850821824.0, 850780288.0, 850734016.0, 850691200.0, 850648576.0, 850606272.0, 850560512.0, 850518592.0, 850475136.0, 850432128.0, 850388096.0, 850345408.0, 850296960.0, 850255360.0, 850212160.0, 850171136.0, 850129024.0, 850081792.0, 850038784.0, 849997248.0, 849953536.0, 849908672.0, 849867136.0, 849822464.0, 849776256.0, 849733952.0, 849690112.0, 849647040.0, 849601216.0, 849556608.0, 849515456.0, 849469120.0, 849424768.0, 849383552.0, 849337024.0, 849294848.0, 849251968.0, 849211200.0, 849167104.0, 849123520.0, 849079360.0, 849032640.0, 848990528.0, 848945280.0, 848903424.0, 848859904.0, 848815552.0, 848775360.0, 848733440.0, 848689280.0, 848647104.0, 848599808.0, 848554496.0, 848511552.0, 848465344.0, 848424064.0, 848380480.0, 848336192.0, 848289792.0, 848249408.0, 848211776.0, 848167488.0, 848120512.0, 848077504.0, 848034944.0, 847990656.0, 847953024.0, 847904576.0, 847861440.0, 847815424.0, 847773120.0, 847725824.0, 847686400.0, 847653952.0, 847605376.0, 847557696.0, 847516160.0, 847474176.0, 847429248.0, 847388096.0, 847341568.0, 847298368.0, 847257280.0, 847213504.0, 847173952.0, 847131200.0, 847085760.0, 847039744.0, 846995264.0, 846952256.0, 846910784.0, 846864000.0, 846816896.0, 846775744.0, 846737792.0, 846692736.0, 846645568.0, 846610432.0, 846561664.0, 846519552.0, 846480320.0, 846435072.0, 846388864.0, 846352960.0, 846307520.0, 846267072.0, 846219072.0, 846172480.0, 846128960.0, 846089856.0, 846042752.0, 846003072.0, 845964800.0, 845913024.0, 845870144.0, 845821056.0, 845776000.0, 845738368.0, 845697792.0, 845657216.0, 845611200.0, 845569280.0, 845534848.0, 845498048.0, 845438656.0, 845395072.0, 845357248.0, 845307584.0, 845262528.0, 845216512.0, 845184320.0, 845167168.0, 845089664.0, 845050560.0, 845002880.0, 844960448.0, 844920448.0, 844877696.0, 844834048.0, 844792128.0, 844752192.0, 844714688.0, 844667008.0, 844623680.0, 844579904.0, 844534464.0, 844489472.0, 844444224.0, 844404352.0, 844385408.0, 844317440.0, 844286656.0, 844227264.0, 844187328.0, 844139776.0, 844134528.0, 844075200.0, 844020224.0, 843969280.0, 843925312.0, 843886592.0, 843844352.0], 'train_accs': [0.1410377323627472, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05125786364078522, 0.03144654259085655, 0.018396226689219475, 0.04150943458080292, 0.021383648738265038, 0.04088050499558449, 0.030817611142992973, 0.04150943458080292, 0.040723271667957306, 0.04009433835744858, 0.009905660524964333, 0.02091195061802864, 0.011163521558046341, 0.041352201253175735, 0.019968554377555847, 0.019654087722301483, 0.010691823437809944, 0.039308175444602966, 0.009905660524964333, 0.034433960914611816, 0.030031446367502213, 0.006289308425039053, 0.03349056467413902, 0.011320754885673523, 0.030188679695129395, 0.029716983437538147, 0.010691823437809944, 0.030031446367502213, 0.0514150932431221, 0.04150943458080292, 0.041352204978466034, 0.04150943458080292, 0.04150943458080292, 0.04150943458080292, 0.04150943458080292, 0.03679245710372925, 0.04150943458080292, 0.04150943458080292, 0.037893082946538925, 0.04088050499558449, 0.03349056467413902, 0.040723271667957306, 0.03773584961891174, 0.0416666679084301, 0.04150943458080292, 0.041509438306093216, 0.041352204978466034, 0.03962264582514763, 0.04088050499558449, 0.04150943458080292, 0.04040880873799324, 0.04150943458080292, 0.040723271667957306, 0.04040880873799324, 0.04150943458080292, 0.04150943458080292, 0.04150943458080292, 0.04150943458080292, 0.02845912054181099, 0.028301887214183807, 0.028930816799402237, 0.02924528531730175, 0.03474843129515648, 0.027515724301338196, 0.03805031627416611, 0.04150943458080292, 0.04040880873799324, 0.03977987542748451, 0.027515724301338196, 0.03349056467413902, 0.035220127552747726, 0.035849060863256454, 0.03805031627416611, 0.038679249584674835, 0.03616352379322052, 0.033018868416547775, 0.03883647918701172, 0.03836478292942047, 0.09088050574064255, 0.039937108755111694, 0.039937108755111694, 0.039937108755111694, 0.04009433835744858, 0.04009433835744858, 0.04009433835744858, 0.04009433835744858, 0.04009433835744858, 0.04025157168507576, 0.04040880873799324, 0.03946541249752045, 0.04088050499558449, 0.039150942116975784, 0.03946541249752045, 0.040566038340330124, 0.03977987542748451, 0.039308175444602966, 0.036320753395557404, 0.03679245710372925, 0.033805035054683685, 0.03805031254887581, 0.0372641496360302, 0.04009433835744858, 0.04103773459792137, 0.0460691824555397, 0.04119496792554855, 0.04009433835744858, 0.03490566089749336, 0.041352204978466034, 0.04512578621506691, 0.04119496792554855, 0.030345913022756577, 0.035849057137966156, 0.04292453080415726, 0.03553459420800209, 0.05062893033027649, 0.07012578845024109, 0.04150943458080292, 0.04182390123605728, 0.03883647918701172, 0.04182390123605728, 0.040723271667957306, 0.04732704535126686, 0.036477990448474884, 0.037264153361320496, 0.03616352379322052, 0.03553459420800209, 0.033018868416547775, 0.037893082946538925, 0.039308175444602966, 0.05062893033027649, 0.05204402655363083, 0.03522012382745743, 0.038679249584674835, 0.0487421378493309, 0.05125786364078522, 0.042295604944229126, 0.049685534089803696, 0.06776729971170425, 0.05707547441124916, 0.07955975830554962, 0.06069182604551315, 0.06525157392024994, 0.07122641801834106, 0.04308176040649414, 0.06273584812879562, 0.04779874160885811, 0.05786164104938507, 0.04355346038937569, 0.04371068999171257, 0.0514150969684124, 0.05157233029603958, 0.044025156646966934, 0.06163522228598595, 0.05691824480891228, 0.06477987766265869, 0.07185535132884979, 0.06053459644317627, 0.06682389974594116, 0.05959119647741318, 0.07908805459737778, 0.08490566909313202, 0.06242138892412186, 0.0850628986954689, 0.0735849142074585], 'val_accs': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.02876984141767025, 0.0416666679084301, 0.032738097012043, 0.02083333395421505, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0386904776096344, 0.0376984179019928, 0.0367063507437706, 0.0386904776096344, 0.0416666679084301, 0.0, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0317460335791111, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0406746082007885, 0.0416666679084301, 0.0386904776096344, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0406746082007885, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0575396828353405, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0674603208899498, 0.0416666679084301, 0.0396825410425663, 0.0416666679084301, 0.0436507984995842, 0.0416666679084301, 0.0505952388048172, 0.0803571417927742, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.042658731341362, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0456349216401577, 0.0406746082007885, 0.0416666679084301, 0.055555559694767, 0.0476190485060215, 0.0406746082007885, 0.0406746082007885, 0.0525793693959713, 0.095238097012043, 0.042658731341362, 0.0496031790971756, 0.0634920671582222, 0.0505952388048172, 0.0803571417927742, 0.0634920671582222, 0.0763888955116272, 0.072420634329319, 0.0525793693959713, 0.0634920671582222, 0.0476190485060215, 0.0634920671582222, 0.0505952388048172, 0.042658731341362, 0.0505952388048172, 0.042658731341362, 0.0585317499935627, 0.0793650820851326, 0.0625, 0.0734127014875412, 0.0694444477558136, 0.032738097012043, 0.0634920746088028, 0.0843253955245018, 0.08829365670681, 0.1011904776096344, 0.0605158731341362, 0.08829365670681, 0.0912698432803154, 0.0892857164144516], 'train_acc': 0.02718037627892045, 'val_acc': 0.029688276117667556, 'test_nrmse': 0.9894557052185926, 'y_test': [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1200.0, 2500.0, 3300.0, 11300.0, 13800.0, 12200.0, 8100.0, 4400.0, 2500.0, 3000.0, 3700.0, 300.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1300.0, 5800.0, 11300.0, 23400.0, 44600.0, 63500.0, 57800.0, 63900.0, 38600.0, 32400.0, 19400.0, 24300.0, 9700.0, 600.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 1100.0, 5000.0, 14500.0, 42800.0, 57800.0, 72500.0, 76200.0, 61500.0, 48100.0, 51700.0, 20400.0, 11100.0, 8400.0, 2000.0, 1100.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 700.0, 9100.0, 13200.0, 20300.0, 28900.0, 26800.0, 40600.0, 52300.0, 36200.0, 29900.0, 41400.0, 30500.0, 19300.0, 8300.0, 700.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2600.0, 4500.0, 6900.0, 6600.0, 17000.0, 16300.0, 32100.0, 22500.0, 14000.0, 9100.0, 5000.0, 4500.0, 400.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 400.0, 2800.0, 5100.0, 11700.0, 21900.0, 14800.0, 12900.0, 24100.0, 18200.0, 13200.0, 15500.0, 10600.0, 4700.0, 2100.0, 700.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 500.0, 7700.0, 18600.0, 14500.0, 22800.0, 34500.0, 23900.0, 46400.0, 25200.0, 20700.0, 19600.0, 28200.0, 14100.0, 6500.0, 1800.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1500.0, 4300.0, 6200.0, 17500.0, 11300.0, 9600.0, 10600.0, 11800.0, 7700.0, 3700.0, 3700.0, 3500.0, 2100.0, 900.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 400.0, 4100.0, 13300.0, 29500.0, 54500.0, 48100.0, 59800.0, 68100.0, 63900.0, 50800.0, 55000.0, 34800.0, 11000.0, 1600.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 400.0, 4600.0, 20100.0, 37100.0, 50200.0, 62400.0, 49300.0, 52100.0, 47400.0, 57700.0, 45600.0, 22000.0, 12600.0, 6500.0, 800.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 400.0, 4700.0, 7700.0, 29200.0, 28200.0, 29100.0, 42000.0, 41400.0, 26800.0, 13400.0, 6500.0, 3400.0, 900.0, 200.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 900.0, 4900.0, 9800.0, 13500.0, 25300.0, 29700.0, 41500.0, 24900.0, 8400.0, 17300.0, 14100.0, 2200.0, 500.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 300.0, 5600.0, 12200.0, 22100.0, 28200.0, 32800.0, 48700.0, 38200.0, 42600.0, 30200.0, 28600.0, 21100.0, 16000.0, 8000.0, 400.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 100.0, 700.0, 1900.0, 4000.0, 5500.0, 2700.0, 4300.0, 4600.0, 4100.0, 3800.0, 1800.0, 1000.0, 1000.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 400.0, 1200.0, 4300.0, 4300.0, 6000.0, 3700.0, 2000.0, 5300.0, 2800.0, 1200.0, 400.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 400.0, 3200.0, 6900.0, 12100.0, 31800.0, 31700.0, 44200.0, 34900.0, 24800.0, 32300.0, 21000.0, 16600.0, 7000.0, 3300.0, 200.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1400.0, 5100.0, 12300.0, 13700.0, 13200.0, 9700.0, 15500.0, 12700.0, 8200.0, 11100.0, 8300.0, 5200.0, 1200.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5200.0, 14100.0, 17500.0, 8400.0, 9800.0, 26200.0, 48100.0, 63700.0, 46200.0, 38200.0, 26100.0, 14000.0, 7200.0, 700.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1500.0, 8100.0, 19000.0, 22500.0, 22100.0, 53000.0, 41900.0, 33200.0, 50300.0, 43700.0, 35100.0, 20800.0, 6100.0, 800.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2000.0, 8200.0, 8100.0, 14400.0, 35800.0, 27800.0, 25000.0, 23000.0, 9000.0, 12300.0, 22200.0, 9800.0, 2200.0, 100.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 700.0, 2000.0, 4800.0, 5800.0, 7500.0, 6200.0, 8800.0, 9800.0, 7300.0, 6000.0, 4100.0, 1300.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 100.0, 600.0, 6400.0, 9800.0, 5400.0, 22000.0, 29800.0, 34600.0, 34400.0, 27500.0, 16100.0, 6300.0, 3500.0, 800.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 400.0, 8400.0, 7500.0, 8500.0, 22200.0, 28400.0, 30500.0, 34800.0, 40100.0, 52300.0, 32100.0, 26000.0, 9800.0, 2100.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1500.0, 5200.0, 6200.0, 8400.0, 10800.0, 10700.0, 10700.0, 12900.0, 14000.0, 10700.0, 14700.0, 7300.0, 3900.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 700.0, 500.0, 4700.0, 3200.0, 2400.0, 2100.0, 2100.0, 3100.0, 2000.0, 1400.0, 2100.0, 400.0, 400.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1200.0, 2100.0, 2600.0, 6900.0, 8100.0, 11100.0, 6500.0, 3000.0, 11400.0, 16600.0, 8100.0, 4700.0, 5000.0, 700.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 100.0, 2300.0, 4300.0, 15000.0, 15100.0, 27600.0, 32000.0, 56800.0, 19500.0, 32900.0, 25600.0, 9600.0, 20500.0, 2500.0, 100.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4200.0, 11100.0, 29600.0, 40300.0, 50900.0, 28700.0, 50700.0, 27300.0, 32500.0, 37200.0, 22900.0, 17800.0, 4000.0, 200.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1400.0, 4600.0, 6900.0, 11400.0, 15900.0, 23200.0, 19200.0, 15300.0, 5200.0, 5200.0, 1100.0, 1200.0, 200.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1700.0, 7700.0, 12500.0, 14000.0, 18700.0, 14500.0, 14300.0, 17900.0, 10400.0, 5900.0, 11400.0, 4200.0, 700.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 100.0, 2500.0, 6000.0, 19200.0, 20500.0, 16900.0, 15900.0, 18400.0, 9800.0, 8100.0, 7400.0, 8500.0, 3600.0, 6900.0, 100.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1700.0, 6000.0, 6400.0, 22200.0, 41100.0, 27600.0, 25900.0, 29600.0, 18500.0, 6900.0, 2500.0, 4000.0, 3900.0, 100.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3600.0, 11800.0, 29000.0, 39600.0, 58800.0, 61400.0, 44100.0, 45200.0, 46000.0, 28000.0, 29900.0, 8200.0, 2700.0, 400.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2600.0, 10400.0, 26400.0, 42400.0, 54500.0, 57900.0, 49900.0, 35700.0, 20600.0, 17300.0, 10700.0, 8500.0, 3900.0, 300.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1400.0, 11900.0, 21100.0, 22900.0, 46500.0, 35400.0, 44000.0, 43200.0, 31300.0, 20700.0, 13300.0, 8500.0, 4100.0, 300.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2100.0, 12700.0, 8700.0, 19600.0, 17900.0, 17800.0, 33400.0, 34900.0, 28400.0, 13700.0, 7700.0, 10900.0, 3000.0, 100.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3200.0, 10600.0, 19700.0, 21300.0, 34300.0, 35200.0, 36900.0, 38900.0, 40000.0, 15700.0, 8400.0, 6900.0, 2800.0, 100.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1500.0, 7600.0, 13000.0, 12000.0, 6000.0, 11000.0, 13900.0, 15300.0, 10200.0, 21100.0, 10200.0, 6100.0, 1300.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 800.0, 900.0, 1000.0, 2000.0, 2400.0, 4400.0, 3200.0, 2000.0, 3300.0, 3000.0, 5700.0, 1000.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 500.0, 2200.0, 1900.0, 3400.0, 4600.0, 5200.0, 3700.0, 3900.0, 400.0, 100.0, 100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 900.0, 6600.0, 100.0, 800.0, 1800.0, 10500.0, 4200.0, 7000.0, 2400.0, 2700.0, 1900.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3100.0, 10400.0, 23800.0, 30300.0, 67400.0, 36400.0, 34800.0, 56300.0, 31600.0, 25100.0, 14500.0, 7700.0, 1300.0, 650.0, 0.0, 0.0, 0.0, 0.0]], 'y_pred': [[0.0, 0.0, 20.0640811920166, 63.65702819824219, 140.0079803466797, 290.428466796875, 345.2232666015625, 346.11529541015625, 346.237060546875, 346.25360107421875, 346.255859375, 346.25616455078125, 346.2562255859375, 346.2562561035156, 346.2562561035156, 346.2562561035156, 346.2562561035156, 346.2562561035156, 346.2562561035156, 346.2562561035156, 346.2562561035156, 346.2562561035156, 346.2562561035156, 346.2562561035156], [0.0, 0.0, 0.0, 12.75796127319336, 49.46540069580078, 123.04344940185547, 285.85198974609375, 345.1412353515625, 346.1039733886719, 346.2355041503906, 346.2533874511719, 346.2558288574219, 346.2561340332031, 346.25616455078125, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594], [0.0, 0.0, 7.462364196777344, 38.650733947753906, 102.4188003540039, 224.11331176757812, 344.1388854980469, 345.98773193359375, 346.2197265625, 346.2512512207031, 346.2554931640625, 346.256103515625, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594], [0.0, 3.82049560546875, 37.401851654052734, 94.55137634277344, 183.9685516357422, 336.0419006347656, 345.751220703125, 346.1874694824219, 346.24688720703125, 346.25494384765625, 346.256103515625, 346.2562255859375, 346.2562561035156, 346.2562561035156, 346.2562561035156, 346.2562561035156, 346.2562561035156, 346.2562561035156, 346.2562561035156, 346.2562561035156, 346.2562561035156, 346.2562561035156, 346.2562561035156, 346.2562561035156], [0.0, 0.0, 3.2053849697113037, 28.33917236328125, 81.55760192871094, 180.12620544433594, 339.65106201171875, 345.8238525390625, 346.1973876953125, 346.2481994628906, 346.255126953125, 346.256103515625, 346.25616455078125, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594], [0.0, 0.0, 0.027554631233215332, 21.42706298828125, 67.99315643310547, 157.140380859375, 329.81695556640625, 345.651123046875, 346.1737976074219, 346.2449951171875, 346.25469970703125, 346.2559509277344, 346.25616455078125, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594], [0.0, 0.0, 3.6028504371643066, 29.659076690673828, 84.96356964111328, 188.87551879882812, 341.617431640625, 345.8678283691406, 346.203369140625, 346.2490234375, 346.2552490234375, 346.256103515625, 346.25616455078125, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594], [0.0, 0.0, 15.809029579162598, 56.03004837036133, 130.031982421875, 275.0645751953125, 345.0453796386719, 346.09130859375, 346.2337951660156, 346.253173828125, 346.2558288574219, 346.25616455078125, 346.2562255859375, 346.2562561035156, 346.2562561035156, 346.2562561035156, 346.2562561035156, 346.2562561035156, 346.2562561035156, 346.2562561035156, 346.2562561035156, 346.2562561035156, 346.2562561035156, 346.2562561035156], [0.0, 0.0, 2.023387908935547, 25.623903274536133, 76.14103698730469, 170.51019287109375, 336.5644836425781, 345.7641906738281, 346.1891784667969, 346.24713134765625, 346.25494384765625, 346.2560729980469, 346.25616455078125, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594], [0.0, 0.0, 12.308218002319336, 48.58616638183594, 118.24775695800781, 251.73886108398438, 344.752197265625, 346.05364990234375, 346.2286682128906, 346.2524719238281, 346.2557373046875, 346.25616455078125, 346.2562255859375, 346.2562561035156, 346.2562561035156, 346.2562561035156, 346.2562561035156, 346.2562561035156, 346.2562561035156, 346.2562561035156, 346.2562561035156, 346.2562561035156, 346.2562561035156, 346.2562561035156], [0.0, 0.0, 19.34929847717285, 62.25060272216797, 137.94000244140625, 286.7092590332031, 345.18670654296875, 346.1103210449219, 346.23638916015625, 346.2535400390625, 346.255859375, 346.25616455078125, 346.2562255859375, 346.2562561035156, 346.2562561035156, 346.2562561035156, 346.2562561035156, 346.2562561035156, 346.2562561035156, 346.2562561035156, 346.2562561035156, 346.2562561035156, 346.2562561035156, 346.2562561035156], [0.0, 0.0, 1.68869948387146, 24.866147994995117, 74.56591033935547, 167.57254028320312, 335.2440185546875, 345.7410583496094, 346.18609619140625, 346.2467041015625, 346.2548828125, 346.25604248046875, 346.25616455078125, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594], [0.0, 0.0, 4.4825334548950195, 31.4836483001709, 88.23684692382812, 194.10009765625, 342.27642822265625, 345.8928527832031, 346.206787109375, 346.2494812011719, 346.2552795410156, 346.256103515625, 346.25616455078125, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594], [0.0, 0.0, 14.732248306274414, 53.39332962036133, 125.39132690429688, 264.6118469238281, 344.92999267578125, 346.0761413574219, 346.23175048828125, 346.2528991699219, 346.2557678222656, 346.25616455078125, 346.2562255859375, 346.2562561035156, 346.2562561035156, 346.2562561035156, 346.2562561035156, 346.2562561035156, 346.2562561035156, 346.2562561035156, 346.2562561035156, 346.2562561035156, 346.2562561035156, 346.2562561035156], [0.0, 0.0, 0.6492988467216492, 22.532421112060547, 69.78367614746094, 159.06591796875, 330.43695068359375, 345.6697082519531, 346.1763610839844, 346.245361328125, 346.2547912597656, 346.2559814453125, 346.25616455078125, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594], [0.0, 0.0, 0.0, 21.463882446289062, 68.64006042480469, 159.9249725341797, 332.4055480957031, 345.67510986328125, 346.1770935058594, 346.24542236328125, 346.2547912597656, 346.2560119628906, 346.25616455078125, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594], [0.0, 0.0, 8.970388412475586, 41.61384201049805, 107.02384948730469, 230.9447479248047, 344.35040283203125, 346.00927734375, 346.2226257324219, 346.2516784667969, 346.2555847167969, 346.2561340332031, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594], [0.0, 0.0, 3.3652358055114746, 28.905385971069336, 83.12374877929688, 184.34912109375, 340.7604675292969, 345.8474426269531, 346.20062255859375, 346.24859619140625, 346.2551574707031, 346.256103515625, 346.25616455078125, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594], [0.0, 0.0, 15.798051834106445, 56.31826400756836, 130.96466064453125, 278.02850341796875, 345.06787109375, 346.09423828125, 346.2342529296875, 346.2532043457031, 346.25579833984375, 346.25616455078125, 346.2562255859375, 346.2562561035156, 346.2562561035156, 346.2562561035156, 346.2562561035156, 346.2562561035156, 346.2562561035156, 346.2562561035156, 346.2562561035156, 346.2562561035156, 346.2562561035156, 346.2562561035156], [0.0, 0.0, 15.383291244506836, 54.39817428588867, 126.43968963623047, 265.3934631347656, 344.9460144042969, 346.0782775878906, 346.23199462890625, 346.2529602050781, 346.2557678222656, 346.25616455078125, 346.2562255859375, 346.2562561035156, 346.2562561035156, 346.2562561035156, 346.2562561035156, 346.2562561035156, 346.2562561035156, 346.2562561035156, 346.2562561035156, 346.2562561035156, 346.2562561035156, 346.2562561035156], [0.0, 0.0, 4.8553056716918945, 31.850522994995117, 88.13336944580078, 191.5717315673828, 341.829833984375, 345.8835144042969, 346.20550537109375, 346.24932861328125, 346.2552490234375, 346.256103515625, 346.25616455078125, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594], [0.0, 0.0, 0.854549765586853, 23.22934341430664, 71.64884185791016, 163.52734375, 333.6234436035156, 345.7062683105469, 346.18133544921875, 346.24603271484375, 346.25482177734375, 346.25604248046875, 346.25616455078125, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594], [0.0, 0.0, 11.121532440185547, 45.90814971923828, 113.6546401977539, 241.99749755859375, 344.5939636230469, 346.03533935546875, 346.2262268066406, 346.2521057128906, 346.2557067871094, 346.25616455078125, 346.2562255859375, 346.2562561035156, 346.2562561035156, 346.2562561035156, 346.2562561035156, 346.2562561035156, 346.2562561035156, 346.2562561035156, 346.2562561035156, 346.2562561035156, 346.2562561035156, 346.2562561035156], [0.0, 0.0, 9.255006790161133, 41.30160140991211, 104.92156982421875, 221.9521026611328, 344.1142883300781, 345.99310302734375, 346.2204284667969, 346.2513732910156, 346.2555236816406, 346.256103515625, 346.2562255859375, 346.2562561035156, 346.2562561035156, 346.2562561035156, 346.2562561035156, 346.2562561035156, 346.2562561035156, 346.2562561035156, 346.2562561035156, 346.2562561035156, 346.2562561035156, 346.2562561035156], [0.0, 0.0, 0.10491883754730225, 21.703588485717773, 68.7420883178711, 158.9622344970703, 331.2754211425781, 345.6678771972656, 346.1761169433594, 346.24530029296875, 346.2547302246094, 346.2559814453125, 346.25616455078125, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594], [0.0, 0.0, 2.328372001647949, 26.91338539123535, 79.76103210449219, 180.10675048828125, 340.0373229980469, 345.8189697265625, 346.19671630859375, 346.2481384277344, 346.2550964355469, 346.2560729980469, 346.25616455078125, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594], [0.0, 0.0, 4.213365077972412, 30.845949172973633, 86.96846008300781, 191.5982666015625, 341.9607849121094, 345.88287353515625, 346.2054443359375, 346.24932861328125, 346.2552795410156, 346.256103515625, 346.25616455078125, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594], [0.0, 0.0, 7.769198894500732, 38.811317443847656, 101.82439422607422, 219.90188598632812, 344.0282287597656, 345.982421875, 346.218994140625, 346.25115966796875, 346.2554931640625, 346.256103515625, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594], [0.0, 0.0, 18.697956085205078, 61.7952766418457, 138.44435119628906, 289.90667724609375, 345.20587158203125, 346.1129150390625, 346.2367248535156, 346.2535705566406, 346.255859375, 346.25616455078125, 346.2562255859375, 346.2562561035156, 346.2562561035156, 346.2562561035156, 346.2562561035156, 346.2562561035156, 346.2562561035156, 346.2562561035156, 346.2562561035156, 346.2562561035156, 346.2562561035156, 346.2562561035156], [0.0, 0.0, 1.0487775802612305, 23.490442276000977, 71.88530731201172, 163.1374969482422, 333.10089111328125, 345.7063903808594, 346.1813659667969, 346.24603271484375, 346.25482177734375, 346.25604248046875, 346.25616455078125, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594], [0.0, 0.0, 4.490981101989746, 31.610326766967773, 88.67073059082031, 195.51873779296875, 342.45965576171875, 345.898193359375, 346.20751953125, 346.2496032714844, 346.2552795410156, 346.256103515625, 346.25616455078125, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594], [0.0, 0.0, 3.0539445877075195, 28.215856552124023, 81.78727722167969, 181.98712158203125, 340.277099609375, 345.83465576171875, 346.1988525390625, 346.2484130859375, 346.255126953125, 346.256103515625, 346.25616455078125, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594], [0.0, 0.0, 4.585934638977051, 31.727886199951172, 88.74083709716797, 195.12977600097656, 342.4042663574219, 345.8977966308594, 346.2074279785156, 346.24957275390625, 346.2552795410156, 346.256103515625, 346.25616455078125, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594], [0.0, 0.0, 14.623857498168945, 53.59416961669922, 126.35566711425781, 268.2043151855469, 344.96484375, 346.08062744140625, 346.2322998046875, 346.2529602050781, 346.2557678222656, 346.25616455078125, 346.2562255859375, 346.2562561035156, 346.2562561035156, 346.2562561035156, 346.2562561035156, 346.2562561035156, 346.2562561035156, 346.2562561035156, 346.2562561035156, 346.2562561035156, 346.2562561035156, 346.2562561035156], [0.0, 0.0, 9.424931526184082, 41.87892150878906, 106.2586898803711, 225.6141815185547, 344.2234191894531, 346.00042724609375, 346.221435546875, 346.25146484375, 346.2555236816406, 346.256103515625, 346.2562255859375, 346.2562561035156, 346.2562561035156, 346.2562561035156, 346.2562561035156, 346.2562561035156, 346.2562561035156, 346.2562561035156, 346.2562561035156, 346.2562561035156, 346.2562561035156, 346.2562561035156], [0.0, 0.0, 8.575197219848633, 40.0832633972168, 103.22093963623047, 219.9293212890625, 344.0353698730469, 345.9857482910156, 346.21942138671875, 346.2512512207031, 346.2554931640625, 346.256103515625, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594], [0.0, 0.0, 6.736602783203125, 35.991451263427734, 95.82391357421875, 205.6874237060547, 343.2889709472656, 345.94122314453125, 346.21337890625, 346.2503662109375, 346.25543212890625, 346.256103515625, 346.25616455078125, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594], [0.0, 0.0, 6.216302871704102, 34.968257904052734, 94.1647720336914, 203.26104736328125, 343.1109313964844, 345.93096923828125, 346.2119445800781, 346.2502136230469, 346.25543212890625, 346.256103515625, 346.25616455078125, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594], [0.0, 0.0, 5.785564422607422, 33.84836959838867, 91.79263305664062, 197.9809112548828, 342.6138610839844, 345.9122314453125, 346.20941162109375, 346.2498474121094, 346.25537109375, 346.256103515625, 346.25616455078125, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594], [0.0, 0.0, 2.803715467453003, 27.42904281616211, 79.8390884399414, 177.36624145507812, 338.9607238769531, 345.80859375, 346.1953125, 346.2479553222656, 346.2550964355469, 346.2560729980469, 346.25616455078125, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594], [0.0, 0.0, 1.3895865678787231, 24.626636505126953, 74.84127044677734, 170.19937133789062, 336.941650390625, 345.7585144042969, 346.1884765625, 346.2469787597656, 346.25494384765625, 346.2560729980469, 346.25616455078125, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594], [0.0, 0.0, 4.3032941818237305, 31.292457580566406, 88.26351928710938, 195.46876525878906, 342.4656982421875, 345.89569091796875, 346.2071533203125, 346.24957275390625, 346.2552795410156, 346.256103515625, 346.25616455078125, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594, 346.2561950683594]], 'exp_name': 'solar power prediction using weather features', 'plant': 126, 'spot': 174, 'start_date': '20190820', 'end_date': '20200809', 'batch_size': 64, 'x_frames': 3, 'y_frames': 1, 'hid_dim': 256, 'optim': 'RMSprop', 'activation': 'relu', 'lss': 'MSE', 'lr': 0.001, 'epochs': 256, 'early_stop': 30, 'evaluation': 'NRMSE', 'features': \"[<FeatureType.SUNSHINE: '일조(hr)'>, <FeatureType.HUMIDITY: '습도(%)'>]\"}\n",
      "\n",
      "Namespace(activation='relu', batch_size=64, early_stop=30, end_date='20200809', epochs=256, evaluation='NRMSE', exp_name='solar power prediction using weather features', features=\"[<FeatureType.SUNSHINE: '일조(hr)'>, <FeatureType.HUMIDITY: '습도(%)'>, <FeatureType.WIND_SPEED: '풍속(m/s)'>]\", hid_dim=256, lr=0.001, lss='MSE', optim='RMSprop', plant=126, spot=174, start_date='20190820', x_frames=3, y_frames=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/256\n",
      "5/5 [==============================] - 0s 97ms/step - loss: 1316903168.0000 - accuracy: 0.2090 - val_loss: 855066432.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1316456064.0000 - accuracy: 0.0000e+00 - val_loss: 854943232.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1316359808.0000 - accuracy: 0.0000e+00 - val_loss: 854880448.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/256\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1316302336.0000 - accuracy: 0.0000e+00 - val_loss: 854832768.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1316256000.0000 - accuracy: 0.0000e+00 - val_loss: 854785536.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1316209920.0000 - accuracy: 0.0000e+00 - val_loss: 854740608.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1316165504.0000 - accuracy: 0.0000e+00 - val_loss: 854699328.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1316124032.0000 - accuracy: 0.0000e+00 - val_loss: 854657024.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1316081408.0000 - accuracy: 0.0000e+00 - val_loss: 854611968.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1316036992.0000 - accuracy: 0.0000e+00 - val_loss: 854567808.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315993344.0000 - accuracy: 0.0000e+00 - val_loss: 854523584.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315949696.0000 - accuracy: 0.0000e+00 - val_loss: 854479616.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315906048.0000 - accuracy: 0.0000e+00 - val_loss: 854435136.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1315862144.0000 - accuracy: 0.0000e+00 - val_loss: 854391168.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315818368.0000 - accuracy: 0.0000e+00 - val_loss: 854350784.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315778176.0000 - accuracy: 0.0000e+00 - val_loss: 854309632.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315736576.0000 - accuracy: 0.0000e+00 - val_loss: 854264704.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315692416.0000 - accuracy: 0.0000e+00 - val_loss: 854225280.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315652736.0000 - accuracy: 0.0000e+00 - val_loss: 854183936.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315614592.0000 - accuracy: 0.0000e+00 - val_loss: 854848192.0000 - val_accuracy: 0.0417\n",
      "Epoch 21/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315736960.0000 - accuracy: 0.0112 - val_loss: 854100928.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315528576.0000 - accuracy: 0.0000e+00 - val_loss: 854058688.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1315486720.0000 - accuracy: 0.0000e+00 - val_loss: 854011328.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315440384.0000 - accuracy: 0.0000e+00 - val_loss: 853968576.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315397760.0000 - accuracy: 0.0000e+00 - val_loss: 853927616.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315356672.0000 - accuracy: 0.0000e+00 - val_loss: 853882112.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315311360.0000 - accuracy: 0.0000e+00 - val_loss: 853835648.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315266432.0000 - accuracy: 0.0000e+00 - val_loss: 853793152.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315223680.0000 - accuracy: 0.0000e+00 - val_loss: 853752768.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315182720.0000 - accuracy: 0.0000e+00 - val_loss: 853708480.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315138688.0000 - accuracy: 0.0000e+00 - val_loss: 853665088.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1315095552.0000 - accuracy: 0.0000e+00 - val_loss: 853621120.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315051776.0000 - accuracy: 0.0000e+00 - val_loss: 853577920.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315009024.0000 - accuracy: 0.0000e+00 - val_loss: 853534848.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314965760.0000 - accuracy: 0.0000e+00 - val_loss: 853492096.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314922880.0000 - accuracy: 0.0000e+00 - val_loss: 853447808.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314878848.0000 - accuracy: 0.0000e+00 - val_loss: 853400704.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314832640.0000 - accuracy: 0.0000e+00 - val_loss: 853358720.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314790528.0000 - accuracy: 0.0000e+00 - val_loss: 853312832.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314745600.0000 - accuracy: 0.0000e+00 - val_loss: 853272384.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314702336.0000 - accuracy: 0.0000e+00 - val_loss: 853226432.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314658944.0000 - accuracy: 0.0000e+00 - val_loss: 853178240.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314612352.0000 - accuracy: 0.0000e+00 - val_loss: 853139072.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314572672.0000 - accuracy: 0.0000e+00 - val_loss: 853094912.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314528384.0000 - accuracy: 0.0000e+00 - val_loss: 853046784.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314481920.0000 - accuracy: 0.0000e+00 - val_loss: 853006848.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314441728.0000 - accuracy: 0.0000e+00 - val_loss: 852964672.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314399616.0000 - accuracy: 0.0000e+00 - val_loss: 852920704.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314355840.0000 - accuracy: 0.0000e+00 - val_loss: 852881280.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 11ms/step - loss: 1314316032.0000 - accuracy: 0.0000e+00 - val_loss: 852836224.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1314272000.0000 - accuracy: 0.0000e+00 - val_loss: 852794624.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314229888.0000 - accuracy: 0.0000e+00 - val_loss: 852751424.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314186752.0000 - accuracy: 0.0000e+00 - val_loss: 852704320.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314140672.0000 - accuracy: 0.0000e+00 - val_loss: 852662464.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314099072.0000 - accuracy: 0.0000e+00 - val_loss: 852619072.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1314055552.0000 - accuracy: 0.0000e+00 - val_loss: 852573504.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314010368.0000 - accuracy: 0.0000e+00 - val_loss: 852530496.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313967872.0000 - accuracy: 0.0000e+00 - val_loss: 852488064.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313925376.0000 - accuracy: 0.0000e+00 - val_loss: 852442752.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313880704.0000 - accuracy: 0.0000e+00 - val_loss: 852398976.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1313836928.0000 - accuracy: 0.0000e+00 - val_loss: 852356992.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313795200.0000 - accuracy: 0.0000e+00 - val_loss: 852316480.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313753984.0000 - accuracy: 0.0000e+00 - val_loss: 852267584.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313707008.0000 - accuracy: 0.0000e+00 - val_loss: 852227776.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313667328.0000 - accuracy: 0.0072 - val_loss: 852187008.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313625728.0000 - accuracy: 0.0000e+00 - val_loss: 852145088.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313584128.0000 - accuracy: 0.0000e+00 - val_loss: 852099776.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313539200.0000 - accuracy: 0.0000e+00 - val_loss: 852058432.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313497344.0000 - accuracy: 0.0000e+00 - val_loss: 852011392.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1313451520.0000 - accuracy: 0.0000e+00 - val_loss: 851968576.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313408768.0000 - accuracy: 0.0000e+00 - val_loss: 851927552.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313367680.0000 - accuracy: 0.0000e+00 - val_loss: 851882368.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313322880.0000 - accuracy: 0.0000e+00 - val_loss: 851836800.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313277312.0000 - accuracy: 0.0000e+00 - val_loss: 851790720.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313232256.0000 - accuracy: 0.0000e+00 - val_loss: 851752256.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1313193600.0000 - accuracy: 0.0000e+00 - val_loss: 851707904.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313149312.0000 - accuracy: 0.0000e+00 - val_loss: 851663424.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313105280.0000 - accuracy: 0.0000e+00 - val_loss: 851620736.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313062784.0000 - accuracy: 0.0000e+00 - val_loss: 851574784.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1313017472.0000 - accuracy: 0.0000e+00 - val_loss: 851533248.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312976256.0000 - accuracy: 0.0000e+00 - val_loss: 851490112.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312933632.0000 - accuracy: 1.5723e-04 - val_loss: 851447040.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312890112.0000 - accuracy: 0.0000e+00 - val_loss: 851404032.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312847360.0000 - accuracy: 0.0000e+00 - val_loss: 851358016.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312802304.0000 - accuracy: 0.0099 - val_loss: 851317632.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312761344.0000 - accuracy: 0.0000e+00 - val_loss: 851271680.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312716032.0000 - accuracy: 0.0000e+00 - val_loss: 851228352.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312673152.0000 - accuracy: 0.0000e+00 - val_loss: 851184896.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1312629760.0000 - accuracy: 0.0000e+00 - val_loss: 851139456.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312585088.0000 - accuracy: 0.0000e+00 - val_loss: 851096448.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312542208.0000 - accuracy: 0.0000e+00 - val_loss: 851054400.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312500480.0000 - accuracy: 0.0000e+00 - val_loss: 851011904.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312485120.0000 - accuracy: 0.0623 - val_loss: 850968192.0000 - val_accuracy: 0.0417\n",
      "Epoch 94/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312414592.0000 - accuracy: 0.0415 - val_loss: 850922240.0000 - val_accuracy: 0.0417\n",
      "Epoch 95/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312369152.0000 - accuracy: 0.0415 - val_loss: 850876800.0000 - val_accuracy: 0.0417\n",
      "Epoch 96/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312324352.0000 - accuracy: 0.0415 - val_loss: 850835328.0000 - val_accuracy: 0.0417\n",
      "Epoch 97/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312282752.0000 - accuracy: 0.0415 - val_loss: 850789312.0000 - val_accuracy: 0.0417\n",
      "Epoch 98/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312237568.0000 - accuracy: 0.0415 - val_loss: 850746816.0000 - val_accuracy: 0.0417\n",
      "Epoch 99/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1312194944.0000 - accuracy: 0.0415 - val_loss: 850704384.0000 - val_accuracy: 0.0417\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312152576.0000 - accuracy: 0.0415 - val_loss: 850662144.0000 - val_accuracy: 0.0417\n",
      "Epoch 101/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312110592.0000 - accuracy: 0.0415 - val_loss: 850616512.0000 - val_accuracy: 0.0417\n",
      "Epoch 102/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312065408.0000 - accuracy: 0.0415 - val_loss: 850574784.0000 - val_accuracy: 0.0417\n",
      "Epoch 103/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312023936.0000 - accuracy: 0.0415 - val_loss: 850531392.0000 - val_accuracy: 0.0417\n",
      "Epoch 104/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311980672.0000 - accuracy: 0.0415 - val_loss: 850488640.0000 - val_accuracy: 0.0417\n",
      "Epoch 105/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311938176.0000 - accuracy: 0.0415 - val_loss: 850444864.0000 - val_accuracy: 0.0417\n",
      "Epoch 106/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311894656.0000 - accuracy: 0.0415 - val_loss: 850402240.0000 - val_accuracy: 0.0417\n",
      "Epoch 107/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311851776.0000 - accuracy: 0.0415 - val_loss: 850354176.0000 - val_accuracy: 0.0417\n",
      "Epoch 108/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1311805312.0000 - accuracy: 0.0415 - val_loss: 850312832.0000 - val_accuracy: 0.0417\n",
      "Epoch 109/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311763712.0000 - accuracy: 0.0415 - val_loss: 850269824.0000 - val_accuracy: 0.0417\n",
      "Epoch 110/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311721344.0000 - accuracy: 0.0415 - val_loss: 850228736.0000 - val_accuracy: 0.0417\n",
      "Epoch 111/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311679744.0000 - accuracy: 0.0415 - val_loss: 850186752.0000 - val_accuracy: 0.0417\n",
      "Epoch 112/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311637888.0000 - accuracy: 0.0415 - val_loss: 850139840.0000 - val_accuracy: 0.0417\n",
      "Epoch 113/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311591680.0000 - accuracy: 0.0415 - val_loss: 850097088.0000 - val_accuracy: 0.0417\n",
      "Epoch 114/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311549056.0000 - accuracy: 0.0321 - val_loss: 850055680.0000 - val_accuracy: 0.0417\n",
      "Epoch 115/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311508096.0000 - accuracy: 0.0415 - val_loss: 850012288.0000 - val_accuracy: 0.0417\n",
      "Epoch 116/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311464192.0000 - accuracy: 0.0316 - val_loss: 849967488.0000 - val_accuracy: 0.0417\n",
      "Epoch 117/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311420544.0000 - accuracy: 0.0415 - val_loss: 849925952.0000 - val_accuracy: 0.0417\n",
      "Epoch 118/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1311378688.0000 - accuracy: 0.0414 - val_loss: 849881600.0000 - val_accuracy: 0.0417\n",
      "Epoch 119/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311334272.0000 - accuracy: 0.0336 - val_loss: 849835520.0000 - val_accuracy: 0.0417\n",
      "Epoch 120/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311289472.0000 - accuracy: 0.0388 - val_loss: 849793536.0000 - val_accuracy: 0.0417\n",
      "Epoch 121/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311247104.0000 - accuracy: 0.0415 - val_loss: 849749888.0000 - val_accuracy: 0.0417\n",
      "Epoch 122/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311203712.0000 - accuracy: 0.0415 - val_loss: 849707008.0000 - val_accuracy: 0.0417\n",
      "Epoch 123/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311160704.0000 - accuracy: 0.0388 - val_loss: 849660864.0000 - val_accuracy: 0.0417\n",
      "Epoch 124/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312344448.0000 - accuracy: 0.1028 - val_loss: 849623616.0000 - val_accuracy: 0.0417\n",
      "Epoch 125/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311079040.0000 - accuracy: 0.0423 - val_loss: 849581504.0000 - val_accuracy: 0.0417\n",
      "Epoch 126/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311036672.0000 - accuracy: 0.0420 - val_loss: 849534592.0000 - val_accuracy: 0.0417\n",
      "Epoch 127/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1310990464.0000 - accuracy: 0.0417 - val_loss: 849490048.0000 - val_accuracy: 0.0417\n",
      "Epoch 128/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310946432.0000 - accuracy: 0.0409 - val_loss: 849448640.0000 - val_accuracy: 0.0417\n",
      "Epoch 129/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310904704.0000 - accuracy: 0.0414 - val_loss: 849402176.0000 - val_accuracy: 0.0417\n",
      "Epoch 130/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310859136.0000 - accuracy: 0.0412 - val_loss: 849360000.0000 - val_accuracy: 0.0417\n",
      "Epoch 131/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310817024.0000 - accuracy: 0.0393 - val_loss: 849317376.0000 - val_accuracy: 0.0417\n",
      "Epoch 132/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310774656.0000 - accuracy: 0.0407 - val_loss: 849276736.0000 - val_accuracy: 0.0417\n",
      "Epoch 133/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310733440.0000 - accuracy: 0.0388 - val_loss: 849232832.0000 - val_accuracy: 0.0417\n",
      "Epoch 134/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310690048.0000 - accuracy: 0.0406 - val_loss: 849189376.0000 - val_accuracy: 0.0417\n",
      "Epoch 135/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310646656.0000 - accuracy: 0.0395 - val_loss: 849145344.0000 - val_accuracy: 0.0417\n",
      "Epoch 136/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310603264.0000 - accuracy: 0.0414 - val_loss: 849098752.0000 - val_accuracy: 0.0417\n",
      "Epoch 137/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1310557440.0000 - accuracy: 0.0414 - val_loss: 849056704.0000 - val_accuracy: 0.0417\n",
      "Epoch 138/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310515072.0000 - accuracy: 0.0414 - val_loss: 849011840.0000 - val_accuracy: 0.0417\n",
      "Epoch 139/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310470656.0000 - accuracy: 0.0412 - val_loss: 848970048.0000 - val_accuracy: 0.0417\n",
      "Epoch 140/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310428672.0000 - accuracy: 0.0407 - val_loss: 848927872.0000 - val_accuracy: 0.0417\n",
      "Epoch 141/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310386816.0000 - accuracy: 0.0447 - val_loss: 848882624.0000 - val_accuracy: 0.0417\n",
      "Epoch 142/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310342784.0000 - accuracy: 0.0415 - val_loss: 848842944.0000 - val_accuracy: 0.0417\n",
      "Epoch 143/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310301824.0000 - accuracy: 0.0415 - val_loss: 848800896.0000 - val_accuracy: 0.0417\n",
      "Epoch 144/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310260736.0000 - accuracy: 0.0415 - val_loss: 848757120.0000 - val_accuracy: 0.0417\n",
      "Epoch 145/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1310216832.0000 - accuracy: 0.0415 - val_loss: 848714816.0000 - val_accuracy: 0.0417\n",
      "Epoch 146/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1310174720.0000 - accuracy: 0.0418 - val_loss: 848667776.0000 - val_accuracy: 0.0417\n",
      "Epoch 147/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310421760.0000 - accuracy: 0.0566 - val_loss: 854568256.0000 - val_accuracy: 0.3403\n",
      "Epoch 148/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311099264.0000 - accuracy: 0.1267 - val_loss: 848592000.0000 - val_accuracy: 0.0417\n",
      "Epoch 149/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310052096.0000 - accuracy: 0.0415 - val_loss: 848543552.0000 - val_accuracy: 0.0417\n",
      "Epoch 150/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310004992.0000 - accuracy: 0.0415 - val_loss: 848501120.0000 - val_accuracy: 0.0417\n",
      "Epoch 151/256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 11ms/step - loss: 1309962240.0000 - accuracy: 0.0415 - val_loss: 848456960.0000 - val_accuracy: 0.0417\n",
      "Epoch 152/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309918720.0000 - accuracy: 0.0415 - val_loss: 848412480.0000 - val_accuracy: 0.0417\n",
      "Epoch 153/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309874304.0000 - accuracy: 0.0415 - val_loss: 848365952.0000 - val_accuracy: 0.0417\n",
      "Epoch 154/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309828992.0000 - accuracy: 0.0415 - val_loss: 848325888.0000 - val_accuracy: 0.0417\n",
      "Epoch 155/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309788672.0000 - accuracy: 0.0415 - val_loss: 848285120.0000 - val_accuracy: 0.0417\n",
      "Epoch 156/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1309748096.0000 - accuracy: 0.0415 - val_loss: 848244160.0000 - val_accuracy: 0.0417\n",
      "Epoch 157/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309706624.0000 - accuracy: 0.0415 - val_loss: 848197120.0000 - val_accuracy: 0.0417\n",
      "Epoch 158/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309660928.0000 - accuracy: 0.0415 - val_loss: 848154240.0000 - val_accuracy: 0.0417\n",
      "Epoch 159/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309618560.0000 - accuracy: 0.0415 - val_loss: 848111936.0000 - val_accuracy: 0.0417\n",
      "Epoch 160/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309576448.0000 - accuracy: 0.0415 - val_loss: 848067840.0000 - val_accuracy: 0.0417\n",
      "Epoch 161/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1309532672.0000 - accuracy: 0.0415 - val_loss: 848027776.0000 - val_accuracy: 0.0417\n",
      "Epoch 162/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309491968.0000 - accuracy: 0.0415 - val_loss: 847982208.0000 - val_accuracy: 0.0417\n",
      "Epoch 163/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309447424.0000 - accuracy: 0.0415 - val_loss: 847939200.0000 - val_accuracy: 0.0417\n",
      "Epoch 164/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309404416.0000 - accuracy: 0.0415 - val_loss: 847893248.0000 - val_accuracy: 0.0417\n",
      "Epoch 165/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1309359616.0000 - accuracy: 0.0415 - val_loss: 847851008.0000 - val_accuracy: 0.0417\n",
      "Epoch 166/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309317248.0000 - accuracy: 0.0415 - val_loss: 847804096.0000 - val_accuracy: 0.0417\n",
      "Epoch 167/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309271296.0000 - accuracy: 0.0415 - val_loss: 847764608.0000 - val_accuracy: 0.0417\n",
      "Epoch 168/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309231872.0000 - accuracy: 0.0415 - val_loss: 847726464.0000 - val_accuracy: 0.0417\n",
      "Epoch 169/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309192320.0000 - accuracy: 0.0415 - val_loss: 847684352.0000 - val_accuracy: 0.0417\n",
      "Epoch 170/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309150592.0000 - accuracy: 0.0415 - val_loss: 847636352.0000 - val_accuracy: 0.0417\n",
      "Epoch 171/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309104000.0000 - accuracy: 0.0415 - val_loss: 847592704.0000 - val_accuracy: 0.0417\n",
      "Epoch 172/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309060480.0000 - accuracy: 0.0415 - val_loss: 847551808.0000 - val_accuracy: 0.0417\n",
      "Epoch 173/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309019520.0000 - accuracy: 0.0415 - val_loss: 847507328.0000 - val_accuracy: 0.0417\n",
      "Epoch 174/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308976000.0000 - accuracy: 0.0415 - val_loss: 847466624.0000 - val_accuracy: 0.0417\n",
      "Epoch 175/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1308934912.0000 - accuracy: 0.0415 - val_loss: 847420736.0000 - val_accuracy: 0.0417\n",
      "Epoch 176/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308889600.0000 - accuracy: 0.0415 - val_loss: 847377536.0000 - val_accuracy: 0.0417\n",
      "Epoch 177/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308846848.0000 - accuracy: 0.0415 - val_loss: 847336384.0000 - val_accuracy: 0.0417\n",
      "Epoch 178/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308805888.0000 - accuracy: 0.0415 - val_loss: 847293184.0000 - val_accuracy: 0.0417\n",
      "Epoch 179/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308762752.0000 - accuracy: 0.0415 - val_loss: 847253120.0000 - val_accuracy: 0.0417\n",
      "Epoch 180/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308722688.0000 - accuracy: 0.0415 - val_loss: 847210880.0000 - val_accuracy: 0.0417\n",
      "Epoch 181/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308680704.0000 - accuracy: 0.0415 - val_loss: 847165312.0000 - val_accuracy: 0.0417\n",
      "Epoch 182/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308635392.0000 - accuracy: 0.0415 - val_loss: 847119232.0000 - val_accuracy: 0.0417\n",
      "Epoch 183/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308590464.0000 - accuracy: 0.0415 - val_loss: 847075328.0000 - val_accuracy: 0.0417\n",
      "Epoch 184/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1308546048.0000 - accuracy: 0.0415 - val_loss: 847031552.0000 - val_accuracy: 0.0417\n",
      "Epoch 185/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308503296.0000 - accuracy: 0.0415 - val_loss: 846990208.0000 - val_accuracy: 0.0417\n",
      "Epoch 186/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308461568.0000 - accuracy: 0.0415 - val_loss: 846944640.0000 - val_accuracy: 0.0417\n",
      "Epoch 187/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308416640.0000 - accuracy: 0.0415 - val_loss: 846897856.0000 - val_accuracy: 0.0417\n",
      "Epoch 188/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308370944.0000 - accuracy: 0.0415 - val_loss: 846856384.0000 - val_accuracy: 0.0417\n",
      "Epoch 189/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308329344.0000 - accuracy: 0.0415 - val_loss: 846813312.0000 - val_accuracy: 0.0417\n",
      "Epoch 190/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1308286208.0000 - accuracy: 0.0415 - val_loss: 846771264.0000 - val_accuracy: 0.0417\n",
      "Epoch 191/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308244096.0000 - accuracy: 0.0415 - val_loss: 846728064.0000 - val_accuracy: 0.0417\n",
      "Epoch 192/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308202752.0000 - accuracy: 0.0514 - val_loss: 846685120.0000 - val_accuracy: 0.0417\n",
      "Epoch 193/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308158592.0000 - accuracy: 0.0415 - val_loss: 846643712.0000 - val_accuracy: 0.0417\n",
      "Epoch 194/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1308117632.0000 - accuracy: 0.0415 - val_loss: 846599680.0000 - val_accuracy: 0.0417\n",
      "Epoch 195/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308074368.0000 - accuracy: 0.0415 - val_loss: 846560128.0000 - val_accuracy: 0.0417\n",
      "Epoch 196/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308034048.0000 - accuracy: 0.0415 - val_loss: 846516032.0000 - val_accuracy: 0.0417\n",
      "Epoch 197/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307990016.0000 - accuracy: 0.0415 - val_loss: 846472128.0000 - val_accuracy: 0.0417\n",
      "Epoch 198/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307946368.0000 - accuracy: 0.0415 - val_loss: 846430720.0000 - val_accuracy: 0.0417\n",
      "Epoch 199/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307904640.0000 - accuracy: 0.0415 - val_loss: 846390720.0000 - val_accuracy: 0.0417\n",
      "Epoch 200/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307864960.0000 - accuracy: 0.0473 - val_loss: 846345728.0000 - val_accuracy: 0.0417\n",
      "Epoch 201/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307820800.0000 - accuracy: 0.0415 - val_loss: 846301760.0000 - val_accuracy: 0.0417\n",
      "Epoch 202/256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 11ms/step - loss: 1307776640.0000 - accuracy: 0.0415 - val_loss: 846255424.0000 - val_accuracy: 0.0417\n",
      "Epoch 203/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1307730816.0000 - accuracy: 0.0415 - val_loss: 846213120.0000 - val_accuracy: 0.0417\n",
      "Epoch 204/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307688960.0000 - accuracy: 0.0415 - val_loss: 846173248.0000 - val_accuracy: 0.0417\n",
      "Epoch 205/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307648512.0000 - accuracy: 0.0415 - val_loss: 846126720.0000 - val_accuracy: 0.0417\n",
      "Epoch 206/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307603456.0000 - accuracy: 0.0415 - val_loss: 846083200.0000 - val_accuracy: 0.0417\n",
      "Epoch 207/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307559936.0000 - accuracy: 0.0415 - val_loss: 846040704.0000 - val_accuracy: 0.0417\n",
      "Epoch 208/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307517312.0000 - accuracy: 0.0415 - val_loss: 845997312.0000 - val_accuracy: 0.0417\n",
      "Epoch 209/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307474944.0000 - accuracy: 0.0415 - val_loss: 845954880.0000 - val_accuracy: 0.0417\n",
      "Epoch 210/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307432576.0000 - accuracy: 0.0415 - val_loss: 845906624.0000 - val_accuracy: 0.0417\n",
      "Epoch 211/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307384704.0000 - accuracy: 0.0415 - val_loss: 845861824.0000 - val_accuracy: 0.0417\n",
      "Epoch 212/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307340800.0000 - accuracy: 0.0415 - val_loss: 845824192.0000 - val_accuracy: 0.0417\n",
      "Epoch 213/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1307303040.0000 - accuracy: 0.0415 - val_loss: 845783616.0000 - val_accuracy: 0.0417\n",
      "Epoch 214/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307262592.0000 - accuracy: 0.0415 - val_loss: 845743040.0000 - val_accuracy: 0.0417\n",
      "Epoch 215/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307221632.0000 - accuracy: 0.0415 - val_loss: 845697152.0000 - val_accuracy: 0.0417\n",
      "Epoch 216/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307176576.0000 - accuracy: 0.0415 - val_loss: 845655488.0000 - val_accuracy: 0.0417\n",
      "Epoch 217/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307134848.0000 - accuracy: 0.0415 - val_loss: 845616448.0000 - val_accuracy: 0.0417\n",
      "Epoch 218/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307094144.0000 - accuracy: 0.0415 - val_loss: 845575808.0000 - val_accuracy: 0.0417\n",
      "Epoch 219/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307052160.0000 - accuracy: 0.0415 - val_loss: 845526912.0000 - val_accuracy: 0.0417\n",
      "Epoch 220/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307005056.0000 - accuracy: 0.0415 - val_loss: 845481408.0000 - val_accuracy: 0.0417\n",
      "Epoch 221/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306961792.0000 - accuracy: 0.0415 - val_loss: 845438400.0000 - val_accuracy: 0.0417\n",
      "Epoch 222/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1306920064.0000 - accuracy: 0.0415 - val_loss: 845394496.0000 - val_accuracy: 0.0417\n",
      "Epoch 223/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306875904.0000 - accuracy: 0.0415 - val_loss: 845349184.0000 - val_accuracy: 0.0417\n",
      "Epoch 224/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306830464.0000 - accuracy: 0.0415 - val_loss: 845306944.0000 - val_accuracy: 0.0417\n",
      "Epoch 225/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306786560.0000 - accuracy: 0.0417 - val_loss: 845266176.0000 - val_accuracy: 0.0417\n",
      "Epoch 226/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306744704.0000 - accuracy: 0.0415 - val_loss: 845220800.0000 - val_accuracy: 0.0417\n",
      "Epoch 227/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306702208.0000 - accuracy: 0.0415 - val_loss: 845181888.0000 - val_accuracy: 0.0417\n",
      "Epoch 228/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306660096.0000 - accuracy: 0.0420 - val_loss: 845138048.0000 - val_accuracy: 0.0417\n",
      "Epoch 229/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306618112.0000 - accuracy: 0.0415 - val_loss: 845091008.0000 - val_accuracy: 0.0417\n",
      "Epoch 230/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306574208.0000 - accuracy: 0.0415 - val_loss: 845048384.0000 - val_accuracy: 0.0417\n",
      "Epoch 231/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306531328.0000 - accuracy: 0.0443 - val_loss: 845008384.0000 - val_accuracy: 0.0417\n",
      "Epoch 232/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1306491136.0000 - accuracy: 0.0418 - val_loss: 844966400.0000 - val_accuracy: 0.0417\n",
      "Epoch 233/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306449024.0000 - accuracy: 0.0451 - val_loss: 844931072.0000 - val_accuracy: 0.0575\n",
      "Epoch 234/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306405632.0000 - accuracy: 0.0467 - val_loss: 844885248.0000 - val_accuracy: 0.0496\n",
      "Epoch 235/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306363392.0000 - accuracy: 0.0498 - val_loss: 844841728.0000 - val_accuracy: 0.0417\n",
      "Epoch 236/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306323584.0000 - accuracy: 0.0432 - val_loss: 844802816.0000 - val_accuracy: 0.0496\n",
      "Epoch 237/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306283520.0000 - accuracy: 0.0550 - val_loss: 844755648.0000 - val_accuracy: 0.0417\n",
      "Epoch 238/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306239232.0000 - accuracy: 0.0459 - val_loss: 844717696.0000 - val_accuracy: 0.0675\n",
      "Epoch 239/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306195968.0000 - accuracy: 0.0483 - val_loss: 844672704.0000 - val_accuracy: 0.0556\n",
      "Epoch 240/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306151296.0000 - accuracy: 0.0604 - val_loss: 844629120.0000 - val_accuracy: 0.0833\n",
      "Epoch 241/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1306109952.0000 - accuracy: 0.0679 - val_loss: 844578688.0000 - val_accuracy: 0.0427\n",
      "Epoch 242/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307317120.0000 - accuracy: 0.1225 - val_loss: 844547008.0000 - val_accuracy: 0.0605\n",
      "Epoch 243/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306022912.0000 - accuracy: 0.0498 - val_loss: 844497792.0000 - val_accuracy: 0.0446\n",
      "Epoch 244/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1305979776.0000 - accuracy: 0.0582 - val_loss: 844458688.0000 - val_accuracy: 0.0665\n",
      "Epoch 245/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1305940096.0000 - accuracy: 0.0580 - val_loss: 844410176.0000 - val_accuracy: 0.0486\n",
      "Epoch 246/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306439808.0000 - accuracy: 0.0868 - val_loss: 844367360.0000 - val_accuracy: 0.0407\n",
      "Epoch 247/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1305851264.0000 - accuracy: 0.0445 - val_loss: 844325376.0000 - val_accuracy: 0.0724\n",
      "Epoch 248/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1305804800.0000 - accuracy: 0.0660 - val_loss: 844277248.0000 - val_accuracy: 0.0466\n",
      "Epoch 249/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1305762176.0000 - accuracy: 0.0564 - val_loss: 844241408.0000 - val_accuracy: 0.0813\n",
      "Epoch 250/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306091264.0000 - accuracy: 0.0928 - val_loss: 844417920.0000 - val_accuracy: 0.0833\n",
      "Epoch 251/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1305693696.0000 - accuracy: 0.0582 - val_loss: 844152640.0000 - val_accuracy: 0.0565\n",
      "Epoch 252/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1305636480.0000 - accuracy: 0.0634 - val_loss: 844105536.0000 - val_accuracy: 0.0794\n",
      "Epoch 253/256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 11ms/step - loss: 1305587968.0000 - accuracy: 0.0780 - val_loss: 844078400.0000 - val_accuracy: 0.0833\n",
      "Epoch 254/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1305549056.0000 - accuracy: 0.0538 - val_loss: 844019008.0000 - val_accuracy: 0.0823\n",
      "Epoch 255/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1305500160.0000 - accuracy: 0.0805 - val_loss: 844004992.0000 - val_accuracy: 0.0843\n",
      "Epoch 256/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1305463296.0000 - accuracy: 0.0459 - val_loss: 843942592.0000 - val_accuracy: 0.0833\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 72, 3)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                   [(None, 256), (None, 266240      input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_2 (RepeatVector)  (None, 24, 256)      0           lstm_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_5 (LSTM)                   [(None, 24, 256), (N 525312      repeat_vector_2[0][0]            \n",
      "                                                                 lstm_4[0][1]                     \n",
      "                                                                 lstm_4[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 24, 1)        257         lstm_5[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 791,809\n",
      "Trainable params: 791,809\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Took 19.72 sec for training the model\n",
      "{'train_losses': [1316903168.0, 1316456064.0, 1316359808.0, 1316302336.0, 1316256000.0, 1316209920.0, 1316165504.0, 1316124032.0, 1316081408.0, 1316036992.0, 1315993344.0, 1315949696.0, 1315906048.0, 1315862144.0, 1315818368.0, 1315778176.0, 1315736576.0, 1315692416.0, 1315652736.0, 1315614592.0, 1315736960.0, 1315528576.0, 1315486720.0, 1315440384.0, 1315397760.0, 1315356672.0, 1315311360.0, 1315266432.0, 1315223680.0, 1315182720.0, 1315138688.0, 1315095552.0, 1315051776.0, 1315009024.0, 1314965760.0, 1314922880.0, 1314878848.0, 1314832640.0, 1314790528.0, 1314745600.0, 1314702336.0, 1314658944.0, 1314612352.0, 1314572672.0, 1314528384.0, 1314481920.0, 1314441728.0, 1314399616.0, 1314355840.0, 1314316032.0, 1314272000.0, 1314229888.0, 1314186752.0, 1314140672.0, 1314099072.0, 1314055552.0, 1314010368.0, 1313967872.0, 1313925376.0, 1313880704.0, 1313836928.0, 1313795200.0, 1313753984.0, 1313707008.0, 1313667328.0, 1313625728.0, 1313584128.0, 1313539200.0, 1313497344.0, 1313451520.0, 1313408768.0, 1313367680.0, 1313322880.0, 1313277312.0, 1313232256.0, 1313193600.0, 1313149312.0, 1313105280.0, 1313062784.0, 1313017472.0, 1312976256.0, 1312933632.0, 1312890112.0, 1312847360.0, 1312802304.0, 1312761344.0, 1312716032.0, 1312673152.0, 1312629760.0, 1312585088.0, 1312542208.0, 1312500480.0, 1312485120.0, 1312414592.0, 1312369152.0, 1312324352.0, 1312282752.0, 1312237568.0, 1312194944.0, 1312152576.0, 1312110592.0, 1312065408.0, 1312023936.0, 1311980672.0, 1311938176.0, 1311894656.0, 1311851776.0, 1311805312.0, 1311763712.0, 1311721344.0, 1311679744.0, 1311637888.0, 1311591680.0, 1311549056.0, 1311508096.0, 1311464192.0, 1311420544.0, 1311378688.0, 1311334272.0, 1311289472.0, 1311247104.0, 1311203712.0, 1311160704.0, 1312344448.0, 1311079040.0, 1311036672.0, 1310990464.0, 1310946432.0, 1310904704.0, 1310859136.0, 1310817024.0, 1310774656.0, 1310733440.0, 1310690048.0, 1310646656.0, 1310603264.0, 1310557440.0, 1310515072.0, 1310470656.0, 1310428672.0, 1310386816.0, 1310342784.0, 1310301824.0, 1310260736.0, 1310216832.0, 1310174720.0, 1310421760.0, 1311099264.0, 1310052096.0, 1310004992.0, 1309962240.0, 1309918720.0, 1309874304.0, 1309828992.0, 1309788672.0, 1309748096.0, 1309706624.0, 1309660928.0, 1309618560.0, 1309576448.0, 1309532672.0, 1309491968.0, 1309447424.0, 1309404416.0, 1309359616.0, 1309317248.0, 1309271296.0, 1309231872.0, 1309192320.0, 1309150592.0, 1309104000.0, 1309060480.0, 1309019520.0, 1308976000.0, 1308934912.0, 1308889600.0, 1308846848.0, 1308805888.0, 1308762752.0, 1308722688.0, 1308680704.0, 1308635392.0, 1308590464.0, 1308546048.0, 1308503296.0, 1308461568.0, 1308416640.0, 1308370944.0, 1308329344.0, 1308286208.0, 1308244096.0, 1308202752.0, 1308158592.0, 1308117632.0, 1308074368.0, 1308034048.0, 1307990016.0, 1307946368.0, 1307904640.0, 1307864960.0, 1307820800.0, 1307776640.0, 1307730816.0, 1307688960.0, 1307648512.0, 1307603456.0, 1307559936.0, 1307517312.0, 1307474944.0, 1307432576.0, 1307384704.0, 1307340800.0, 1307303040.0, 1307262592.0, 1307221632.0, 1307176576.0, 1307134848.0, 1307094144.0, 1307052160.0, 1307005056.0, 1306961792.0, 1306920064.0, 1306875904.0, 1306830464.0, 1306786560.0, 1306744704.0, 1306702208.0, 1306660096.0, 1306618112.0, 1306574208.0, 1306531328.0, 1306491136.0, 1306449024.0, 1306405632.0, 1306363392.0, 1306323584.0, 1306283520.0, 1306239232.0, 1306195968.0, 1306151296.0, 1306109952.0, 1307317120.0, 1306022912.0, 1305979776.0, 1305940096.0, 1306439808.0, 1305851264.0, 1305804800.0, 1305762176.0, 1306091264.0, 1305693696.0, 1305636480.0, 1305587968.0, 1305549056.0, 1305500160.0, 1305463296.0], 'val_losses': [855066432.0, 854943232.0, 854880448.0, 854832768.0, 854785536.0, 854740608.0, 854699328.0, 854657024.0, 854611968.0, 854567808.0, 854523584.0, 854479616.0, 854435136.0, 854391168.0, 854350784.0, 854309632.0, 854264704.0, 854225280.0, 854183936.0, 854848192.0, 854100928.0, 854058688.0, 854011328.0, 853968576.0, 853927616.0, 853882112.0, 853835648.0, 853793152.0, 853752768.0, 853708480.0, 853665088.0, 853621120.0, 853577920.0, 853534848.0, 853492096.0, 853447808.0, 853400704.0, 853358720.0, 853312832.0, 853272384.0, 853226432.0, 853178240.0, 853139072.0, 853094912.0, 853046784.0, 853006848.0, 852964672.0, 852920704.0, 852881280.0, 852836224.0, 852794624.0, 852751424.0, 852704320.0, 852662464.0, 852619072.0, 852573504.0, 852530496.0, 852488064.0, 852442752.0, 852398976.0, 852356992.0, 852316480.0, 852267584.0, 852227776.0, 852187008.0, 852145088.0, 852099776.0, 852058432.0, 852011392.0, 851968576.0, 851927552.0, 851882368.0, 851836800.0, 851790720.0, 851752256.0, 851707904.0, 851663424.0, 851620736.0, 851574784.0, 851533248.0, 851490112.0, 851447040.0, 851404032.0, 851358016.0, 851317632.0, 851271680.0, 851228352.0, 851184896.0, 851139456.0, 851096448.0, 851054400.0, 851011904.0, 850968192.0, 850922240.0, 850876800.0, 850835328.0, 850789312.0, 850746816.0, 850704384.0, 850662144.0, 850616512.0, 850574784.0, 850531392.0, 850488640.0, 850444864.0, 850402240.0, 850354176.0, 850312832.0, 850269824.0, 850228736.0, 850186752.0, 850139840.0, 850097088.0, 850055680.0, 850012288.0, 849967488.0, 849925952.0, 849881600.0, 849835520.0, 849793536.0, 849749888.0, 849707008.0, 849660864.0, 849623616.0, 849581504.0, 849534592.0, 849490048.0, 849448640.0, 849402176.0, 849360000.0, 849317376.0, 849276736.0, 849232832.0, 849189376.0, 849145344.0, 849098752.0, 849056704.0, 849011840.0, 848970048.0, 848927872.0, 848882624.0, 848842944.0, 848800896.0, 848757120.0, 848714816.0, 848667776.0, 854568256.0, 848592000.0, 848543552.0, 848501120.0, 848456960.0, 848412480.0, 848365952.0, 848325888.0, 848285120.0, 848244160.0, 848197120.0, 848154240.0, 848111936.0, 848067840.0, 848027776.0, 847982208.0, 847939200.0, 847893248.0, 847851008.0, 847804096.0, 847764608.0, 847726464.0, 847684352.0, 847636352.0, 847592704.0, 847551808.0, 847507328.0, 847466624.0, 847420736.0, 847377536.0, 847336384.0, 847293184.0, 847253120.0, 847210880.0, 847165312.0, 847119232.0, 847075328.0, 847031552.0, 846990208.0, 846944640.0, 846897856.0, 846856384.0, 846813312.0, 846771264.0, 846728064.0, 846685120.0, 846643712.0, 846599680.0, 846560128.0, 846516032.0, 846472128.0, 846430720.0, 846390720.0, 846345728.0, 846301760.0, 846255424.0, 846213120.0, 846173248.0, 846126720.0, 846083200.0, 846040704.0, 845997312.0, 845954880.0, 845906624.0, 845861824.0, 845824192.0, 845783616.0, 845743040.0, 845697152.0, 845655488.0, 845616448.0, 845575808.0, 845526912.0, 845481408.0, 845438400.0, 845394496.0, 845349184.0, 845306944.0, 845266176.0, 845220800.0, 845181888.0, 845138048.0, 845091008.0, 845048384.0, 845008384.0, 844966400.0, 844931072.0, 844885248.0, 844841728.0, 844802816.0, 844755648.0, 844717696.0, 844672704.0, 844629120.0, 844578688.0, 844547008.0, 844497792.0, 844458688.0, 844410176.0, 844367360.0, 844325376.0, 844277248.0, 844241408.0, 844417920.0, 844152640.0, 844105536.0, 844078400.0, 844019008.0, 844004992.0, 843942592.0], 'train_accs': [0.20896226167678833, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.011163522489368916, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0072327046655118465, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001572327018948272, 0.0, 0.0, 0.009905660524964333, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.062264151871204376, 0.04150943458080292, 0.041509438306093216, 0.04150943458080292, 0.041509438306093216, 0.04150943458080292, 0.041509438306093216, 0.04150943458080292, 0.04150943458080292, 0.04150943458080292, 0.041509438306093216, 0.041509438306093216, 0.041509438306093216, 0.04150943458080292, 0.041509438306093216, 0.041509438306093216, 0.041509438306093216, 0.04150943458080292, 0.041509438306093216, 0.04150943458080292, 0.04150943458080292, 0.03207547217607498, 0.04150943458080292, 0.031603772193193436, 0.04150943458080292, 0.041352204978466034, 0.0336478017270565, 0.03883647918701172, 0.04150943458080292, 0.04150943458080292, 0.03883647918701172, 0.1028301864862442, 0.04229560121893883, 0.041981130838394165, 0.0416666716337204, 0.04088050499558449, 0.041352204978466034, 0.04119496792554855, 0.039308175444602966, 0.040723271667957306, 0.03883647918701172, 0.040566038340330124, 0.03946541249752045, 0.041352204978466034, 0.041352204978466034, 0.041352204978466034, 0.04119496792554855, 0.040723271667957306, 0.04465408995747566, 0.04150943458080292, 0.041509438306093216, 0.04150943458080292, 0.041509438306093216, 0.04182390123605728, 0.056603774428367615, 0.1267295479774475, 0.04150943458080292, 0.04150943458080292, 0.041509438306093216, 0.041509438306093216, 0.041509438306093216, 0.041509438306093216, 0.04150943458080292, 0.041509438306093216, 0.041509438306093216, 0.04150943458080292, 0.04150943458080292, 0.04150943458080292, 0.041509438306093216, 0.04150943458080292, 0.04150943458080292, 0.041509438306093216, 0.041509438306093216, 0.04150943458080292, 0.041509438306093216, 0.041509438306093216, 0.04150943458080292, 0.04150943458080292, 0.041509438306093216, 0.04150943458080292, 0.04150943458080292, 0.04150943458080292, 0.04150943458080292, 0.04150943458080292, 0.041509438306093216, 0.04150943458080292, 0.041509438306093216, 0.041509438306093216, 0.041509438306093216, 0.041509438306093216, 0.04150943458080292, 0.041509438306093216, 0.041509438306093216, 0.04150943458080292, 0.04150943458080292, 0.04150943458080292, 0.041509438306093216, 0.041509438306093216, 0.041509438306093216, 0.0514150969684124, 0.041509438306093216, 0.04150943458080292, 0.04150943458080292, 0.041509438306093216, 0.041509438306093216, 0.041509438306093216, 0.041509438306093216, 0.04732704535126686, 0.041509438306093216, 0.04150943458080292, 0.041509438306093216, 0.041509438306093216, 0.041509438306093216, 0.041509438306093216, 0.041509438306093216, 0.04150943458080292, 0.04150943458080292, 0.04150943458080292, 0.041509438306093216, 0.04150943458080292, 0.041509438306093216, 0.04150943458080292, 0.041509438306093216, 0.04150943458080292, 0.041509438306093216, 0.041509438306093216, 0.041509438306093216, 0.04150943458080292, 0.041509438306093216, 0.04150943458080292, 0.04150943458080292, 0.041509438306093216, 0.0416666679084301, 0.041509438306093216, 0.041509438306093216, 0.041981134563684464, 0.04150943458080292, 0.04150943458080292, 0.0443396233022213, 0.04182390123605728, 0.04512578994035721, 0.04669811576604843, 0.049842771142721176, 0.04323899745941162, 0.05503144860267639, 0.04591194912791252, 0.04827044531702995, 0.06037735939025879, 0.06792452931404114, 0.12248428910970688, 0.049842771142721176, 0.058176103979349136, 0.058018866926431656, 0.08679245412349701, 0.04449685662984848, 0.06603774428367615, 0.05644654855132103, 0.09276729822158813, 0.05817610025405884, 0.06336477398872375, 0.0779874250292778, 0.053773585706949234, 0.08050314337015152, 0.04591194912791252], 'val_accs': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0416666679084301, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.3402777910232544, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0575396828353405, 0.049603171646595, 0.0416666679084301, 0.0496031790971756, 0.0416666679084301, 0.0674603208899498, 0.055555559694767, 0.0833333358168602, 0.042658731341362, 0.0605158731341362, 0.0446428582072258, 0.0664682537317276, 0.0486111119389534, 0.0406746082007885, 0.072420634329319, 0.0466269850730896, 0.0813492089509964, 0.0833333358168602, 0.0565476194024086, 0.0793650820851326, 0.0833333358168602, 0.0823412761092186, 0.0843254029750824, 0.0833333358168602], 'train_acc': 0.030033904738331785, 'val_acc': 0.029986670066136867, 'test_nrmse': 0.989544287199212, 'y_test': [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1200.0, 2500.0, 3300.0, 11300.0, 13800.0, 12200.0, 8100.0, 4400.0, 2500.0, 3000.0, 3700.0, 300.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1300.0, 5800.0, 11300.0, 23400.0, 44600.0, 63500.0, 57800.0, 63900.0, 38600.0, 32400.0, 19400.0, 24300.0, 9700.0, 600.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 1100.0, 5000.0, 14500.0, 42800.0, 57800.0, 72500.0, 76200.0, 61500.0, 48100.0, 51700.0, 20400.0, 11100.0, 8400.0, 2000.0, 1100.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 700.0, 9100.0, 13200.0, 20300.0, 28900.0, 26800.0, 40600.0, 52300.0, 36200.0, 29900.0, 41400.0, 30500.0, 19300.0, 8300.0, 700.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2600.0, 4500.0, 6900.0, 6600.0, 17000.0, 16300.0, 32100.0, 22500.0, 14000.0, 9100.0, 5000.0, 4500.0, 400.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 400.0, 2800.0, 5100.0, 11700.0, 21900.0, 14800.0, 12900.0, 24100.0, 18200.0, 13200.0, 15500.0, 10600.0, 4700.0, 2100.0, 700.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 500.0, 7700.0, 18600.0, 14500.0, 22800.0, 34500.0, 23900.0, 46400.0, 25200.0, 20700.0, 19600.0, 28200.0, 14100.0, 6500.0, 1800.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1500.0, 4300.0, 6200.0, 17500.0, 11300.0, 9600.0, 10600.0, 11800.0, 7700.0, 3700.0, 3700.0, 3500.0, 2100.0, 900.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 400.0, 4100.0, 13300.0, 29500.0, 54500.0, 48100.0, 59800.0, 68100.0, 63900.0, 50800.0, 55000.0, 34800.0, 11000.0, 1600.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 400.0, 4600.0, 20100.0, 37100.0, 50200.0, 62400.0, 49300.0, 52100.0, 47400.0, 57700.0, 45600.0, 22000.0, 12600.0, 6500.0, 800.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 400.0, 4700.0, 7700.0, 29200.0, 28200.0, 29100.0, 42000.0, 41400.0, 26800.0, 13400.0, 6500.0, 3400.0, 900.0, 200.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 900.0, 4900.0, 9800.0, 13500.0, 25300.0, 29700.0, 41500.0, 24900.0, 8400.0, 17300.0, 14100.0, 2200.0, 500.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 300.0, 5600.0, 12200.0, 22100.0, 28200.0, 32800.0, 48700.0, 38200.0, 42600.0, 30200.0, 28600.0, 21100.0, 16000.0, 8000.0, 400.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 100.0, 700.0, 1900.0, 4000.0, 5500.0, 2700.0, 4300.0, 4600.0, 4100.0, 3800.0, 1800.0, 1000.0, 1000.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 400.0, 1200.0, 4300.0, 4300.0, 6000.0, 3700.0, 2000.0, 5300.0, 2800.0, 1200.0, 400.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 400.0, 3200.0, 6900.0, 12100.0, 31800.0, 31700.0, 44200.0, 34900.0, 24800.0, 32300.0, 21000.0, 16600.0, 7000.0, 3300.0, 200.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1400.0, 5100.0, 12300.0, 13700.0, 13200.0, 9700.0, 15500.0, 12700.0, 8200.0, 11100.0, 8300.0, 5200.0, 1200.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5200.0, 14100.0, 17500.0, 8400.0, 9800.0, 26200.0, 48100.0, 63700.0, 46200.0, 38200.0, 26100.0, 14000.0, 7200.0, 700.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1500.0, 8100.0, 19000.0, 22500.0, 22100.0, 53000.0, 41900.0, 33200.0, 50300.0, 43700.0, 35100.0, 20800.0, 6100.0, 800.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2000.0, 8200.0, 8100.0, 14400.0, 35800.0, 27800.0, 25000.0, 23000.0, 9000.0, 12300.0, 22200.0, 9800.0, 2200.0, 100.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 700.0, 2000.0, 4800.0, 5800.0, 7500.0, 6200.0, 8800.0, 9800.0, 7300.0, 6000.0, 4100.0, 1300.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 100.0, 600.0, 6400.0, 9800.0, 5400.0, 22000.0, 29800.0, 34600.0, 34400.0, 27500.0, 16100.0, 6300.0, 3500.0, 800.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 400.0, 8400.0, 7500.0, 8500.0, 22200.0, 28400.0, 30500.0, 34800.0, 40100.0, 52300.0, 32100.0, 26000.0, 9800.0, 2100.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1500.0, 5200.0, 6200.0, 8400.0, 10800.0, 10700.0, 10700.0, 12900.0, 14000.0, 10700.0, 14700.0, 7300.0, 3900.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 700.0, 500.0, 4700.0, 3200.0, 2400.0, 2100.0, 2100.0, 3100.0, 2000.0, 1400.0, 2100.0, 400.0, 400.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1200.0, 2100.0, 2600.0, 6900.0, 8100.0, 11100.0, 6500.0, 3000.0, 11400.0, 16600.0, 8100.0, 4700.0, 5000.0, 700.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 100.0, 2300.0, 4300.0, 15000.0, 15100.0, 27600.0, 32000.0, 56800.0, 19500.0, 32900.0, 25600.0, 9600.0, 20500.0, 2500.0, 100.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4200.0, 11100.0, 29600.0, 40300.0, 50900.0, 28700.0, 50700.0, 27300.0, 32500.0, 37200.0, 22900.0, 17800.0, 4000.0, 200.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1400.0, 4600.0, 6900.0, 11400.0, 15900.0, 23200.0, 19200.0, 15300.0, 5200.0, 5200.0, 1100.0, 1200.0, 200.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1700.0, 7700.0, 12500.0, 14000.0, 18700.0, 14500.0, 14300.0, 17900.0, 10400.0, 5900.0, 11400.0, 4200.0, 700.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 100.0, 2500.0, 6000.0, 19200.0, 20500.0, 16900.0, 15900.0, 18400.0, 9800.0, 8100.0, 7400.0, 8500.0, 3600.0, 6900.0, 100.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1700.0, 6000.0, 6400.0, 22200.0, 41100.0, 27600.0, 25900.0, 29600.0, 18500.0, 6900.0, 2500.0, 4000.0, 3900.0, 100.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3600.0, 11800.0, 29000.0, 39600.0, 58800.0, 61400.0, 44100.0, 45200.0, 46000.0, 28000.0, 29900.0, 8200.0, 2700.0, 400.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2600.0, 10400.0, 26400.0, 42400.0, 54500.0, 57900.0, 49900.0, 35700.0, 20600.0, 17300.0, 10700.0, 8500.0, 3900.0, 300.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1400.0, 11900.0, 21100.0, 22900.0, 46500.0, 35400.0, 44000.0, 43200.0, 31300.0, 20700.0, 13300.0, 8500.0, 4100.0, 300.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2100.0, 12700.0, 8700.0, 19600.0, 17900.0, 17800.0, 33400.0, 34900.0, 28400.0, 13700.0, 7700.0, 10900.0, 3000.0, 100.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3200.0, 10600.0, 19700.0, 21300.0, 34300.0, 35200.0, 36900.0, 38900.0, 40000.0, 15700.0, 8400.0, 6900.0, 2800.0, 100.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1500.0, 7600.0, 13000.0, 12000.0, 6000.0, 11000.0, 13900.0, 15300.0, 10200.0, 21100.0, 10200.0, 6100.0, 1300.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 800.0, 900.0, 1000.0, 2000.0, 2400.0, 4400.0, 3200.0, 2000.0, 3300.0, 3000.0, 5700.0, 1000.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 500.0, 2200.0, 1900.0, 3400.0, 4600.0, 5200.0, 3700.0, 3900.0, 400.0, 100.0, 100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 900.0, 6600.0, 100.0, 800.0, 1800.0, 10500.0, 4200.0, 7000.0, 2400.0, 2700.0, 1900.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3100.0, 10400.0, 23800.0, 30300.0, 67400.0, 36400.0, 34800.0, 56300.0, 31600.0, 25100.0, 14500.0, 7700.0, 1300.0, 650.0, 0.0, 0.0, 0.0, 0.0]], 'y_pred': [[0.0, 0.0, 3.590548515319824, 28.405101776123047, 80.94827270507812, 170.9647216796875, 324.40557861328125, 342.7357177734375, 343.385986328125, 343.474609375, 343.4866027832031, 343.4882507324219, 343.488525390625, 343.4885559082031, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125], [0.0, 0.0, 2.935168743133545, 28.13936996459961, 83.02932739257812, 180.51708984375, 331.39459228515625, 342.80645751953125, 343.3955383300781, 343.4758605957031, 343.48681640625, 343.4882507324219, 343.4884948730469, 343.488525390625, 343.488525390625, 343.488525390625, 343.488525390625, 343.488525390625, 343.488525390625, 343.488525390625, 343.488525390625, 343.488525390625, 343.488525390625, 343.488525390625], [0.0, 0.0, 4.165194988250732, 29.6010684967041, 83.11531829833984, 173.19813537597656, 325.7696533203125, 342.7660827636719, 343.3901062011719, 343.4751892089844, 343.48675537109375, 343.4883117675781, 343.488525390625, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125], [0.0, 0.0, 7.777855396270752, 33.51701736450195, 84.34888458251953, 170.76148986816406, 323.9818420410156, 342.7091979980469, 343.3824768066406, 343.4742126464844, 343.4866638183594, 343.4883728027344, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594], [0.0, 0.0, 4.450377941131592, 29.4796199798584, 81.3101806640625, 169.16534423828125, 322.6163635253906, 342.70892333984375, 343.3823547363281, 343.4741516113281, 343.48663330078125, 343.4883117675781, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125], [0.0, 0.0, 5.355963230133057, 33.42600631713867, 92.67000579833984, 189.73599243164062, 334.4173889160156, 342.9217529296875, 343.4114074707031, 343.4780578613281, 343.48712158203125, 343.4884033203125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125], [0.0, 0.0, 5.889249324798584, 31.517051696777344, 83.34783172607422, 170.64695739746094, 323.7764587402344, 342.7198181152344, 343.38385009765625, 343.474365234375, 343.4866943359375, 343.4883728027344, 343.48858642578125, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594], [0.0, 0.0, 5.127106666564941, 29.643535614013672, 79.07728576660156, 164.2212677001953, 317.8032531738281, 342.6271057128906, 343.3712463378906, 343.4726257324219, 343.4864196777344, 343.48834228515625, 343.48858642578125, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594], [0.0, 0.0, 4.845106601715088, 30.513912200927734, 83.66938018798828, 172.6945343017578, 325.3660888671875, 342.7545471191406, 343.3885498046875, 343.4749755859375, 343.4867248535156, 343.4883728027344, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125], [0.0, 0.0, 4.561399459838867, 29.220157623291016, 79.78871154785156, 166.21961975097656, 319.8866882324219, 342.6643371582031, 343.3763122558594, 343.47332763671875, 343.4864807128906, 343.48834228515625, 343.4885559082031, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125], [0.0, 0.0, 4.9406819343566895, 30.868183135986328, 84.6870346069336, 174.32334899902344, 326.4833984375, 342.77587890625, 343.3915100097656, 343.4753723144531, 343.48675537109375, 343.4883728027344, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125], [0.0, 0.0, 3.446223258972168, 27.554079055786133, 78.07585144042969, 165.4722442626953, 319.4159851074219, 342.66229248046875, 343.3759460449219, 343.4732360839844, 343.4864807128906, 343.48822021484375, 343.488525390625, 343.4885559082031, 343.4885559082031, 343.4885559082031, 343.4885559082031, 343.4885559082031, 343.4885559082031, 343.4885559082031, 343.4885559082031, 343.4885559082031, 343.4885559082031, 343.4885559082031], [0.0, 0.0, 5.257259368896484, 32.285213470458984, 88.78903198242188, 181.61441040039062, 330.91387939453125, 342.8535461425781, 343.402099609375, 343.4768371582031, 343.48699951171875, 343.4884033203125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125], [0.0, 0.0, 4.581218719482422, 28.39816665649414, 76.51596069335938, 160.43881225585938, 313.2253723144531, 342.5719299316406, 343.3636779785156, 343.4716491699219, 343.4862365722656, 343.4882507324219, 343.4885559082031, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125], [0.0, 0.0, 3.5041451454162598, 28.250276565551758, 80.705810546875, 170.82395935058594, 324.4076843261719, 342.7328796386719, 343.3855895996094, 343.4745178222656, 343.4866027832031, 343.4882507324219, 343.488525390625, 343.4885559082031, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125], [0.0, 0.0, 5.692768573760986, 30.94426918029785, 82.01789093017578, 168.55726623535156, 321.95599365234375, 342.6926574707031, 343.3801574707031, 343.4738464355469, 343.48663330078125, 343.4883728027344, 343.48858642578125, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594], [0.0, 0.0, 8.854040145874023, 33.96285629272461, 82.1603012084961, 166.94241333007812, 321.197021484375, 342.6317443847656, 343.3719177246094, 343.4727783203125, 343.4864807128906, 343.4883728027344, 343.4886169433594, 343.4886474609375, 343.4886474609375, 343.4886474609375, 343.4886474609375, 343.4886474609375, 343.4886474609375, 343.4886474609375, 343.4886474609375, 343.4886474609375, 343.4886474609375, 343.4886474609375], [0.0, 0.0, 6.2063307762146, 31.185420989990234, 80.89437103271484, 166.27536010742188, 320.0101318359375, 342.6501770019531, 343.3744201660156, 343.47308349609375, 343.4864807128906, 343.4883728027344, 343.48858642578125, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594], [0.0, 0.0, 6.383077144622803, 30.853607177734375, 78.87458038330078, 162.87442016601562, 316.618896484375, 342.5889892578125, 343.3660583496094, 343.471923828125, 343.4863586425781, 343.48834228515625, 343.48858642578125, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594], [0.0, 0.0, 4.259888172149658, 28.808799743652344, 79.43856811523438, 166.07839965820312, 319.71685791015625, 342.66607666015625, 343.37652587890625, 343.4732971191406, 343.48651123046875, 343.48828125, 343.4885559082031, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125], [0.0, 0.0, 3.816112995147705, 28.830463409423828, 81.60282135009766, 171.42626953125, 324.63177490234375, 342.74267578125, 343.3869323730469, 343.4747619628906, 343.4866638183594, 343.4882507324219, 343.488525390625, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125], [0.0, 0.0, 3.0728940963745117, 26.736797332763672, 76.50033569335938, 163.64735412597656, 317.87060546875, 342.63616943359375, 343.3724060058594, 343.47271728515625, 343.4864196777344, 343.4881896972656, 343.4884948730469, 343.4885559082031, 343.4885559082031, 343.4885559082031, 343.4885559082031, 343.4885559082031, 343.4885559082031, 343.4885559082031, 343.4885559082031, 343.4885559082031, 343.4885559082031, 343.4885559082031], [0.0, 0.0, 5.2367167472839355, 31.140117645263672, 84.55867767333984, 173.49539184570312, 325.8406982421875, 342.7651672363281, 343.3900451660156, 343.4751892089844, 343.48675537109375, 343.4883728027344, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125], [0.0, 0.0, 5.496744632720947, 30.775218963623047, 82.12670135498047, 168.95974731445312, 322.28643798828125, 342.7003173828125, 343.3812255859375, 343.4739990234375, 343.48663330078125, 343.4883728027344, 343.48858642578125, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594], [0.0, 0.0, 5.196376800537109, 30.615306854248047, 82.64920043945312, 170.25772094726562, 323.3792419433594, 342.72113037109375, 343.3840637207031, 343.474365234375, 343.4866638183594, 343.4883728027344, 343.48858642578125, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594], [0.0, 0.0, 4.23491907119751, 27.994277954101562, 76.29532623291016, 160.5011444091797, 313.3695373535156, 342.57550048828125, 343.3642272949219, 343.4716491699219, 343.48626708984375, 343.4882507324219, 343.488525390625, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125], [0.0, 0.0, 8.95703411102295, 34.4589958190918, 83.71002960205078, 169.34654235839844, 323.2413635253906, 342.67071533203125, 343.37725830078125, 343.4734802246094, 343.4866027832031, 343.4883728027344, 343.4886169433594, 343.4886474609375, 343.4886474609375, 343.4886474609375, 343.4886474609375, 343.4886474609375, 343.4886474609375, 343.4886474609375, 343.4886474609375, 343.4886474609375, 343.4886474609375, 343.4886474609375], [0.0, 0.0, 8.578042030334473, 33.39004898071289, 80.8167724609375, 164.89083862304688, 319.1968688964844, 342.5990295410156, 343.367431640625, 343.47216796875, 343.48638916015625, 343.4883728027344, 343.4886169433594, 343.4886474609375, 343.4886474609375, 343.4886474609375, 343.4886474609375, 343.4886474609375, 343.4886474609375, 343.4886474609375, 343.4886474609375, 343.4886474609375, 343.4886474609375, 343.4886474609375], [0.0, 0.0, 5.238346576690674, 30.469865798950195, 81.8905258178711, 168.86907958984375, 322.2164611816406, 342.6998596191406, 343.3811950683594, 343.4739685058594, 343.48663330078125, 343.4883728027344, 343.48858642578125, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594], [0.0, 0.0, 5.523991107940674, 32.347904205322266, 87.90782165527344, 179.29869079589844, 329.6442565917969, 342.8289489746094, 343.3987731933594, 343.47637939453125, 343.4869384765625, 343.4884033203125, 343.48858642578125, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594], [0.0, 0.0, 4.728689193725586, 29.393192291259766, 79.75718688964844, 165.8946075439453, 319.4883117675781, 342.658935546875, 343.3755187988281, 343.47320556640625, 343.4864807128906, 343.48834228515625, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125], [0.0, 0.0, 6.272611141204834, 31.559284210205078, 82.06575012207031, 168.08389282226562, 321.59295654296875, 342.6792907714844, 343.37835693359375, 343.4736633300781, 343.4865417480469, 343.4883728027344, 343.48858642578125, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594], [0.0, 0.0, 6.650777339935303, 31.31873321533203, 79.69482421875, 163.9750213623047, 317.7385559082031, 342.60687255859375, 343.3684997558594, 343.4723205566406, 343.4863586425781, 343.4883728027344, 343.48858642578125, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594], [0.0, 0.0, 6.368748188018799, 31.5307674407959, 81.58304595947266, 167.23106384277344, 320.8497009277344, 342.66455078125, 343.3763732910156, 343.473388671875, 343.4865417480469, 343.4883728027344, 343.48858642578125, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594], [0.0, 0.0, 4.576918125152588, 29.144725799560547, 79.42034912109375, 165.5093994140625, 319.0839538574219, 342.6546936035156, 343.3749694824219, 343.47314453125, 343.4864807128906, 343.48834228515625, 343.4885559082031, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125], [0.0, 0.0, 4.390644073486328, 29.66581916809082, 82.30781555175781, 171.0911102294922, 324.16802978515625, 342.73638916015625, 343.3860778808594, 343.4746398925781, 343.4866638183594, 343.4883728027344, 343.4885559082031, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125], [0.0, 0.0, 3.841400146484375, 28.271465301513672, 79.17557525634766, 166.4845733642578, 320.2085266113281, 342.6755065917969, 343.3778076171875, 343.4734802246094, 343.48651123046875, 343.4882507324219, 343.4885559082031, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125, 343.48858642578125], [0.0, 0.0, 3.509507179260254, 27.227094650268555, 76.44790649414062, 162.11553955078125, 315.5517578125, 342.6115417480469, 343.3690185546875, 343.4723205566406, 343.48626708984375, 343.48822021484375, 343.488525390625, 343.4885559082031, 343.4885559082031, 343.4885559082031, 343.4885559082031, 343.4885559082031, 343.4885559082031, 343.4885559082031, 343.4885559082031, 343.4885559082031, 343.4885559082031, 343.4885559082031], [0.0, 0.0, 2.96798038482666, 26.21086311340332, 74.83069610595703, 160.5352783203125, 314.0808410644531, 342.5891418457031, 343.3659973144531, 343.47186279296875, 343.4862365722656, 343.4881896972656, 343.4884948730469, 343.4885559082031, 343.4885559082031, 343.4885559082031, 343.4885559082031, 343.4885559082031, 343.4885559082031, 343.4885559082031, 343.4885559082031, 343.4885559082031, 343.4885559082031, 343.4885559082031], [0.0, 0.0, 6.1303887367248535, 32.744163513183594, 87.16485595703125, 176.84686279296875, 328.10546875, 342.8016662597656, 343.3950500488281, 343.47589111328125, 343.48687744140625, 343.4884033203125, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594], [0.0, 0.0, 7.1675615310668945, 32.077476501464844, 80.81007385253906, 165.50531005859375, 319.378662109375, 342.62872314453125, 343.3714599609375, 343.4727478027344, 343.4864196777344, 343.4883728027344, 343.48858642578125, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594], [0.0, 0.0, 5.609561920166016, 30.213701248168945, 79.46543884277344, 164.2989044189453, 317.7426452636719, 342.627197265625, 343.3712463378906, 343.4726257324219, 343.4864196777344, 343.48834228515625, 343.48858642578125, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594, 343.4886169433594]], 'exp_name': 'solar power prediction using weather features', 'plant': 126, 'spot': 174, 'start_date': '20190820', 'end_date': '20200809', 'batch_size': 64, 'x_frames': 3, 'y_frames': 1, 'hid_dim': 256, 'optim': 'RMSprop', 'activation': 'relu', 'lss': 'MSE', 'lr': 0.001, 'epochs': 256, 'early_stop': 30, 'evaluation': 'NRMSE', 'features': \"[<FeatureType.SUNSHINE: '일조(hr)'>, <FeatureType.HUMIDITY: '습도(%)'>, <FeatureType.WIND_SPEED: '풍속(m/s)'>]\"}\n",
      "\n",
      "Namespace(activation='relu', batch_size=64, early_stop=30, end_date='20200809', epochs=256, evaluation='NRMSE', exp_name='solar power prediction using weather features', features=\"[<FeatureType.SUNSHINE: '일조(hr)'>, <FeatureType.HUMIDITY: '습도(%)'>, <FeatureType.WIND_SPEED: '풍속(m/s)'>, <FeatureType.VISIBILITY: '시정(10m)'>]\", hid_dim=256, lr=0.001, lss='MSE', optim='RMSprop', plant=126, spot=174, start_date='20190820', x_frames=3, y_frames=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/256\n",
      "5/5 [==============================] - 1s 123ms/step - loss: 1316886272.0000 - accuracy: 0.2124 - val_loss: 855006848.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1316386944.0000 - accuracy: 0.0000e+00 - val_loss: 854868352.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1316285952.0000 - accuracy: 0.0000e+00 - val_loss: 854807296.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1316229504.0000 - accuracy: 0.0000e+00 - val_loss: 854758656.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1316181632.0000 - accuracy: 0.0000e+00 - val_loss: 854709312.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1316133376.0000 - accuracy: 0.0000e+00 - val_loss: 854663296.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1316088192.0000 - accuracy: 0.0000e+00 - val_loss: 854620928.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1316045696.0000 - accuracy: 0.0000e+00 - val_loss: 854577728.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1316002304.0000 - accuracy: 0.0000e+00 - val_loss: 854532288.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315957376.0000 - accuracy: 0.0000e+00 - val_loss: 854487360.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315913088.0000 - accuracy: 0.0000e+00 - val_loss: 854442176.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1315868160.0000 - accuracy: 0.0000e+00 - val_loss: 854396608.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315822848.0000 - accuracy: 0.0000e+00 - val_loss: 854350720.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315777792.0000 - accuracy: 0.0000e+00 - val_loss: 854305664.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315733120.0000 - accuracy: 0.0000e+00 - val_loss: 854264704.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315692160.0000 - accuracy: 0.0000e+00 - val_loss: 854222528.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315649792.0000 - accuracy: 0.0000e+00 - val_loss: 854176512.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315604480.0000 - accuracy: 0.0000e+00 - val_loss: 854136320.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315564160.0000 - accuracy: 0.0000e+00 - val_loss: 854094528.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315522176.0000 - accuracy: 0.0000e+00 - val_loss: 854052096.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1315483392.0000 - accuracy: 0.0000e+00 - val_loss: 854010368.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315436032.0000 - accuracy: 0.0000e+00 - val_loss: 853964672.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315393024.0000 - accuracy: 0.0000e+00 - val_loss: 853916928.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315346176.0000 - accuracy: 0.0000e+00 - val_loss: 853872768.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315302016.0000 - accuracy: 0.0000e+00 - val_loss: 853830720.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315259904.0000 - accuracy: 0.0000e+00 - val_loss: 853784192.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315214208.0000 - accuracy: 0.0000e+00 - val_loss: 853737792.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315168640.0000 - accuracy: 0.0000e+00 - val_loss: 853694464.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315125376.0000 - accuracy: 0.0000e+00 - val_loss: 853654464.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315085184.0000 - accuracy: 0.0000e+00 - val_loss: 853611008.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1315041664.0000 - accuracy: 0.0000e+00 - val_loss: 853567616.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314998656.0000 - accuracy: 0.0000e+00 - val_loss: 853523904.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314955008.0000 - accuracy: 0.0000e+00 - val_loss: 853480576.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314911872.0000 - accuracy: 0.0000e+00 - val_loss: 853437184.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314868736.0000 - accuracy: 0.0000e+00 - val_loss: 853395264.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314826368.0000 - accuracy: 0.0000e+00 - val_loss: 853350976.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314782464.0000 - accuracy: 0.0000e+00 - val_loss: 853303872.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314736256.0000 - accuracy: 0.0000e+00 - val_loss: 853261632.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314694144.0000 - accuracy: 0.0000e+00 - val_loss: 853215744.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1314649088.0000 - accuracy: 0.0000e+00 - val_loss: 853171264.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314604544.0000 - accuracy: 0.0000e+00 - val_loss: 853128896.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314561920.0000 - accuracy: 0.0000e+00 - val_loss: 853080640.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314515072.0000 - accuracy: 0.0000e+00 - val_loss: 853041280.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314475392.0000 - accuracy: 0.0000e+00 - val_loss: 852996864.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314431104.0000 - accuracy: 0.0000e+00 - val_loss: 852948672.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1314384384.0000 - accuracy: 0.0000e+00 - val_loss: 852908544.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314343808.0000 - accuracy: 0.0000e+00 - val_loss: 852866304.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314301696.0000 - accuracy: 0.0000e+00 - val_loss: 852822016.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314257792.0000 - accuracy: 0.0000e+00 - val_loss: 852782528.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 12ms/step - loss: 1314217728.0000 - accuracy: 0.0000e+00 - val_loss: 852737344.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314173440.0000 - accuracy: 0.0000e+00 - val_loss: 852695360.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314131712.0000 - accuracy: 0.0000e+00 - val_loss: 852652032.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314088064.0000 - accuracy: 0.0000e+00 - val_loss: 852604736.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314041856.0000 - accuracy: 0.0000e+00 - val_loss: 852562816.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313999872.0000 - accuracy: 0.0000e+00 - val_loss: 852519232.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313956352.0000 - accuracy: 0.0000e+00 - val_loss: 852473472.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313911040.0000 - accuracy: 0.0000e+00 - val_loss: 852430336.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313868160.0000 - accuracy: 0.0000e+00 - val_loss: 852387840.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1313825536.0000 - accuracy: 0.0000e+00 - val_loss: 852342400.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313780608.0000 - accuracy: 0.0000e+00 - val_loss: 852298304.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313736960.0000 - accuracy: 0.0000e+00 - val_loss: 852256256.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313694976.0000 - accuracy: 0.0000e+00 - val_loss: 852215488.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1313653632.0000 - accuracy: 0.0000e+00 - val_loss: 852166336.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313606272.0000 - accuracy: 0.0000e+00 - val_loss: 852126592.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314170112.0000 - accuracy: 0.0458 - val_loss: 852091008.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313529728.0000 - accuracy: 0.0000e+00 - val_loss: 852047360.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313486208.0000 - accuracy: 0.0000e+00 - val_loss: 852000640.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313440512.0000 - accuracy: 0.0000e+00 - val_loss: 851958656.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1313398144.0000 - accuracy: 0.0000e+00 - val_loss: 851911168.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313351552.0000 - accuracy: 0.0000e+00 - val_loss: 851867968.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313308672.0000 - accuracy: 0.0000e+00 - val_loss: 851826560.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313267072.0000 - accuracy: 0.0000e+00 - val_loss: 851781312.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313222272.0000 - accuracy: 0.0000e+00 - val_loss: 851735296.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313176448.0000 - accuracy: 3.1447e-04 - val_loss: 851688896.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313131264.0000 - accuracy: 6.2893e-04 - val_loss: 851650432.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313092096.0000 - accuracy: 4.7170e-04 - val_loss: 851605888.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313047808.0000 - accuracy: 1.5723e-04 - val_loss: 851561152.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1313009024.0000 - accuracy: 0.0025 - val_loss: 851518528.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312961152.0000 - accuracy: 0.0000e+00 - val_loss: 851472256.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312915584.0000 - accuracy: 0.0000e+00 - val_loss: 851430720.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312873984.0000 - accuracy: 0.0000e+00 - val_loss: 851387328.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312871808.0000 - accuracy: 0.0069 - val_loss: 851397568.0000 - val_accuracy: 0.1121\n",
      "Epoch 83/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312796928.0000 - accuracy: 0.0233 - val_loss: 851302080.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312745984.0000 - accuracy: 0.0011 - val_loss: 851255488.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312700288.0000 - accuracy: 0.0000e+00 - val_loss: 851214848.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312659072.0000 - accuracy: 0.0000e+00 - val_loss: 851168512.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312613632.0000 - accuracy: 0.0000e+00 - val_loss: 851125184.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1312570496.0000 - accuracy: 0.0000e+00 - val_loss: 851081408.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312526976.0000 - accuracy: 0.0000e+00 - val_loss: 851035840.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312482048.0000 - accuracy: 0.0000e+00 - val_loss: 850992768.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312439168.0000 - accuracy: 0.0000e+00 - val_loss: 850950528.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312396928.0000 - accuracy: 0.0000e+00 - val_loss: 850907840.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312354048.0000 - accuracy: 0.0000e+00 - val_loss: 850864512.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312310912.0000 - accuracy: 0.0000e+00 - val_loss: 850818496.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312265216.0000 - accuracy: 0.0000e+00 - val_loss: 850772544.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312221440.0000 - accuracy: 0.0097 - val_loss: 850730688.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1312178560.0000 - accuracy: 0.0000e+00 - val_loss: 850684608.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312133504.0000 - accuracy: 0.0071 - val_loss: 850641984.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 11ms/step - loss: 1312090752.0000 - accuracy: 0.0000e+00 - val_loss: 850599360.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312048128.0000 - accuracy: 0.0096 - val_loss: 850557056.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 101/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312005760.0000 - accuracy: 0.0000e+00 - val_loss: 850511296.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 102/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311960576.0000 - accuracy: 0.0000e+00 - val_loss: 850469440.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 103/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311918848.0000 - accuracy: 0.0000e+00 - val_loss: 850425728.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 104/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311875456.0000 - accuracy: 0.0000e+00 - val_loss: 850382848.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 105/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311832832.0000 - accuracy: 0.0000e+00 - val_loss: 850338880.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 106/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311789696.0000 - accuracy: 0.0099 - val_loss: 850296320.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 107/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1311746048.0000 - accuracy: 0.0000e+00 - val_loss: 850248000.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 108/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311699328.0000 - accuracy: 0.0000e+00 - val_loss: 850206336.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 109/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311657472.0000 - accuracy: 0.0000e+00 - val_loss: 850163136.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 110/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311615232.0000 - accuracy: 0.0000e+00 - val_loss: 850122048.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 111/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311573504.0000 - accuracy: 0.0000e+00 - val_loss: 850079616.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 112/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311531264.0000 - accuracy: 0.0000e+00 - val_loss: 850032768.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 113/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311484928.0000 - accuracy: 0.0000e+00 - val_loss: 849989824.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 114/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311442304.0000 - accuracy: 0.0000e+00 - val_loss: 849948160.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 115/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311401088.0000 - accuracy: 0.0000e+00 - val_loss: 849904576.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 116/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1311356800.0000 - accuracy: 0.0000e+00 - val_loss: 849859648.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 117/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311312896.0000 - accuracy: 0.0000e+00 - val_loss: 849817984.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 118/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312507264.0000 - accuracy: 0.1291 - val_loss: 849780352.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 119/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311233408.0000 - accuracy: 0.0000e+00 - val_loss: 849733120.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 120/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311187328.0000 - accuracy: 0.0077 - val_loss: 849690304.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 121/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311144448.0000 - accuracy: 0.0206 - val_loss: 849646080.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 122/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311100672.0000 - accuracy: 0.0097 - val_loss: 849602880.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 123/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311057280.0000 - accuracy: 0.0000e+00 - val_loss: 849556800.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 124/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311012224.0000 - accuracy: 0.0099 - val_loss: 849512256.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 125/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310968064.0000 - accuracy: 0.0022 - val_loss: 849471104.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 126/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1310926464.0000 - accuracy: 0.0000e+00 - val_loss: 849424704.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 127/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310880896.0000 - accuracy: 0.0099 - val_loss: 849380416.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 128/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310836864.0000 - accuracy: 0.0000e+00 - val_loss: 849339072.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 129/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310795520.0000 - accuracy: 0.0099 - val_loss: 849292544.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 130/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310749824.0000 - accuracy: 7.8616e-04 - val_loss: 849250432.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 131/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310707712.0000 - accuracy: 0.0000e+00 - val_loss: 849207616.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 132/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310665472.0000 - accuracy: 0.0000e+00 - val_loss: 849166848.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 133/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310623872.0000 - accuracy: 0.0000e+00 - val_loss: 849122752.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 134/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310580736.0000 - accuracy: 0.0000e+00 - val_loss: 849079168.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 135/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1310536960.0000 - accuracy: 0.0000e+00 - val_loss: 849034944.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 136/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310493824.0000 - accuracy: 0.0099 - val_loss: 848988288.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 137/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310447616.0000 - accuracy: 0.0000e+00 - val_loss: 848946304.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 138/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1310405376.0000 - accuracy: 0.0000e+00 - val_loss: 848900992.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 139/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310360704.0000 - accuracy: 0.0000e+00 - val_loss: 848859136.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 140/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310318720.0000 - accuracy: 0.0000e+00 - val_loss: 848815616.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 141/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310275712.0000 - accuracy: 0.0000e+00 - val_loss: 848770944.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 142/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310231552.0000 - accuracy: 0.0300 - val_loss: 848731264.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 143/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310191104.0000 - accuracy: 0.0000e+00 - val_loss: 848689280.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 144/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310150016.0000 - accuracy: 0.0000e+00 - val_loss: 848645184.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 145/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1310105856.0000 - accuracy: 0.0000e+00 - val_loss: 848602752.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 146/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310063488.0000 - accuracy: 0.0000e+00 - val_loss: 848555328.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 147/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310017536.0000 - accuracy: 0.0099 - val_loss: 848510400.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 148/256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 11ms/step - loss: 1309972352.0000 - accuracy: 0.0000e+00 - val_loss: 848467456.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 149/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309929344.0000 - accuracy: 0.0099 - val_loss: 848421248.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 150/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309884416.0000 - accuracy: 0.0000e+00 - val_loss: 848379904.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 151/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309841920.0000 - accuracy: 0.0000e+00 - val_loss: 848336384.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 152/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309798912.0000 - accuracy: 0.0000e+00 - val_loss: 848291968.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 153/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309754880.0000 - accuracy: 0.0000e+00 - val_loss: 848245696.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 154/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1309709568.0000 - accuracy: 0.0000e+00 - val_loss: 848205504.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 155/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309669248.0000 - accuracy: 0.0000e+00 - val_loss: 848164544.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 156/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309628544.0000 - accuracy: 0.0000e+00 - val_loss: 848123392.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 157/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309586944.0000 - accuracy: 0.0000e+00 - val_loss: 848076224.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 158/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309542144.0000 - accuracy: 0.0099 - val_loss: 848033280.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 159/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309498368.0000 - accuracy: 0.0000e+00 - val_loss: 847990784.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 160/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309456128.0000 - accuracy: 0.0000e+00 - val_loss: 847946496.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 161/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309412096.0000 - accuracy: 0.0000e+00 - val_loss: 847906240.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 162/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309371392.0000 - accuracy: 0.0000e+00 - val_loss: 847860416.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 163/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309326592.0000 - accuracy: 0.0000e+00 - val_loss: 847817408.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 164/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1309283456.0000 - accuracy: 0.0000e+00 - val_loss: 847771136.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 165/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1309238400.0000 - accuracy: 0.0000e+00 - val_loss: 847728768.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 166/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309196032.0000 - accuracy: 0.0000e+00 - val_loss: 847681664.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 167/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309149824.0000 - accuracy: 0.0000e+00 - val_loss: 847642304.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 168/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309110016.0000 - accuracy: 0.0000e+00 - val_loss: 847603200.0000 - val_accuracy: 0.0417\n",
      "Epoch 169/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309106304.0000 - accuracy: 0.0588 - val_loss: 847561216.0000 - val_accuracy: 0.0079\n",
      "Epoch 170/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309028224.0000 - accuracy: 0.0085 - val_loss: 847513216.0000 - val_accuracy: 0.0079\n",
      "Epoch 171/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308981376.0000 - accuracy: 0.0036 - val_loss: 847469248.0000 - val_accuracy: 0.0079\n",
      "Epoch 172/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308937856.0000 - accuracy: 0.0108 - val_loss: 847428096.0000 - val_accuracy: 0.0079\n",
      "Epoch 173/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1308896640.0000 - accuracy: 0.0066 - val_loss: 847383616.0000 - val_accuracy: 0.0079\n",
      "Epoch 174/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308852736.0000 - accuracy: 0.0071 - val_loss: 847342720.0000 - val_accuracy: 0.0069\n",
      "Epoch 175/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308811264.0000 - accuracy: 0.0119 - val_loss: 847296320.0000 - val_accuracy: 0.0060\n",
      "Epoch 176/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308766080.0000 - accuracy: 0.0121 - val_loss: 847253184.0000 - val_accuracy: 0.0050\n",
      "Epoch 177/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308723328.0000 - accuracy: 0.0027 - val_loss: 847212160.0000 - val_accuracy: 0.0060\n",
      "Epoch 178/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308682112.0000 - accuracy: 0.0165 - val_loss: 847168256.0000 - val_accuracy: 0.0050\n",
      "Epoch 179/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308639104.0000 - accuracy: 0.0033 - val_loss: 847128576.0000 - val_accuracy: 0.0079\n",
      "Epoch 180/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308598656.0000 - accuracy: 0.0020 - val_loss: 847085696.0000 - val_accuracy: 0.0169\n",
      "Epoch 181/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308555776.0000 - accuracy: 0.0093 - val_loss: 847040320.0000 - val_accuracy: 0.0129\n",
      "Epoch 182/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1308511232.0000 - accuracy: 0.0033 - val_loss: 846993984.0000 - val_accuracy: 0.0208\n",
      "Epoch 183/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1308465792.0000 - accuracy: 0.0321 - val_loss: 846949504.0000 - val_accuracy: 0.0069\n",
      "Epoch 184/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308421632.0000 - accuracy: 0.0063 - val_loss: 846906112.0000 - val_accuracy: 0.0079\n",
      "Epoch 185/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308378624.0000 - accuracy: 0.0082 - val_loss: 846864704.0000 - val_accuracy: 0.0040\n",
      "Epoch 186/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308336768.0000 - accuracy: 0.0247 - val_loss: 846818432.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 187/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308291584.0000 - accuracy: 0.0105 - val_loss: 846771520.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 188/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308245888.0000 - accuracy: 0.0016 - val_loss: 846730112.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 189/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308204032.0000 - accuracy: 0.0000e+00 - val_loss: 846687104.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 190/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308161024.0000 - accuracy: 0.0000e+00 - val_loss: 846644928.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 191/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308118528.0000 - accuracy: 0.0000e+00 - val_loss: 846602048.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 192/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1308076160.0000 - accuracy: 0.0066 - val_loss: 846558272.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 193/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308032896.0000 - accuracy: 0.0000e+00 - val_loss: 846516608.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 194/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307991424.0000 - accuracy: 0.0000e+00 - val_loss: 846472640.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 195/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307948160.0000 - accuracy: 0.0000e+00 - val_loss: 846432960.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 196/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307907456.0000 - accuracy: 0.0000e+00 - val_loss: 846389440.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 197/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307863552.0000 - accuracy: 0.0016 - val_loss: 846354816.0000 - val_accuracy: 0.0417\n",
      "Epoch 198/256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 11ms/step - loss: 1307821568.0000 - accuracy: 0.0099 - val_loss: 846301888.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 199/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307777280.0000 - accuracy: 0.0000e+00 - val_loss: 846262848.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 200/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307737216.0000 - accuracy: 0.0000e+00 - val_loss: 846217728.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 201/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307693568.0000 - accuracy: 0.0000e+00 - val_loss: 846174016.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 202/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1307649280.0000 - accuracy: 7.8616e-04 - val_loss: 846126528.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 203/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307603328.0000 - accuracy: 0.0000e+00 - val_loss: 846084224.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 204/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307561472.0000 - accuracy: 0.0000e+00 - val_loss: 846044416.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 205/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307521024.0000 - accuracy: 0.0000e+00 - val_loss: 845997952.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 206/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307475328.0000 - accuracy: 0.0000e+00 - val_loss: 845954496.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 207/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307431936.0000 - accuracy: 0.0000e+00 - val_loss: 845911744.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 208/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307388672.0000 - accuracy: 0.0000e+00 - val_loss: 845867904.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 209/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307346560.0000 - accuracy: 0.0000e+00 - val_loss: 845825280.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 210/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307303936.0000 - accuracy: 0.0000e+00 - val_loss: 845776384.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 211/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1307255680.0000 - accuracy: 0.0000e+00 - val_loss: 845731520.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 212/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307211648.0000 - accuracy: 0.0000e+00 - val_loss: 845693696.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 213/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307178624.0000 - accuracy: 0.0038 - val_loss: 845653120.0000 - val_accuracy: 0.0089\n",
      "Epoch 214/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307652480.0000 - accuracy: 0.0678 - val_loss: 845615680.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 215/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307093504.0000 - accuracy: 0.0000e+00 - val_loss: 845568768.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 216/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307047680.0000 - accuracy: 0.0000e+00 - val_loss: 845526528.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 217/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307005440.0000 - accuracy: 0.0000e+00 - val_loss: 845485952.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 218/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306964480.0000 - accuracy: 0.0000e+00 - val_loss: 845444032.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 219/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306922112.0000 - accuracy: 0.0000e+00 - val_loss: 845396288.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 220/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306875648.0000 - accuracy: 0.0000e+00 - val_loss: 845351680.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 221/256\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1306832128.0000 - accuracy: 0.0000e+00 - val_loss: 845308992.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 222/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306789376.0000 - accuracy: 0.0000e+00 - val_loss: 845264192.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 223/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306745600.0000 - accuracy: 0.0000e+00 - val_loss: 845218944.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 224/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306700416.0000 - accuracy: 0.0000e+00 - val_loss: 845173696.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 225/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306655744.0000 - accuracy: 0.0000e+00 - val_loss: 845132736.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 226/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306614144.0000 - accuracy: 0.0000e+00 - val_loss: 845089344.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 227/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306571392.0000 - accuracy: 0.0000e+00 - val_loss: 845047296.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 228/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306529536.0000 - accuracy: 0.0000e+00 - val_loss: 845005376.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 229/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1306487296.0000 - accuracy: 0.0000e+00 - val_loss: 844959168.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 230/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1306443648.0000 - accuracy: 0.0000e+00 - val_loss: 844916608.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 231/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306400896.0000 - accuracy: 0.0000e+00 - val_loss: 844876736.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 232/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306360448.0000 - accuracy: 0.0000e+00 - val_loss: 844834304.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 233/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306318976.0000 - accuracy: 0.0000e+00 - val_loss: 844791296.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 234/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306275328.0000 - accuracy: 0.0000e+00 - val_loss: 844749120.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 235/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306232960.0000 - accuracy: 0.0000e+00 - val_loss: 844708928.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 236/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306193536.0000 - accuracy: 0.0000e+00 - val_loss: 844670080.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 237/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306151936.0000 - accuracy: 0.0000e+00 - val_loss: 844622720.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 238/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306108544.0000 - accuracy: 0.0000e+00 - val_loss: 844580160.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 239/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306064640.0000 - accuracy: 0.0000e+00 - val_loss: 844536320.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 240/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1306021248.0000 - accuracy: 0.0000e+00 - val_loss: 844492608.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 241/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1305977728.0000 - accuracy: 0.0000e+00 - val_loss: 844445376.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 242/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1305932416.0000 - accuracy: 0.0000e+00 - val_loss: 844401216.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 243/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1305887488.0000 - accuracy: 0.0000e+00 - val_loss: 844360576.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 244/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1305847936.0000 - accuracy: 0.0000e+00 - val_loss: 844320960.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 245/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1305805312.0000 - accuracy: 0.0000e+00 - val_loss: 844273472.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 246/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1305761280.0000 - accuracy: 0.0000e+00 - val_loss: 844232384.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 247/256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 11ms/step - loss: 1305716992.0000 - accuracy: 0.0000e+00 - val_loss: 844183680.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 248/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1305670784.0000 - accuracy: 0.0000e+00 - val_loss: 844139840.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 249/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1305629440.0000 - accuracy: 0.0000e+00 - val_loss: 844095360.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 250/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1305585408.0000 - accuracy: 0.0058 - val_loss: 844342528.0000 - val_accuracy: 0.0208\n",
      "Epoch 251/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1305623808.0000 - accuracy: 0.0127 - val_loss: 844014336.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 252/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1305502720.0000 - accuracy: 0.0000e+00 - val_loss: 843966464.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 253/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1305456256.0000 - accuracy: 0.0000e+00 - val_loss: 843923840.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 254/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1305413376.0000 - accuracy: 0.0000e+00 - val_loss: 843878592.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 255/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1305368448.0000 - accuracy: 0.0000e+00 - val_loss: 843836672.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 256/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1305326336.0000 - accuracy: 0.0000e+00 - val_loss: 843797376.0000 - val_accuracy: 0.0000e+00\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 72, 4)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_6 (LSTM)                   [(None, 256), (None, 267264      input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_3 (RepeatVector)  (None, 24, 256)      0           lstm_6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_7 (LSTM)                   [(None, 24, 256), (N 525312      repeat_vector_3[0][0]            \n",
      "                                                                 lstm_6[0][1]                     \n",
      "                                                                 lstm_6[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 24, 1)        257         lstm_7[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 792,833\n",
      "Trainable params: 792,833\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Took 19.67 sec for training the model\n",
      "{'train_losses': [1316886272.0, 1316386944.0, 1316285952.0, 1316229504.0, 1316181632.0, 1316133376.0, 1316088192.0, 1316045696.0, 1316002304.0, 1315957376.0, 1315913088.0, 1315868160.0, 1315822848.0, 1315777792.0, 1315733120.0, 1315692160.0, 1315649792.0, 1315604480.0, 1315564160.0, 1315522176.0, 1315483392.0, 1315436032.0, 1315393024.0, 1315346176.0, 1315302016.0, 1315259904.0, 1315214208.0, 1315168640.0, 1315125376.0, 1315085184.0, 1315041664.0, 1314998656.0, 1314955008.0, 1314911872.0, 1314868736.0, 1314826368.0, 1314782464.0, 1314736256.0, 1314694144.0, 1314649088.0, 1314604544.0, 1314561920.0, 1314515072.0, 1314475392.0, 1314431104.0, 1314384384.0, 1314343808.0, 1314301696.0, 1314257792.0, 1314217728.0, 1314173440.0, 1314131712.0, 1314088064.0, 1314041856.0, 1313999872.0, 1313956352.0, 1313911040.0, 1313868160.0, 1313825536.0, 1313780608.0, 1313736960.0, 1313694976.0, 1313653632.0, 1313606272.0, 1314170112.0, 1313529728.0, 1313486208.0, 1313440512.0, 1313398144.0, 1313351552.0, 1313308672.0, 1313267072.0, 1313222272.0, 1313176448.0, 1313131264.0, 1313092096.0, 1313047808.0, 1313009024.0, 1312961152.0, 1312915584.0, 1312873984.0, 1312871808.0, 1312796928.0, 1312745984.0, 1312700288.0, 1312659072.0, 1312613632.0, 1312570496.0, 1312526976.0, 1312482048.0, 1312439168.0, 1312396928.0, 1312354048.0, 1312310912.0, 1312265216.0, 1312221440.0, 1312178560.0, 1312133504.0, 1312090752.0, 1312048128.0, 1312005760.0, 1311960576.0, 1311918848.0, 1311875456.0, 1311832832.0, 1311789696.0, 1311746048.0, 1311699328.0, 1311657472.0, 1311615232.0, 1311573504.0, 1311531264.0, 1311484928.0, 1311442304.0, 1311401088.0, 1311356800.0, 1311312896.0, 1312507264.0, 1311233408.0, 1311187328.0, 1311144448.0, 1311100672.0, 1311057280.0, 1311012224.0, 1310968064.0, 1310926464.0, 1310880896.0, 1310836864.0, 1310795520.0, 1310749824.0, 1310707712.0, 1310665472.0, 1310623872.0, 1310580736.0, 1310536960.0, 1310493824.0, 1310447616.0, 1310405376.0, 1310360704.0, 1310318720.0, 1310275712.0, 1310231552.0, 1310191104.0, 1310150016.0, 1310105856.0, 1310063488.0, 1310017536.0, 1309972352.0, 1309929344.0, 1309884416.0, 1309841920.0, 1309798912.0, 1309754880.0, 1309709568.0, 1309669248.0, 1309628544.0, 1309586944.0, 1309542144.0, 1309498368.0, 1309456128.0, 1309412096.0, 1309371392.0, 1309326592.0, 1309283456.0, 1309238400.0, 1309196032.0, 1309149824.0, 1309110016.0, 1309106304.0, 1309028224.0, 1308981376.0, 1308937856.0, 1308896640.0, 1308852736.0, 1308811264.0, 1308766080.0, 1308723328.0, 1308682112.0, 1308639104.0, 1308598656.0, 1308555776.0, 1308511232.0, 1308465792.0, 1308421632.0, 1308378624.0, 1308336768.0, 1308291584.0, 1308245888.0, 1308204032.0, 1308161024.0, 1308118528.0, 1308076160.0, 1308032896.0, 1307991424.0, 1307948160.0, 1307907456.0, 1307863552.0, 1307821568.0, 1307777280.0, 1307737216.0, 1307693568.0, 1307649280.0, 1307603328.0, 1307561472.0, 1307521024.0, 1307475328.0, 1307431936.0, 1307388672.0, 1307346560.0, 1307303936.0, 1307255680.0, 1307211648.0, 1307178624.0, 1307652480.0, 1307093504.0, 1307047680.0, 1307005440.0, 1306964480.0, 1306922112.0, 1306875648.0, 1306832128.0, 1306789376.0, 1306745600.0, 1306700416.0, 1306655744.0, 1306614144.0, 1306571392.0, 1306529536.0, 1306487296.0, 1306443648.0, 1306400896.0, 1306360448.0, 1306318976.0, 1306275328.0, 1306232960.0, 1306193536.0, 1306151936.0, 1306108544.0, 1306064640.0, 1306021248.0, 1305977728.0, 1305932416.0, 1305887488.0, 1305847936.0, 1305805312.0, 1305761280.0, 1305716992.0, 1305670784.0, 1305629440.0, 1305585408.0, 1305623808.0, 1305502720.0, 1305456256.0, 1305413376.0, 1305368448.0, 1305326336.0], 'val_losses': [855006848.0, 854868352.0, 854807296.0, 854758656.0, 854709312.0, 854663296.0, 854620928.0, 854577728.0, 854532288.0, 854487360.0, 854442176.0, 854396608.0, 854350720.0, 854305664.0, 854264704.0, 854222528.0, 854176512.0, 854136320.0, 854094528.0, 854052096.0, 854010368.0, 853964672.0, 853916928.0, 853872768.0, 853830720.0, 853784192.0, 853737792.0, 853694464.0, 853654464.0, 853611008.0, 853567616.0, 853523904.0, 853480576.0, 853437184.0, 853395264.0, 853350976.0, 853303872.0, 853261632.0, 853215744.0, 853171264.0, 853128896.0, 853080640.0, 853041280.0, 852996864.0, 852948672.0, 852908544.0, 852866304.0, 852822016.0, 852782528.0, 852737344.0, 852695360.0, 852652032.0, 852604736.0, 852562816.0, 852519232.0, 852473472.0, 852430336.0, 852387840.0, 852342400.0, 852298304.0, 852256256.0, 852215488.0, 852166336.0, 852126592.0, 852091008.0, 852047360.0, 852000640.0, 851958656.0, 851911168.0, 851867968.0, 851826560.0, 851781312.0, 851735296.0, 851688896.0, 851650432.0, 851605888.0, 851561152.0, 851518528.0, 851472256.0, 851430720.0, 851387328.0, 851397568.0, 851302080.0, 851255488.0, 851214848.0, 851168512.0, 851125184.0, 851081408.0, 851035840.0, 850992768.0, 850950528.0, 850907840.0, 850864512.0, 850818496.0, 850772544.0, 850730688.0, 850684608.0, 850641984.0, 850599360.0, 850557056.0, 850511296.0, 850469440.0, 850425728.0, 850382848.0, 850338880.0, 850296320.0, 850248000.0, 850206336.0, 850163136.0, 850122048.0, 850079616.0, 850032768.0, 849989824.0, 849948160.0, 849904576.0, 849859648.0, 849817984.0, 849780352.0, 849733120.0, 849690304.0, 849646080.0, 849602880.0, 849556800.0, 849512256.0, 849471104.0, 849424704.0, 849380416.0, 849339072.0, 849292544.0, 849250432.0, 849207616.0, 849166848.0, 849122752.0, 849079168.0, 849034944.0, 848988288.0, 848946304.0, 848900992.0, 848859136.0, 848815616.0, 848770944.0, 848731264.0, 848689280.0, 848645184.0, 848602752.0, 848555328.0, 848510400.0, 848467456.0, 848421248.0, 848379904.0, 848336384.0, 848291968.0, 848245696.0, 848205504.0, 848164544.0, 848123392.0, 848076224.0, 848033280.0, 847990784.0, 847946496.0, 847906240.0, 847860416.0, 847817408.0, 847771136.0, 847728768.0, 847681664.0, 847642304.0, 847603200.0, 847561216.0, 847513216.0, 847469248.0, 847428096.0, 847383616.0, 847342720.0, 847296320.0, 847253184.0, 847212160.0, 847168256.0, 847128576.0, 847085696.0, 847040320.0, 846993984.0, 846949504.0, 846906112.0, 846864704.0, 846818432.0, 846771520.0, 846730112.0, 846687104.0, 846644928.0, 846602048.0, 846558272.0, 846516608.0, 846472640.0, 846432960.0, 846389440.0, 846354816.0, 846301888.0, 846262848.0, 846217728.0, 846174016.0, 846126528.0, 846084224.0, 846044416.0, 845997952.0, 845954496.0, 845911744.0, 845867904.0, 845825280.0, 845776384.0, 845731520.0, 845693696.0, 845653120.0, 845615680.0, 845568768.0, 845526528.0, 845485952.0, 845444032.0, 845396288.0, 845351680.0, 845308992.0, 845264192.0, 845218944.0, 845173696.0, 845132736.0, 845089344.0, 845047296.0, 845005376.0, 844959168.0, 844916608.0, 844876736.0, 844834304.0, 844791296.0, 844749120.0, 844708928.0, 844670080.0, 844622720.0, 844580160.0, 844536320.0, 844492608.0, 844445376.0, 844401216.0, 844360576.0, 844320960.0, 844273472.0, 844232384.0, 844183680.0, 844139840.0, 844095360.0, 844342528.0, 844014336.0, 843966464.0, 843923840.0, 843878592.0, 843836672.0, 843797376.0], 'train_accs': [0.21242137253284454, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04575471580028534, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0003144654037896544, 0.0006289308075793087, 0.0004716981202363968, 0.0001572327018948272, 0.002515723230317235, 0.0, 0.0, 0.0, 0.006918238941580057, 0.023270439356565475, 0.0011006288696080446, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.009748428128659725, 0.0, 0.007075471803545952, 0.0, 0.009591195732355118, 0.0, 0.0, 0.0, 0.0, 0.0, 0.009905660524964333, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12908805906772614, 0.0, 0.007704402785748243, 0.020597483962774277, 0.009748428128659725, 0.0, 0.009905660524964333, 0.002201257972046733, 0.0, 0.009905660524964333, 0.0, 0.009905660524964333, 0.0007861635531298816, 0.0, 0.0, 0.0, 0.0, 0.0, 0.009905660524964333, 0.0, 0.0, 0.0, 0.0, 0.0, 0.030031446367502213, 0.0, 0.0, 0.0, 0.0, 0.009905660524964333, 0.0, 0.009905660524964333, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.009905660524964333, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.058805033564567566, 0.008490566164255142, 0.0036163520999252796, 0.0108490576967597, 0.006603773683309555, 0.007075472269207239, 0.011949685402214527, 0.01210691872984171, 0.0026729560922831297, 0.016509434208273888, 0.003301887074485421, 0.002044025342911482, 0.009276730008423328, 0.0033018868416547775, 0.03207547217607498, 0.006289308425039053, 0.008176101371645927, 0.024685533717274666, 0.010534591041505337, 0.0015723271062597632, 0.0, 0.0, 0.0, 0.006603774148970842, 0.0, 0.0, 0.0, 0.0, 0.0015723269898444414, 0.009905660524964333, 0.0, 0.0, 0.0, 0.0007861635531298816, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0037735849618911743, 0.06776729971170425, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.005817609839141369, 0.012735849246382713, 0.0, 0.0, 0.0, 0.0, 0.0], 'val_accs': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1121031790971756, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0416666679084301, 0.007936508394777775, 0.007936508394777775, 0.007936508394777775, 0.007936508394777775, 0.007936508394777775, 0.006944444961845875, 0.0059523810632526875, 0.004960317630320787, 0.0059523810632526875, 0.004960317630320787, 0.007936508394777775, 0.01686508022248745, 0.012896825559437275, 0.02083333395421505, 0.006944444961845875, 0.007936508394777775, 0.003968254197388887, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0416666679084301, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008928571827709675, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02083333395421505, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'train_acc': 0.0037041814431972853, 'val_acc': 0.0014493428152491106, 'test_nrmse': 0.9894171899128241, 'y_test': [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1200.0, 2500.0, 3300.0, 11300.0, 13800.0, 12200.0, 8100.0, 4400.0, 2500.0, 3000.0, 3700.0, 300.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1300.0, 5800.0, 11300.0, 23400.0, 44600.0, 63500.0, 57800.0, 63900.0, 38600.0, 32400.0, 19400.0, 24300.0, 9700.0, 600.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 1100.0, 5000.0, 14500.0, 42800.0, 57800.0, 72500.0, 76200.0, 61500.0, 48100.0, 51700.0, 20400.0, 11100.0, 8400.0, 2000.0, 1100.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 700.0, 9100.0, 13200.0, 20300.0, 28900.0, 26800.0, 40600.0, 52300.0, 36200.0, 29900.0, 41400.0, 30500.0, 19300.0, 8300.0, 700.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2600.0, 4500.0, 6900.0, 6600.0, 17000.0, 16300.0, 32100.0, 22500.0, 14000.0, 9100.0, 5000.0, 4500.0, 400.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 400.0, 2800.0, 5100.0, 11700.0, 21900.0, 14800.0, 12900.0, 24100.0, 18200.0, 13200.0, 15500.0, 10600.0, 4700.0, 2100.0, 700.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 500.0, 7700.0, 18600.0, 14500.0, 22800.0, 34500.0, 23900.0, 46400.0, 25200.0, 20700.0, 19600.0, 28200.0, 14100.0, 6500.0, 1800.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1500.0, 4300.0, 6200.0, 17500.0, 11300.0, 9600.0, 10600.0, 11800.0, 7700.0, 3700.0, 3700.0, 3500.0, 2100.0, 900.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 400.0, 4100.0, 13300.0, 29500.0, 54500.0, 48100.0, 59800.0, 68100.0, 63900.0, 50800.0, 55000.0, 34800.0, 11000.0, 1600.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 400.0, 4600.0, 20100.0, 37100.0, 50200.0, 62400.0, 49300.0, 52100.0, 47400.0, 57700.0, 45600.0, 22000.0, 12600.0, 6500.0, 800.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 400.0, 4700.0, 7700.0, 29200.0, 28200.0, 29100.0, 42000.0, 41400.0, 26800.0, 13400.0, 6500.0, 3400.0, 900.0, 200.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 900.0, 4900.0, 9800.0, 13500.0, 25300.0, 29700.0, 41500.0, 24900.0, 8400.0, 17300.0, 14100.0, 2200.0, 500.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 300.0, 5600.0, 12200.0, 22100.0, 28200.0, 32800.0, 48700.0, 38200.0, 42600.0, 30200.0, 28600.0, 21100.0, 16000.0, 8000.0, 400.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 100.0, 700.0, 1900.0, 4000.0, 5500.0, 2700.0, 4300.0, 4600.0, 4100.0, 3800.0, 1800.0, 1000.0, 1000.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 400.0, 1200.0, 4300.0, 4300.0, 6000.0, 3700.0, 2000.0, 5300.0, 2800.0, 1200.0, 400.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 400.0, 3200.0, 6900.0, 12100.0, 31800.0, 31700.0, 44200.0, 34900.0, 24800.0, 32300.0, 21000.0, 16600.0, 7000.0, 3300.0, 200.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1400.0, 5100.0, 12300.0, 13700.0, 13200.0, 9700.0, 15500.0, 12700.0, 8200.0, 11100.0, 8300.0, 5200.0, 1200.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5200.0, 14100.0, 17500.0, 8400.0, 9800.0, 26200.0, 48100.0, 63700.0, 46200.0, 38200.0, 26100.0, 14000.0, 7200.0, 700.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1500.0, 8100.0, 19000.0, 22500.0, 22100.0, 53000.0, 41900.0, 33200.0, 50300.0, 43700.0, 35100.0, 20800.0, 6100.0, 800.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2000.0, 8200.0, 8100.0, 14400.0, 35800.0, 27800.0, 25000.0, 23000.0, 9000.0, 12300.0, 22200.0, 9800.0, 2200.0, 100.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 700.0, 2000.0, 4800.0, 5800.0, 7500.0, 6200.0, 8800.0, 9800.0, 7300.0, 6000.0, 4100.0, 1300.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 100.0, 600.0, 6400.0, 9800.0, 5400.0, 22000.0, 29800.0, 34600.0, 34400.0, 27500.0, 16100.0, 6300.0, 3500.0, 800.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 400.0, 8400.0, 7500.0, 8500.0, 22200.0, 28400.0, 30500.0, 34800.0, 40100.0, 52300.0, 32100.0, 26000.0, 9800.0, 2100.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1500.0, 5200.0, 6200.0, 8400.0, 10800.0, 10700.0, 10700.0, 12900.0, 14000.0, 10700.0, 14700.0, 7300.0, 3900.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 700.0, 500.0, 4700.0, 3200.0, 2400.0, 2100.0, 2100.0, 3100.0, 2000.0, 1400.0, 2100.0, 400.0, 400.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1200.0, 2100.0, 2600.0, 6900.0, 8100.0, 11100.0, 6500.0, 3000.0, 11400.0, 16600.0, 8100.0, 4700.0, 5000.0, 700.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 100.0, 2300.0, 4300.0, 15000.0, 15100.0, 27600.0, 32000.0, 56800.0, 19500.0, 32900.0, 25600.0, 9600.0, 20500.0, 2500.0, 100.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4200.0, 11100.0, 29600.0, 40300.0, 50900.0, 28700.0, 50700.0, 27300.0, 32500.0, 37200.0, 22900.0, 17800.0, 4000.0, 200.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1400.0, 4600.0, 6900.0, 11400.0, 15900.0, 23200.0, 19200.0, 15300.0, 5200.0, 5200.0, 1100.0, 1200.0, 200.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1700.0, 7700.0, 12500.0, 14000.0, 18700.0, 14500.0, 14300.0, 17900.0, 10400.0, 5900.0, 11400.0, 4200.0, 700.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 100.0, 2500.0, 6000.0, 19200.0, 20500.0, 16900.0, 15900.0, 18400.0, 9800.0, 8100.0, 7400.0, 8500.0, 3600.0, 6900.0, 100.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1700.0, 6000.0, 6400.0, 22200.0, 41100.0, 27600.0, 25900.0, 29600.0, 18500.0, 6900.0, 2500.0, 4000.0, 3900.0, 100.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3600.0, 11800.0, 29000.0, 39600.0, 58800.0, 61400.0, 44100.0, 45200.0, 46000.0, 28000.0, 29900.0, 8200.0, 2700.0, 400.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2600.0, 10400.0, 26400.0, 42400.0, 54500.0, 57900.0, 49900.0, 35700.0, 20600.0, 17300.0, 10700.0, 8500.0, 3900.0, 300.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1400.0, 11900.0, 21100.0, 22900.0, 46500.0, 35400.0, 44000.0, 43200.0, 31300.0, 20700.0, 13300.0, 8500.0, 4100.0, 300.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2100.0, 12700.0, 8700.0, 19600.0, 17900.0, 17800.0, 33400.0, 34900.0, 28400.0, 13700.0, 7700.0, 10900.0, 3000.0, 100.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3200.0, 10600.0, 19700.0, 21300.0, 34300.0, 35200.0, 36900.0, 38900.0, 40000.0, 15700.0, 8400.0, 6900.0, 2800.0, 100.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1500.0, 7600.0, 13000.0, 12000.0, 6000.0, 11000.0, 13900.0, 15300.0, 10200.0, 21100.0, 10200.0, 6100.0, 1300.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 800.0, 900.0, 1000.0, 2000.0, 2400.0, 4400.0, 3200.0, 2000.0, 3300.0, 3000.0, 5700.0, 1000.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 500.0, 2200.0, 1900.0, 3400.0, 4600.0, 5200.0, 3700.0, 3900.0, 400.0, 100.0, 100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 900.0, 6600.0, 100.0, 800.0, 1800.0, 10500.0, 4200.0, 7000.0, 2400.0, 2700.0, 1900.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3100.0, 10400.0, 23800.0, 30300.0, 67400.0, 36400.0, 34800.0, 56300.0, 31600.0, 25100.0, 14500.0, 7700.0, 1300.0, 650.0, 0.0, 0.0, 0.0, 0.0]], 'y_pred': [[2.01326060295105, 19.534543991088867, 47.73702621459961, 90.49929809570312, 149.80136108398438, 248.74249267578125, 346.1897888183594, 347.3995056152344, 347.54388427734375, 347.5635070800781, 347.566162109375, 347.5665283203125, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875], [1.5644848346710205, 17.67378807067871, 44.29745101928711, 86.92292022705078, 147.02047729492188, 244.83535766601562, 346.0396728515625, 347.3872375488281, 347.5422058105469, 347.56329345703125, 347.56610107421875, 347.5664978027344, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875], [4.254169464111328, 29.643798828125, 68.40546417236328, 121.03044891357422, 193.24429321289062, 331.8167724609375, 347.10601806640625, 347.5039367675781, 347.55810546875, 347.56549072265625, 347.56646728515625, 347.56658935546875, 347.5666198730469, 347.5666198730469, 347.5666198730469, 347.5666198730469, 347.5666198730469, 347.5666198730469, 347.5666198730469, 347.5666198730469, 347.5666198730469, 347.5666198730469, 347.5666198730469, 347.5666198730469], [7.866708755493164, 38.84389877319336, 78.15165710449219, 122.02910614013672, 183.84255981445312, 314.4587097167969, 347.0367126464844, 347.4945373535156, 347.55682373046875, 347.5653076171875, 347.56646728515625, 347.5665588378906, 347.5666198730469, 347.5666198730469, 347.5666198730469, 347.5666198730469, 347.5666198730469, 347.5666198730469, 347.5666198730469, 347.5666198730469, 347.5666198730469, 347.5666198730469, 347.5666198730469, 347.5666198730469], [3.5834367275238037, 24.836179733276367, 55.72047805786133, 93.84629821777344, 146.62277221679688, 230.53579711914062, 345.3211364746094, 347.3789367675781, 347.54107666015625, 347.5631103515625, 347.5660705566406, 347.5665283203125, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875], [2.518008232116699, 21.040817260742188, 49.40618896484375, 88.95539093017578, 143.94293212890625, 229.62631225585938, 345.22216796875, 347.3673095703125, 347.5395202636719, 347.5628967285156, 347.5660705566406, 347.5664978027344, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875], [3.3710148334503174, 24.523759841918945, 56.04766082763672, 97.10527801513672, 153.55288696289062, 250.83154296875, 346.32611083984375, 347.4153747558594, 347.5460510253906, 347.5638427734375, 347.5662536621094, 347.5665588378906, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875], [2.923172950744629, 22.920751571655273, 53.40742111206055, 94.94437408447266, 152.04144287109375, 249.0615234375, 346.2591552734375, 347.4090881347656, 347.545166015625, 347.5636901855469, 347.5662536621094, 347.5665283203125, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875], [2.136749267578125, 19.495508193969727, 46.51557159423828, 85.74514770507812, 140.78860473632812, 224.11599731445312, 344.5642395019531, 347.34857177734375, 347.5369873046875, 347.56256103515625, 347.5660400390625, 347.5664978027344, 347.5665588378906, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875], [2.9400720596313477, 23.331735610961914, 54.89119338989258, 98.78524017333984, 158.46322631835938, 266.6151428222656, 346.5642395019531, 347.43408203125, 347.5486145019531, 347.564208984375, 347.5662536621094, 347.5665588378906, 347.56658935546875, 347.5666198730469, 347.5666198730469, 347.5666198730469, 347.5666198730469, 347.5666198730469, 347.5666198730469, 347.5666198730469, 347.5666198730469, 347.5666198730469, 347.5666198730469, 347.5666198730469], [2.878275156021118, 22.972585678100586, 53.95173645019531, 96.81745147705078, 155.43426513671875, 258.7198791503906, 346.4525451660156, 347.4231872558594, 347.547119140625, 347.5639343261719, 347.5662536621094, 347.5665588378906, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875], [1.8925302028656006, 18.817739486694336, 45.935569763183594, 87.1043472290039, 144.83697509765625, 236.42706298828125, 345.70086669921875, 347.37469482421875, 347.5404968261719, 347.56304931640625, 347.56610107421875, 347.5664978027344, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875], [3.933093547821045, 27.222745895385742, 62.088314056396484, 107.69503784179688, 169.26913452148438, 290.9081115722656, 346.8224182128906, 347.4656677246094, 347.55291748046875, 347.56475830078125, 347.56634521484375, 347.5665588378906, 347.5666198730469, 347.5666198730469, 347.5666198730469, 347.5666198730469, 347.5666198730469, 347.5666198730469, 347.5666198730469, 347.5666198730469, 347.5666198730469, 347.5666198730469, 347.5666198730469, 347.5666198730469], [4.662870407104492, 29.00401496887207, 63.7915153503418, 105.65502166748047, 163.22573852539062, 272.483154296875, 346.6921081542969, 347.4498596191406, 347.55078125, 347.564453125, 347.5662841796875, 347.5665588378906, 347.5666198730469, 347.5666198730469, 347.5666198730469, 347.5666198730469, 347.5666198730469, 347.5666198730469, 347.5666198730469, 347.5666198730469, 347.5666198730469, 347.5666198730469, 347.5666198730469, 347.5666198730469], [2.503807306289673, 20.85068130493164, 48.833309173583984, 87.52379608154297, 141.37265014648438, 223.04745483398438, 344.39093017578125, 347.3499450683594, 347.53717041015625, 347.5625915527344, 347.5660400390625, 347.5664978027344, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875], [1.7500839233398438, 17.83169937133789, 43.39567947387695, 82.24097442626953, 137.5244140625, 219.0048828125, 343.6968688964844, 347.32757568359375, 347.5340881347656, 347.5621643066406, 347.56597900390625, 347.5664978027344, 347.5665588378906, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875], [3.9772753715515137, 27.38711929321289, 62.349056243896484, 108.00984191894531, 169.65240478515625, 291.681884765625, 346.8298645019531, 347.4666442871094, 347.5530090332031, 347.56475830078125, 347.56634521484375, 347.5665588378906, 347.5666198730469, 347.5666198730469, 347.5666198730469, 347.5666198730469, 347.5666198730469, 347.5666198730469, 347.5666198730469, 347.5666198730469, 347.5666198730469, 347.5666198730469, 347.5666198730469, 347.5666198730469], [3.5914978981018066, 25.322843551635742, 57.347679138183594, 98.09344482421875, 154.17807006835938, 251.43716430664062, 346.3499450683594, 347.4177551269531, 347.54638671875, 347.5638732910156, 347.5662536621094, 347.5665588378906, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875], [3.233196496963501, 24.039522171020508, 55.369476318359375, 96.87784576416016, 153.85009765625, 252.43630981445312, 346.3541564941406, 347.41668701171875, 347.5462341308594, 347.5638427734375, 347.5662536621094, 347.5665588378906, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875], [3.0240707397460938, 23.176727294921875, 53.57777404785156, 94.1690444946289, 150.13723754882812, 243.2470703125, 346.08355712890625, 347.39996337890625, 347.5439453125, 347.5635070800781, 347.566162109375, 347.5665283203125, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875], [2.6346609592437744, 22.008146286010742, 52.17190170288086, 94.78518676757812, 153.22479248046875, 253.9842529296875, 346.35150146484375, 347.4139709472656, 347.54583740234375, 347.5637512207031, 347.5662536621094, 347.5665588378906, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875], [2.4679434299468994, 21.184274673461914, 50.254276275634766, 91.46485137939453, 148.45187377929688, 241.94345092773438, 346.0025634765625, 347.392333984375, 347.54290771484375, 347.5633544921875, 347.5661315917969, 347.5665283203125, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875], [3.827871561050415, 26.72362518310547, 61.13654708862305, 106.2586669921875, 167.25125122070312, 286.2539978027344, 346.7830810546875, 347.46051025390625, 347.5521545410156, 347.56463623046875, 347.5662841796875, 347.5665588378906, 347.5666198730469, 347.5666198730469, 347.5666198730469, 347.5666198730469, 347.5666198730469, 347.5666198730469, 347.5666198730469, 347.5666198730469, 347.5666198730469, 347.5666198730469, 347.5666198730469, 347.5666198730469], [4.771536827087402, 29.175086975097656, 63.71965789794922, 104.38946533203125, 160.6368408203125, 264.7688903808594, 346.611572265625, 347.4414978027344, 347.5495910644531, 347.5643005371094, 347.5662536621094, 347.5665588378906, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875], [3.353766441345215, 24.09583282470703, 54.60186004638672, 93.3453369140625, 146.9381103515625, 232.58023071289062, 345.50042724609375, 347.38189697265625, 347.54150390625, 347.5632019042969, 347.56610107421875, 347.5665283203125, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875], [1.9787235260009766, 18.910219192504883, 45.590877532958984, 85.17157745361328, 140.85897827148438, 225.439208984375, 344.7441711425781, 347.34967041015625, 347.5370788574219, 347.5625915527344, 347.5660400390625, 347.5664978027344, 347.5665588378906, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875], [2.7187225818634033, 22.34696388244629, 52.71049880981445, 95.16938018798828, 153.416015625, 254.0208740234375, 346.3598937988281, 347.41510009765625, 347.5459899902344, 347.56378173828125, 347.5662536621094, 347.5665588378906, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875], [4.199705123901367, 27.497133255004883, 61.228843688964844, 102.83412170410156, 159.97561645507812, 265.07159423828125, 346.5988464355469, 347.4395446777344, 347.5493469238281, 347.5642395019531, 347.5662536621094, 347.5665588378906, 347.56658935546875, 347.5666198730469, 347.5666198730469, 347.5666198730469, 347.5666198730469, 347.5666198730469, 347.5666198730469, 347.5666198730469, 347.5666198730469, 347.5666198730469, 347.5666198730469, 347.5666198730469], [4.095720291137695, 27.15255355834961, 60.81155776977539, 102.75320434570312, 160.24847412109375, 266.3366394042969, 346.6086120605469, 347.4403381347656, 347.5494689941406, 347.56427001953125, 347.5662536621094, 347.5665588378906, 347.56658935546875, 347.5666198730469, 347.5666198730469, 347.5666198730469, 347.5666198730469, 347.5666198730469, 347.5666198730469, 347.5666198730469, 347.5666198730469, 347.5666198730469, 347.5666198730469, 347.5666198730469], [2.523082733154297, 20.756906509399414, 48.209495544433594, 85.67549896240234, 137.86917114257812, 214.10995483398438, 342.2953186035156, 347.3226318359375, 347.533447265625, 347.5621032714844, 347.56597900390625, 347.5664978027344, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875], [1.7969911098480225, 18.1505126953125, 44.25642013549805, 84.13978576660156, 140.62738037109375, 226.38507080078125, 344.857421875, 347.3498229980469, 347.5370788574219, 347.5625915527344, 347.5660400390625, 347.5664978027344, 347.5665588378906, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875], [2.735377073287964, 22.5411319732666, 53.238685607910156, 96.36111450195312, 155.32785034179688, 259.11383056640625, 346.45233154296875, 347.4228210449219, 347.5470275878906, 347.5639343261719, 347.5662536621094, 347.5665588378906, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875], [2.9110162258148193, 22.902250289916992, 53.293556213378906, 94.62088012695312, 151.49624633789062, 247.56301879882812, 346.22052001953125, 347.4068908691406, 347.5448913574219, 347.5635986328125, 347.5661926269531, 347.5665283203125, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875], [3.173703670501709, 24.067609786987305, 55.79798889160156, 98.53069305419922, 156.8856201171875, 261.1050109863281, 346.504150390625, 347.4286193847656, 347.5478820800781, 347.5639953613281, 347.5662536621094, 347.5665588378906, 347.56658935546875, 347.5666198730469, 347.5666198730469, 347.5666198730469, 347.5666198730469, 347.5666198730469, 347.5666198730469, 347.5666198730469, 347.5666198730469, 347.5666198730469, 347.5666198730469, 347.5666198730469], [3.1273722648620605, 23.64553451538086, 54.61016082763672, 95.8822021484375, 152.62472534179688, 249.60159301757812, 346.2832946777344, 347.4114990234375, 347.5455017089844, 347.5637512207031, 347.5662536621094, 347.5665588378906, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875], [2.3219661712646484, 20.489147186279297, 48.8538932800293, 89.72542572021484, 146.49139404296875, 237.697265625, 345.7986755371094, 347.3826904296875, 347.5416259765625, 347.563232421875, 347.5661315917969, 347.5665283203125, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875], [1.9823672771453857, 19.27277183532715, 46.950714111328125, 88.75397491455078, 147.07150268554688, 241.6856689453125, 345.96038818359375, 347.3866271972656, 347.5421447753906, 347.563232421875, 347.5661315917969, 347.5665283203125, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875], [1.708775520324707, 18.185749053955078, 45.01032638549805, 86.93887329101562, 145.93084716796875, 240.78265380859375, 345.902099609375, 347.3814697265625, 347.54144287109375, 347.5631408691406, 347.5661315917969, 347.5664978027344, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875], [2.4710254669189453, 22.52975082397461, 55.12655258178711, 103.86019897460938, 169.15078735351562, 295.8483581542969, 346.80462646484375, 347.46307373046875, 347.5525207519531, 347.564697265625, 347.5662841796875, 347.5665588378906, 347.5666198730469, 347.5666198730469, 347.5666198730469, 347.5666198730469, 347.5666198730469, 347.5666198730469, 347.5666198730469, 347.5666198730469, 347.5666198730469, 347.5666198730469, 347.5666198730469, 347.5666198730469], [4.3233723640441895, 28.363271713256836, 63.49325942993164, 107.90275573730469, 168.208984375, 286.9119873046875, 346.8067321777344, 347.4637145996094, 347.5526428222656, 347.5647277832031, 347.5663146972656, 347.5665588378906, 347.5666198730469, 347.5666198730469, 347.5666198730469, 347.5666198730469, 347.5666198730469, 347.5666198730469, 347.5666198730469, 347.5666198730469, 347.5666198730469, 347.5666198730469, 347.5666198730469, 347.5666198730469], [2.983588695526123, 22.93199348449707, 52.726192474365234, 92.17793273925781, 146.80584716796875, 234.248046875, 345.62237548828125, 347.3829040527344, 347.5416564941406, 347.56317138671875, 347.56610107421875, 347.5665283203125, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875], [2.2433130741119385, 20.708703994750977, 50.07536315917969, 93.47588348388672, 153.13818359375, 256.03424072265625, 346.36859130859375, 347.4139404296875, 347.5458679199219, 347.5637512207031, 347.56622314453125, 347.5665588378906, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875, 347.56658935546875]], 'exp_name': 'solar power prediction using weather features', 'plant': 126, 'spot': 174, 'start_date': '20190820', 'end_date': '20200809', 'batch_size': 64, 'x_frames': 3, 'y_frames': 1, 'hid_dim': 256, 'optim': 'RMSprop', 'activation': 'relu', 'lss': 'MSE', 'lr': 0.001, 'epochs': 256, 'early_stop': 30, 'evaluation': 'NRMSE', 'features': \"[<FeatureType.SUNSHINE: '일조(hr)'>, <FeatureType.HUMIDITY: '습도(%)'>, <FeatureType.WIND_SPEED: '풍속(m/s)'>, <FeatureType.VISIBILITY: '시정(10m)'>]\"}\n",
      "\n",
      "Namespace(activation='relu', batch_size=64, early_stop=30, end_date='20200809', epochs=256, evaluation='NRMSE', exp_name='solar power prediction using weather features', features=\"[<FeatureType.SUNSHINE: '일조(hr)'>, <FeatureType.HUMIDITY: '습도(%)'>, <FeatureType.WIND_SPEED: '풍속(m/s)'>, <FeatureType.VISIBILITY: '시정(10m)'>, <FeatureType.GROUND_TEMPERATURE: '지면온도(°C)'>]\", hid_dim=256, lr=0.001, lss='MSE', optim='RMSprop', plant=126, spot=174, start_date='20190820', x_frames=3, y_frames=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/256\n",
      "5/5 [==============================] - 0s 97ms/step - loss: 1316902912.0000 - accuracy: 0.1909 - val_loss: 855026944.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1316404608.0000 - accuracy: 0.0000e+00 - val_loss: 854883648.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1316299648.0000 - accuracy: 0.0000e+00 - val_loss: 854818240.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1316238848.0000 - accuracy: 0.0000e+00 - val_loss: 854766144.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1316188928.0000 - accuracy: 0.0000e+00 - val_loss: 854716608.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1316140544.0000 - accuracy: 0.0000e+00 - val_loss: 854670272.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1316095232.0000 - accuracy: 0.0000e+00 - val_loss: 854627840.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1316052480.0000 - accuracy: 0.0000e+00 - val_loss: 854584384.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1316008832.0000 - accuracy: 0.0000e+00 - val_loss: 854538944.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315963904.0000 - accuracy: 0.0000e+00 - val_loss: 854493696.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1315919104.0000 - accuracy: 0.0000e+00 - val_loss: 854448448.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315874304.0000 - accuracy: 0.0000e+00 - val_loss: 854403264.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315829504.0000 - accuracy: 0.0000e+00 - val_loss: 854357504.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315784448.0000 - accuracy: 0.0000e+00 - val_loss: 854312384.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315739904.0000 - accuracy: 0.0000e+00 - val_loss: 854271488.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315698944.0000 - accuracy: 0.0000e+00 - val_loss: 854229376.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315656576.0000 - accuracy: 0.0000e+00 - val_loss: 854183360.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315611392.0000 - accuracy: 0.0000e+00 - val_loss: 854143104.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315570944.0000 - accuracy: 0.0000e+00 - val_loss: 854101312.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315528960.0000 - accuracy: 0.0000e+00 - val_loss: 854057280.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1315485056.0000 - accuracy: 0.0000e+00 - val_loss: 854012480.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1315441024.0000 - accuracy: 0.0000e+00 - val_loss: 853971264.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315399552.0000 - accuracy: 0.0000e+00 - val_loss: 853923520.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315352960.0000 - accuracy: 0.0000e+00 - val_loss: 853880320.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315309696.0000 - accuracy: 0.0000e+00 - val_loss: 853840384.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315413120.0000 - accuracy: 3.1447e-04 - val_loss: 853795008.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315224704.0000 - accuracy: 0.0000e+00 - val_loss: 853748096.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1315178880.0000 - accuracy: 0.0000e+00 - val_loss: 853704704.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315135488.0000 - accuracy: 0.0000e+00 - val_loss: 853664640.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1315095168.0000 - accuracy: 0.0000e+00 - val_loss: 853621248.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315051904.0000 - accuracy: 0.0000e+00 - val_loss: 853577920.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315008768.0000 - accuracy: 0.0000e+00 - val_loss: 853534336.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314965504.0000 - accuracy: 0.0000e+00 - val_loss: 853491136.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314922624.0000 - accuracy: 0.0000e+00 - val_loss: 853447808.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314879360.0000 - accuracy: 0.0000e+00 - val_loss: 853406080.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314837376.0000 - accuracy: 0.0000e+00 - val_loss: 853361984.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314793472.0000 - accuracy: 0.0000e+00 - val_loss: 853314880.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/256\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1314746752.0000 - accuracy: 0.0000e+00 - val_loss: 853271680.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1314704128.0000 - accuracy: 0.0000e+00 - val_loss: 853225472.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314658560.0000 - accuracy: 0.0000e+00 - val_loss: 853181120.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314614400.0000 - accuracy: 0.0000e+00 - val_loss: 853138880.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314571648.0000 - accuracy: 0.0000e+00 - val_loss: 853090496.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314524800.0000 - accuracy: 0.0000e+00 - val_loss: 853051072.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314485120.0000 - accuracy: 0.0000e+00 - val_loss: 853006720.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314440576.0000 - accuracy: 0.0000e+00 - val_loss: 852958528.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314394112.0000 - accuracy: 0.0000e+00 - val_loss: 852918400.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314353664.0000 - accuracy: 0.0000e+00 - val_loss: 852876032.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314311424.0000 - accuracy: 0.0000e+00 - val_loss: 852831872.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1314267520.0000 - accuracy: 0.0000e+00 - val_loss: 852792256.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 11ms/step - loss: 1314227712.0000 - accuracy: 0.0000e+00 - val_loss: 852747136.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314183168.0000 - accuracy: 0.0000e+00 - val_loss: 852705280.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314141312.0000 - accuracy: 0.0000e+00 - val_loss: 852661952.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314097664.0000 - accuracy: 0.0000e+00 - val_loss: 852614592.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1314051584.0000 - accuracy: 0.0000e+00 - val_loss: 852572672.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314009600.0000 - accuracy: 0.0000e+00 - val_loss: 852529024.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313966080.0000 - accuracy: 0.0000e+00 - val_loss: 852483328.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313920768.0000 - accuracy: 0.0000e+00 - val_loss: 852440128.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1313878144.0000 - accuracy: 0.0000e+00 - val_loss: 852397696.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313835136.0000 - accuracy: 0.0000e+00 - val_loss: 852352256.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313790336.0000 - accuracy: 0.0000e+00 - val_loss: 852308160.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313746688.0000 - accuracy: 0.0000e+00 - val_loss: 852266048.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313704576.0000 - accuracy: 0.0000e+00 - val_loss: 852225280.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313663488.0000 - accuracy: 0.0000e+00 - val_loss: 852176320.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313616128.0000 - accuracy: 0.0000e+00 - val_loss: 852136448.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313577856.0000 - accuracy: 0.0000e+00 - val_loss: 852095360.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313534848.0000 - accuracy: 0.0000e+00 - val_loss: 852053312.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313515520.0000 - accuracy: 0.0146 - val_loss: 852007808.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1313447936.0000 - accuracy: 0.0000e+00 - val_loss: 851966144.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313405952.0000 - accuracy: 0.0000e+00 - val_loss: 851918848.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313359744.0000 - accuracy: 0.0000e+00 - val_loss: 851876032.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313316992.0000 - accuracy: 0.0000e+00 - val_loss: 851834752.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313275392.0000 - accuracy: 0.0000e+00 - val_loss: 851789504.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313230720.0000 - accuracy: 0.0000e+00 - val_loss: 851743872.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313185024.0000 - accuracy: 0.0000e+00 - val_loss: 851697536.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313139584.0000 - accuracy: 0.0000e+00 - val_loss: 851659136.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313100544.0000 - accuracy: 0.0000e+00 - val_loss: 851614464.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1313056384.0000 - accuracy: 0.0000e+00 - val_loss: 851569920.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313012224.0000 - accuracy: 0.0000e+00 - val_loss: 851527104.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312969472.0000 - accuracy: 0.0000e+00 - val_loss: 851480768.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312924160.0000 - accuracy: 0.0000e+00 - val_loss: 851439232.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312882560.0000 - accuracy: 0.0000e+00 - val_loss: 851395840.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312839680.0000 - accuracy: 0.0000e+00 - val_loss: 851352640.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312796288.0000 - accuracy: 0.0000e+00 - val_loss: 851309440.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312753408.0000 - accuracy: 0.0000e+00 - val_loss: 851263296.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312708352.0000 - accuracy: 0.0000e+00 - val_loss: 851222720.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312667136.0000 - accuracy: 0.0000e+00 - val_loss: 851176512.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1312621824.0000 - accuracy: 0.0000e+00 - val_loss: 851133376.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312578432.0000 - accuracy: 0.0000e+00 - val_loss: 851089536.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312535040.0000 - accuracy: 0.0000e+00 - val_loss: 851043968.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312489984.0000 - accuracy: 0.0000e+00 - val_loss: 851000768.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312447232.0000 - accuracy: 0.0000e+00 - val_loss: 850958528.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312404992.0000 - accuracy: 0.0000e+00 - val_loss: 850918336.0000 - val_accuracy: 0.0069\n",
      "Epoch 93/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312362496.0000 - accuracy: 0.0047 - val_loss: 850872448.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312318976.0000 - accuracy: 0.0000e+00 - val_loss: 850826176.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312273152.0000 - accuracy: 0.0000e+00 - val_loss: 850780544.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1312227968.0000 - accuracy: 0.0000e+00 - val_loss: 850739200.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312186496.0000 - accuracy: 0.0000e+00 - val_loss: 850692864.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312194816.0000 - accuracy: 0.0050 - val_loss: 850650176.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 11ms/step - loss: 1312098688.0000 - accuracy: 0.0000e+00 - val_loss: 850607360.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312055936.0000 - accuracy: 0.0000e+00 - val_loss: 850564928.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 101/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312013696.0000 - accuracy: 0.0000e+00 - val_loss: 850519104.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 102/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311968512.0000 - accuracy: 0.0000e+00 - val_loss: 850477184.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 103/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311926784.0000 - accuracy: 0.0000e+00 - val_loss: 850433472.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 104/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311883264.0000 - accuracy: 0.0000e+00 - val_loss: 850390656.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 105/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311840640.0000 - accuracy: 0.0000e+00 - val_loss: 850346560.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 106/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1311796864.0000 - accuracy: 0.0024 - val_loss: 850303744.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 107/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311753856.0000 - accuracy: 0.0000e+00 - val_loss: 850255296.0000 - val_accuracy: 9.9206e-04\n",
      "Epoch 108/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311707264.0000 - accuracy: 0.0000e+00 - val_loss: 850213760.0000 - val_accuracy: 0.0069\n",
      "Epoch 109/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311665280.0000 - accuracy: 6.2893e-04 - val_loss: 850170624.0000 - val_accuracy: 0.0278\n",
      "Epoch 110/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311622784.0000 - accuracy: 0.0075 - val_loss: 850129600.0000 - val_accuracy: 0.0149\n",
      "Epoch 111/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311581056.0000 - accuracy: 0.0019 - val_loss: 850087552.0000 - val_accuracy: 0.0367\n",
      "Epoch 112/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311538816.0000 - accuracy: 0.0086 - val_loss: 850040128.0000 - val_accuracy: 0.0228\n",
      "Epoch 113/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1311492480.0000 - accuracy: 0.0061 - val_loss: 849997120.0000 - val_accuracy: 0.0308\n",
      "Epoch 114/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311449728.0000 - accuracy: 0.0049 - val_loss: 849960640.0000 - val_accuracy: 0.0516\n",
      "Epoch 115/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1311408512.0000 - accuracy: 0.0101 - val_loss: 849912000.0000 - val_accuracy: 0.0238\n",
      "Epoch 116/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311364224.0000 - accuracy: 0.0052 - val_loss: 849895616.0000 - val_accuracy: 0.0784\n",
      "Epoch 117/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311321088.0000 - accuracy: 0.0079 - val_loss: 849826112.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 118/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311278848.0000 - accuracy: 0.0000e+00 - val_loss: 849781312.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 119/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311234176.0000 - accuracy: 3.1447e-04 - val_loss: 849734976.0000 - val_accuracy: 9.9206e-04\n",
      "Epoch 120/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311188992.0000 - accuracy: 0.0000e+00 - val_loss: 849692672.0000 - val_accuracy: 0.0079\n",
      "Epoch 121/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311147136.0000 - accuracy: 0.0057 - val_loss: 849648896.0000 - val_accuracy: 0.0169\n",
      "Epoch 122/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311103104.0000 - accuracy: 0.0055 - val_loss: 849605376.0000 - val_accuracy: 0.0367\n",
      "Epoch 123/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311084800.0000 - accuracy: 0.0168 - val_loss: 849559936.0000 - val_accuracy: 0.0357\n",
      "Epoch 124/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311014784.0000 - accuracy: 0.0088 - val_loss: 849515264.0000 - val_accuracy: 0.0357\n",
      "Epoch 125/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1310970624.0000 - accuracy: 0.0097 - val_loss: 849474112.0000 - val_accuracy: 0.0377\n",
      "Epoch 126/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310929152.0000 - accuracy: 0.0112 - val_loss: 849427520.0000 - val_accuracy: 0.0387\n",
      "Epoch 127/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310883456.0000 - accuracy: 0.0126 - val_loss: 849383232.0000 - val_accuracy: 0.0397\n",
      "Epoch 128/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310839680.0000 - accuracy: 0.0121 - val_loss: 849342144.0000 - val_accuracy: 0.0407\n",
      "Epoch 129/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310798208.0000 - accuracy: 0.0151 - val_loss: 849295744.0000 - val_accuracy: 0.0417\n",
      "Epoch 130/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310752384.0000 - accuracy: 0.0157 - val_loss: 849253632.0000 - val_accuracy: 0.0417\n",
      "Epoch 131/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310710528.0000 - accuracy: 0.0143 - val_loss: 849211584.0000 - val_accuracy: 0.0486\n",
      "Epoch 132/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310668032.0000 - accuracy: 0.0164 - val_loss: 849171008.0000 - val_accuracy: 0.0486\n",
      "Epoch 133/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310626688.0000 - accuracy: 0.0159 - val_loss: 849126464.0000 - val_accuracy: 0.0486\n",
      "Epoch 134/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1310583168.0000 - accuracy: 0.0182 - val_loss: 849082880.0000 - val_accuracy: 0.0486\n",
      "Epoch 135/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310539520.0000 - accuracy: 0.0154 - val_loss: 849041280.0000 - val_accuracy: 0.0595\n",
      "Epoch 136/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310496000.0000 - accuracy: 0.0223 - val_loss: 848991296.0000 - val_accuracy: 0.0437\n",
      "Epoch 137/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310450048.0000 - accuracy: 0.0186 - val_loss: 848949248.0000 - val_accuracy: 0.0446\n",
      "Epoch 138/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310407936.0000 - accuracy: 0.0132 - val_loss: 848906112.0000 - val_accuracy: 0.0595\n",
      "Epoch 139/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310363264.0000 - accuracy: 0.0162 - val_loss: 848866752.0000 - val_accuracy: 0.0655\n",
      "Epoch 140/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310321536.0000 - accuracy: 0.0143 - val_loss: 848828288.0000 - val_accuracy: 0.0754\n",
      "Epoch 141/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310278656.0000 - accuracy: 0.0107 - val_loss: 848774208.0000 - val_accuracy: 0.0407\n",
      "Epoch 142/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310234752.0000 - accuracy: 0.0165 - val_loss: 848734208.0000 - val_accuracy: 0.0466\n",
      "Epoch 143/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310193792.0000 - accuracy: 0.0145 - val_loss: 848699264.0000 - val_accuracy: 0.0734\n",
      "Epoch 144/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1310152064.0000 - accuracy: 0.0192 - val_loss: 848649088.0000 - val_accuracy: 0.0546\n",
      "Epoch 145/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310108160.0000 - accuracy: 0.0170 - val_loss: 848622912.0000 - val_accuracy: 0.0804\n",
      "Epoch 146/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310066432.0000 - accuracy: 0.0075 - val_loss: 848558592.0000 - val_accuracy: 0.0149\n",
      "Epoch 147/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310020352.0000 - accuracy: 0.0105 - val_loss: 848513152.0000 - val_accuracy: 0.0377\n",
      "Epoch 148/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309974912.0000 - accuracy: 0.0157 - val_loss: 848470400.0000 - val_accuracy: 0.0446\n",
      "Epoch 149/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309931776.0000 - accuracy: 0.0222 - val_loss: 848424192.0000 - val_accuracy: 0.0456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309886208.0000 - accuracy: 0.0220 - val_loss: 848384704.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 151/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1310030976.0000 - accuracy: 0.0352 - val_loss: 848345216.0000 - val_accuracy: 0.0813\n",
      "Epoch 152/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309802240.0000 - accuracy: 0.0219 - val_loss: 848297792.0000 - val_accuracy: 0.0764\n",
      "Epoch 153/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1309757568.0000 - accuracy: 0.0220 - val_loss: 848251072.0000 - val_accuracy: 0.0744\n",
      "Epoch 154/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309712384.0000 - accuracy: 0.0190 - val_loss: 848208640.0000 - val_accuracy: 0.0565\n",
      "Epoch 155/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309672064.0000 - accuracy: 0.0193 - val_loss: 848168256.0000 - val_accuracy: 0.0635\n",
      "Epoch 156/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309631104.0000 - accuracy: 0.0189 - val_loss: 848129664.0000 - val_accuracy: 0.0754\n",
      "Epoch 157/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309589760.0000 - accuracy: 0.0164 - val_loss: 848081664.0000 - val_accuracy: 0.0714\n",
      "Epoch 158/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309544576.0000 - accuracy: 0.0300 - val_loss: 848036544.0000 - val_accuracy: 0.0417\n",
      "Epoch 159/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309501056.0000 - accuracy: 0.0143 - val_loss: 847994880.0000 - val_accuracy: 0.0685\n",
      "Epoch 160/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309458432.0000 - accuracy: 0.0285 - val_loss: 847949696.0000 - val_accuracy: 0.0417\n",
      "Epoch 161/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309414400.0000 - accuracy: 0.0154 - val_loss: 847917376.0000 - val_accuracy: 0.0833\n",
      "Epoch 162/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309373824.0000 - accuracy: 0.0300 - val_loss: 847863616.0000 - val_accuracy: 0.0556\n",
      "Epoch 163/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1309328640.0000 - accuracy: 0.0215 - val_loss: 847822976.0000 - val_accuracy: 0.0744\n",
      "Epoch 164/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309285888.0000 - accuracy: 0.0171 - val_loss: 847776320.0000 - val_accuracy: 0.0665\n",
      "Epoch 165/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309240704.0000 - accuracy: 0.0234 - val_loss: 847732608.0000 - val_accuracy: 0.0258\n",
      "Epoch 166/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309205632.0000 - accuracy: 0.0159 - val_loss: 847684736.0000 - val_accuracy: 0.0407\n",
      "Epoch 167/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309152000.0000 - accuracy: 0.0151 - val_loss: 847645440.0000 - val_accuracy: 0.0476\n",
      "Epoch 168/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309111936.0000 - accuracy: 0.0190 - val_loss: 847609280.0000 - val_accuracy: 0.0645\n",
      "Epoch 169/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309072512.0000 - accuracy: 0.0311 - val_loss: 847565312.0000 - val_accuracy: 0.0546\n",
      "Epoch 170/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309030144.0000 - accuracy: 0.0245 - val_loss: 847518976.0000 - val_accuracy: 0.0595\n",
      "Epoch 171/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308982656.0000 - accuracy: 0.0321 - val_loss: 847474688.0000 - val_accuracy: 0.0575\n",
      "Epoch 172/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1308939520.0000 - accuracy: 0.0358 - val_loss: 847431552.0000 - val_accuracy: 0.0526\n",
      "Epoch 173/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308898432.0000 - accuracy: 0.0256 - val_loss: 847392640.0000 - val_accuracy: 0.0784\n",
      "Epoch 174/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308853888.0000 - accuracy: 0.0330 - val_loss: 847387968.0000 - val_accuracy: 0.0992\n",
      "Epoch 175/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308813056.0000 - accuracy: 0.0292 - val_loss: 847300096.0000 - val_accuracy: 0.0437\n",
      "Epoch 176/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308767232.0000 - accuracy: 0.0484 - val_loss: 847256640.0000 - val_accuracy: 0.0546\n",
      "Epoch 177/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308725120.0000 - accuracy: 0.0252 - val_loss: 847222784.0000 - val_accuracy: 0.0833\n",
      "Epoch 178/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308683392.0000 - accuracy: 0.0368 - val_loss: 847173632.0000 - val_accuracy: 0.0694\n",
      "Epoch 179/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308639232.0000 - accuracy: 0.0418 - val_loss: 847157760.0000 - val_accuracy: 0.0962\n",
      "Epoch 180/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308600320.0000 - accuracy: 0.0327 - val_loss: 847094272.0000 - val_accuracy: 0.0843\n",
      "Epoch 181/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308556544.0000 - accuracy: 0.0399 - val_loss: 847046336.0000 - val_accuracy: 0.0794\n",
      "Epoch 182/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1308511616.0000 - accuracy: 0.0410 - val_loss: 847055360.0000 - val_accuracy: 0.1161\n",
      "Epoch 183/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308466944.0000 - accuracy: 0.0607 - val_loss: 846953344.0000 - val_accuracy: 0.0446\n",
      "Epoch 184/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308423552.0000 - accuracy: 0.0259 - val_loss: 846912960.0000 - val_accuracy: 0.0813\n",
      "Epoch 185/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308379648.0000 - accuracy: 0.0445 - val_loss: 846869248.0000 - val_accuracy: 0.0754\n",
      "Epoch 186/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308336640.0000 - accuracy: 0.0539 - val_loss: 846824768.0000 - val_accuracy: 0.0804\n",
      "Epoch 187/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308292736.0000 - accuracy: 0.0508 - val_loss: 846775936.0000 - val_accuracy: 0.0744\n",
      "Epoch 188/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308245248.0000 - accuracy: 0.0509 - val_loss: 846737920.0000 - val_accuracy: 0.0754\n",
      "Epoch 189/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308204160.0000 - accuracy: 0.0484 - val_loss: 846689984.0000 - val_accuracy: 0.0625\n",
      "Epoch 190/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308161664.0000 - accuracy: 0.0393 - val_loss: 846650048.0000 - val_accuracy: 0.0883\n",
      "Epoch 191/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1308117376.0000 - accuracy: 0.0631 - val_loss: 846611584.0000 - val_accuracy: 0.0873\n",
      "Epoch 192/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308074240.0000 - accuracy: 0.0684 - val_loss: 846564672.0000 - val_accuracy: 0.0813\n",
      "Epoch 193/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308033024.0000 - accuracy: 0.0649 - val_loss: 846520000.0000 - val_accuracy: 0.0833\n",
      "Epoch 194/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307993856.0000 - accuracy: 0.0631 - val_loss: 846475456.0000 - val_accuracy: 0.0804\n",
      "Epoch 195/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307949952.0000 - accuracy: 0.0564 - val_loss: 846435840.0000 - val_accuracy: 0.0813\n",
      "Epoch 196/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307908352.0000 - accuracy: 0.0464 - val_loss: 846393664.0000 - val_accuracy: 0.0923\n",
      "Epoch 197/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307861760.0000 - accuracy: 0.0704 - val_loss: 846356864.0000 - val_accuracy: 0.1052\n",
      "Epoch 198/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307818624.0000 - accuracy: 0.0588 - val_loss: 846309760.0000 - val_accuracy: 0.0982\n",
      "Epoch 199/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307776640.0000 - accuracy: 0.0626 - val_loss: 846295808.0000 - val_accuracy: 0.1230\n",
      "Epoch 200/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307736192.0000 - accuracy: 0.0728 - val_loss: 846227648.0000 - val_accuracy: 0.0972\n",
      "Epoch 201/256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 12ms/step - loss: 1307690752.0000 - accuracy: 0.0794 - val_loss: 846182528.0000 - val_accuracy: 0.0942\n",
      "Epoch 202/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307646336.0000 - accuracy: 0.0877 - val_loss: 846162880.0000 - val_accuracy: 0.1210\n",
      "Epoch 203/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307608320.0000 - accuracy: 0.0747 - val_loss: 846089856.0000 - val_accuracy: 0.0843\n",
      "Epoch 204/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307564160.0000 - accuracy: 0.0819 - val_loss: 846048704.0000 - val_accuracy: 0.0833\n",
      "Epoch 205/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307521536.0000 - accuracy: 0.0869 - val_loss: 846008320.0000 - val_accuracy: 0.1052\n",
      "Epoch 206/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307480192.0000 - accuracy: 0.0825 - val_loss: 845957632.0000 - val_accuracy: 0.0833\n",
      "Epoch 207/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307436288.0000 - accuracy: 0.0800 - val_loss: 845915392.0000 - val_accuracy: 0.0833\n",
      "Epoch 208/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307393024.0000 - accuracy: 0.0827 - val_loss: 845870208.0000 - val_accuracy: 0.0833\n",
      "Epoch 209/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307350784.0000 - accuracy: 0.0829 - val_loss: 845827584.0000 - val_accuracy: 0.0833\n",
      "Epoch 210/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1307308928.0000 - accuracy: 0.0830 - val_loss: 845779840.0000 - val_accuracy: 0.0833\n",
      "Epoch 211/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307260416.0000 - accuracy: 0.0553 - val_loss: 845734272.0000 - val_accuracy: 0.0833\n",
      "Epoch 212/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307216128.0000 - accuracy: 0.0819 - val_loss: 845696320.0000 - val_accuracy: 0.0833\n",
      "Epoch 213/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307177984.0000 - accuracy: 0.0830 - val_loss: 845655488.0000 - val_accuracy: 0.0833\n",
      "Epoch 214/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307138176.0000 - accuracy: 0.0830 - val_loss: 845614912.0000 - val_accuracy: 0.0833\n",
      "Epoch 215/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307096064.0000 - accuracy: 0.0830 - val_loss: 845568768.0000 - val_accuracy: 0.0833\n",
      "Epoch 216/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307051392.0000 - accuracy: 0.0830 - val_loss: 845526912.0000 - val_accuracy: 0.0833\n",
      "Epoch 217/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307009152.0000 - accuracy: 0.0830 - val_loss: 845486784.0000 - val_accuracy: 0.0833\n",
      "Epoch 218/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306968064.0000 - accuracy: 0.0830 - val_loss: 845446400.0000 - val_accuracy: 0.0833\n",
      "Epoch 219/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306926208.0000 - accuracy: 0.0830 - val_loss: 845402304.0000 - val_accuracy: 0.0833\n",
      "Epoch 220/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1306878592.0000 - accuracy: 0.0830 - val_loss: 845352384.0000 - val_accuracy: 0.0833\n",
      "Epoch 221/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306835584.0000 - accuracy: 0.0755 - val_loss: 845310656.0000 - val_accuracy: 0.0833\n",
      "Epoch 222/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306793088.0000 - accuracy: 0.0830 - val_loss: 845265216.0000 - val_accuracy: 0.0833\n",
      "Epoch 223/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1306749440.0000 - accuracy: 0.0827 - val_loss: 845219712.0000 - val_accuracy: 0.0833\n",
      "Epoch 224/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306704256.0000 - accuracy: 0.0829 - val_loss: 845174784.0000 - val_accuracy: 0.0833\n",
      "Epoch 225/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306659456.0000 - accuracy: 0.0821 - val_loss: 845138688.0000 - val_accuracy: 0.0833\n",
      "Epoch 226/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306618240.0000 - accuracy: 0.0830 - val_loss: 845091008.0000 - val_accuracy: 0.0833\n",
      "Epoch 227/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306575360.0000 - accuracy: 0.0796 - val_loss: 845075520.0000 - val_accuracy: 0.0833\n",
      "Epoch 228/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306532480.0000 - accuracy: 0.0799 - val_loss: 845006528.0000 - val_accuracy: 0.0833\n",
      "Epoch 229/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1306491008.0000 - accuracy: 0.0830 - val_loss: 844960640.0000 - val_accuracy: 0.0833\n",
      "Epoch 230/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306447360.0000 - accuracy: 0.0830 - val_loss: 844918080.0000 - val_accuracy: 0.0833\n",
      "Epoch 231/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306404480.0000 - accuracy: 0.0830 - val_loss: 844878400.0000 - val_accuracy: 0.0833\n",
      "Epoch 232/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306364032.0000 - accuracy: 0.0830 - val_loss: 844836160.0000 - val_accuracy: 0.0833\n",
      "Epoch 233/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1306322432.0000 - accuracy: 0.0830 - val_loss: 844793472.0000 - val_accuracy: 0.0833\n",
      "Epoch 234/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306278528.0000 - accuracy: 0.0830 - val_loss: 844751808.0000 - val_accuracy: 0.0833\n",
      "Epoch 235/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306236032.0000 - accuracy: 0.0830 - val_loss: 844710784.0000 - val_accuracy: 0.0833\n",
      "Epoch 236/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306196608.0000 - accuracy: 0.0808 - val_loss: 844675776.0000 - val_accuracy: 0.0833\n",
      "Epoch 237/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306155136.0000 - accuracy: 0.0830 - val_loss: 844624640.0000 - val_accuracy: 0.0833\n",
      "Epoch 238/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306112000.0000 - accuracy: 0.0830 - val_loss: 844582208.0000 - val_accuracy: 0.0833\n",
      "Epoch 239/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1306068096.0000 - accuracy: 0.0830 - val_loss: 844538368.0000 - val_accuracy: 0.0833\n",
      "Epoch 240/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306024320.0000 - accuracy: 0.0830 - val_loss: 844501184.0000 - val_accuracy: 0.0833\n",
      "Epoch 241/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1305980416.0000 - accuracy: 0.0830 - val_loss: 844448896.0000 - val_accuracy: 0.0833\n",
      "Epoch 242/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1305935232.0000 - accuracy: 0.0830 - val_loss: 844405888.0000 - val_accuracy: 0.0833\n",
      "Epoch 243/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1305890560.0000 - accuracy: 0.0830 - val_loss: 844363200.0000 - val_accuracy: 0.0833\n",
      "Epoch 244/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1305850752.0000 - accuracy: 0.0816 - val_loss: 844325440.0000 - val_accuracy: 0.0833\n",
      "Epoch 245/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1305807744.0000 - accuracy: 0.0824 - val_loss: 844299584.0000 - val_accuracy: 0.0933\n",
      "Epoch 246/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1305764864.0000 - accuracy: 0.0807 - val_loss: 844231616.0000 - val_accuracy: 0.0833\n",
      "Epoch 247/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1305720704.0000 - accuracy: 0.0830 - val_loss: 844187136.0000 - val_accuracy: 0.0833\n",
      "Epoch 248/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1305674368.0000 - accuracy: 0.0830 - val_loss: 844142912.0000 - val_accuracy: 0.0833\n",
      "Epoch 249/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1305633024.0000 - accuracy: 0.0830 - val_loss: 844098048.0000 - val_accuracy: 0.0833\n",
      "Epoch 250/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1305588736.0000 - accuracy: 0.0813 - val_loss: 844062592.0000 - val_accuracy: 0.0833\n",
      "Epoch 251/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1305549184.0000 - accuracy: 0.0830 - val_loss: 844020800.0000 - val_accuracy: 0.0833\n",
      "Epoch 252/256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 11ms/step - loss: 1305506304.0000 - accuracy: 0.0830 - val_loss: 843974336.0000 - val_accuracy: 0.0833\n",
      "Epoch 253/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1305459584.0000 - accuracy: 0.0816 - val_loss: 843939968.0000 - val_accuracy: 0.0903\n",
      "Epoch 254/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1305416320.0000 - accuracy: 0.0813 - val_loss: 843881984.0000 - val_accuracy: 0.0833\n",
      "Epoch 255/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1305371520.0000 - accuracy: 0.0794 - val_loss: 843839872.0000 - val_accuracy: 0.0833\n",
      "Epoch 256/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1305330304.0000 - accuracy: 0.0829 - val_loss: 843799616.0000 - val_accuracy: 0.0833\n",
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            [(None, 72, 5)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_8 (LSTM)                   [(None, 256), (None, 268288      input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_4 (RepeatVector)  (None, 24, 256)      0           lstm_8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_9 (LSTM)                   [(None, 24, 256), (N 525312      repeat_vector_4[0][0]            \n",
      "                                                                 lstm_8[0][1]                     \n",
      "                                                                 lstm_8[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 24, 1)        257         lstm_9[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 793,857\n",
      "Trainable params: 793,857\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Took 19.81 sec for training the model\n",
      "{'train_losses': [1316902912.0, 1316404608.0, 1316299648.0, 1316238848.0, 1316188928.0, 1316140544.0, 1316095232.0, 1316052480.0, 1316008832.0, 1315963904.0, 1315919104.0, 1315874304.0, 1315829504.0, 1315784448.0, 1315739904.0, 1315698944.0, 1315656576.0, 1315611392.0, 1315570944.0, 1315528960.0, 1315485056.0, 1315441024.0, 1315399552.0, 1315352960.0, 1315309696.0, 1315413120.0, 1315224704.0, 1315178880.0, 1315135488.0, 1315095168.0, 1315051904.0, 1315008768.0, 1314965504.0, 1314922624.0, 1314879360.0, 1314837376.0, 1314793472.0, 1314746752.0, 1314704128.0, 1314658560.0, 1314614400.0, 1314571648.0, 1314524800.0, 1314485120.0, 1314440576.0, 1314394112.0, 1314353664.0, 1314311424.0, 1314267520.0, 1314227712.0, 1314183168.0, 1314141312.0, 1314097664.0, 1314051584.0, 1314009600.0, 1313966080.0, 1313920768.0, 1313878144.0, 1313835136.0, 1313790336.0, 1313746688.0, 1313704576.0, 1313663488.0, 1313616128.0, 1313577856.0, 1313534848.0, 1313515520.0, 1313447936.0, 1313405952.0, 1313359744.0, 1313316992.0, 1313275392.0, 1313230720.0, 1313185024.0, 1313139584.0, 1313100544.0, 1313056384.0, 1313012224.0, 1312969472.0, 1312924160.0, 1312882560.0, 1312839680.0, 1312796288.0, 1312753408.0, 1312708352.0, 1312667136.0, 1312621824.0, 1312578432.0, 1312535040.0, 1312489984.0, 1312447232.0, 1312404992.0, 1312362496.0, 1312318976.0, 1312273152.0, 1312227968.0, 1312186496.0, 1312194816.0, 1312098688.0, 1312055936.0, 1312013696.0, 1311968512.0, 1311926784.0, 1311883264.0, 1311840640.0, 1311796864.0, 1311753856.0, 1311707264.0, 1311665280.0, 1311622784.0, 1311581056.0, 1311538816.0, 1311492480.0, 1311449728.0, 1311408512.0, 1311364224.0, 1311321088.0, 1311278848.0, 1311234176.0, 1311188992.0, 1311147136.0, 1311103104.0, 1311084800.0, 1311014784.0, 1310970624.0, 1310929152.0, 1310883456.0, 1310839680.0, 1310798208.0, 1310752384.0, 1310710528.0, 1310668032.0, 1310626688.0, 1310583168.0, 1310539520.0, 1310496000.0, 1310450048.0, 1310407936.0, 1310363264.0, 1310321536.0, 1310278656.0, 1310234752.0, 1310193792.0, 1310152064.0, 1310108160.0, 1310066432.0, 1310020352.0, 1309974912.0, 1309931776.0, 1309886208.0, 1310030976.0, 1309802240.0, 1309757568.0, 1309712384.0, 1309672064.0, 1309631104.0, 1309589760.0, 1309544576.0, 1309501056.0, 1309458432.0, 1309414400.0, 1309373824.0, 1309328640.0, 1309285888.0, 1309240704.0, 1309205632.0, 1309152000.0, 1309111936.0, 1309072512.0, 1309030144.0, 1308982656.0, 1308939520.0, 1308898432.0, 1308853888.0, 1308813056.0, 1308767232.0, 1308725120.0, 1308683392.0, 1308639232.0, 1308600320.0, 1308556544.0, 1308511616.0, 1308466944.0, 1308423552.0, 1308379648.0, 1308336640.0, 1308292736.0, 1308245248.0, 1308204160.0, 1308161664.0, 1308117376.0, 1308074240.0, 1308033024.0, 1307993856.0, 1307949952.0, 1307908352.0, 1307861760.0, 1307818624.0, 1307776640.0, 1307736192.0, 1307690752.0, 1307646336.0, 1307608320.0, 1307564160.0, 1307521536.0, 1307480192.0, 1307436288.0, 1307393024.0, 1307350784.0, 1307308928.0, 1307260416.0, 1307216128.0, 1307177984.0, 1307138176.0, 1307096064.0, 1307051392.0, 1307009152.0, 1306968064.0, 1306926208.0, 1306878592.0, 1306835584.0, 1306793088.0, 1306749440.0, 1306704256.0, 1306659456.0, 1306618240.0, 1306575360.0, 1306532480.0, 1306491008.0, 1306447360.0, 1306404480.0, 1306364032.0, 1306322432.0, 1306278528.0, 1306236032.0, 1306196608.0, 1306155136.0, 1306112000.0, 1306068096.0, 1306024320.0, 1305980416.0, 1305935232.0, 1305890560.0, 1305850752.0, 1305807744.0, 1305764864.0, 1305720704.0, 1305674368.0, 1305633024.0, 1305588736.0, 1305549184.0, 1305506304.0, 1305459584.0, 1305416320.0, 1305371520.0, 1305330304.0], 'val_losses': [855026944.0, 854883648.0, 854818240.0, 854766144.0, 854716608.0, 854670272.0, 854627840.0, 854584384.0, 854538944.0, 854493696.0, 854448448.0, 854403264.0, 854357504.0, 854312384.0, 854271488.0, 854229376.0, 854183360.0, 854143104.0, 854101312.0, 854057280.0, 854012480.0, 853971264.0, 853923520.0, 853880320.0, 853840384.0, 853795008.0, 853748096.0, 853704704.0, 853664640.0, 853621248.0, 853577920.0, 853534336.0, 853491136.0, 853447808.0, 853406080.0, 853361984.0, 853314880.0, 853271680.0, 853225472.0, 853181120.0, 853138880.0, 853090496.0, 853051072.0, 853006720.0, 852958528.0, 852918400.0, 852876032.0, 852831872.0, 852792256.0, 852747136.0, 852705280.0, 852661952.0, 852614592.0, 852572672.0, 852529024.0, 852483328.0, 852440128.0, 852397696.0, 852352256.0, 852308160.0, 852266048.0, 852225280.0, 852176320.0, 852136448.0, 852095360.0, 852053312.0, 852007808.0, 851966144.0, 851918848.0, 851876032.0, 851834752.0, 851789504.0, 851743872.0, 851697536.0, 851659136.0, 851614464.0, 851569920.0, 851527104.0, 851480768.0, 851439232.0, 851395840.0, 851352640.0, 851309440.0, 851263296.0, 851222720.0, 851176512.0, 851133376.0, 851089536.0, 851043968.0, 851000768.0, 850958528.0, 850918336.0, 850872448.0, 850826176.0, 850780544.0, 850739200.0, 850692864.0, 850650176.0, 850607360.0, 850564928.0, 850519104.0, 850477184.0, 850433472.0, 850390656.0, 850346560.0, 850303744.0, 850255296.0, 850213760.0, 850170624.0, 850129600.0, 850087552.0, 850040128.0, 849997120.0, 849960640.0, 849912000.0, 849895616.0, 849826112.0, 849781312.0, 849734976.0, 849692672.0, 849648896.0, 849605376.0, 849559936.0, 849515264.0, 849474112.0, 849427520.0, 849383232.0, 849342144.0, 849295744.0, 849253632.0, 849211584.0, 849171008.0, 849126464.0, 849082880.0, 849041280.0, 848991296.0, 848949248.0, 848906112.0, 848866752.0, 848828288.0, 848774208.0, 848734208.0, 848699264.0, 848649088.0, 848622912.0, 848558592.0, 848513152.0, 848470400.0, 848424192.0, 848384704.0, 848345216.0, 848297792.0, 848251072.0, 848208640.0, 848168256.0, 848129664.0, 848081664.0, 848036544.0, 847994880.0, 847949696.0, 847917376.0, 847863616.0, 847822976.0, 847776320.0, 847732608.0, 847684736.0, 847645440.0, 847609280.0, 847565312.0, 847518976.0, 847474688.0, 847431552.0, 847392640.0, 847387968.0, 847300096.0, 847256640.0, 847222784.0, 847173632.0, 847157760.0, 847094272.0, 847046336.0, 847055360.0, 846953344.0, 846912960.0, 846869248.0, 846824768.0, 846775936.0, 846737920.0, 846689984.0, 846650048.0, 846611584.0, 846564672.0, 846520000.0, 846475456.0, 846435840.0, 846393664.0, 846356864.0, 846309760.0, 846295808.0, 846227648.0, 846182528.0, 846162880.0, 846089856.0, 846048704.0, 846008320.0, 845957632.0, 845915392.0, 845870208.0, 845827584.0, 845779840.0, 845734272.0, 845696320.0, 845655488.0, 845614912.0, 845568768.0, 845526912.0, 845486784.0, 845446400.0, 845402304.0, 845352384.0, 845310656.0, 845265216.0, 845219712.0, 845174784.0, 845138688.0, 845091008.0, 845075520.0, 845006528.0, 844960640.0, 844918080.0, 844878400.0, 844836160.0, 844793472.0, 844751808.0, 844710784.0, 844675776.0, 844624640.0, 844582208.0, 844538368.0, 844501184.0, 844448896.0, 844405888.0, 844363200.0, 844325440.0, 844299584.0, 844231616.0, 844187136.0, 844142912.0, 844098048.0, 844062592.0, 844020800.0, 843974336.0, 843939968.0, 843881984.0, 843839872.0, 843799616.0], 'train_accs': [0.19088050723075867, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0003144654037896544, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0146226417273283, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004716981202363968, 0.0, 0.0, 0.0, 0.0, 0.00503144646063447, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002358490601181984, 0.0, 0.0, 0.0006289308075793087, 0.007547169923782349, 0.0018867924809455872, 0.008647799491882324, 0.006132076028734446, 0.004874214064329863, 0.01006289292126894, 0.005188679788261652, 0.007861635647714138, 0.0, 0.0003144654037896544, 0.0, 0.0056603774428367615, 0.005503144580870867, 0.016823899000883102, 0.008805031888186932, 0.009748428128659725, 0.011163521558046341, 0.012578616850078106, 0.012106917798519135, 0.015094341710209846, 0.015723271295428276, 0.014308176003396511, 0.016352202743291855, 0.015880504623055458, 0.018238995224237442, 0.015408805571496487, 0.02232704497873783, 0.018553458154201508, 0.01320754736661911, 0.016194969415664673, 0.014308176003396511, 0.010691823437809944, 0.016509434208273888, 0.014465409331023693, 0.019182391464710236, 0.016981132328510284, 0.007547169923782349, 0.010534591041505337, 0.015723271295428276, 0.02216981165111065, 0.022012578323483467, 0.035220127552747726, 0.021855346858501434, 0.022012580186128616, 0.019025158137083054, 0.019339624792337418, 0.01886792480945587, 0.016352202743291855, 0.030031446367502213, 0.014308176003396511, 0.02845912054181099, 0.015408805571496487, 0.030031446367502213, 0.02154088020324707, 0.017138365656137466, 0.023427672684192657, 0.015880504623055458, 0.015094339847564697, 0.019025158137083054, 0.031132075935602188, 0.024528304114937782, 0.03207547590136528, 0.035849057137966156, 0.02562893182039261, 0.033018868416547775, 0.0292452834546566, 0.04842767491936684, 0.025157231837511063, 0.03679245337843895, 0.04182389751076698, 0.03270440548658371, 0.039937108755111694, 0.04103773459792137, 0.06069182604551315, 0.025943398475646973, 0.04449685662984848, 0.053930819034576416, 0.05078616738319397, 0.05094340071082115, 0.04842767119407654, 0.039308175444602966, 0.06305031478404999, 0.06839623302221298, 0.06493711471557617, 0.06305031478404999, 0.05644654855132103, 0.04638364911079407, 0.07044024765491486, 0.058805033564567566, 0.06257861852645874, 0.07279874384403229, 0.07940251380205154, 0.0877358540892601, 0.07468553632497787, 0.08191823959350586, 0.08694969117641449, 0.08254718035459518, 0.08003144711256027, 0.08270440250635147, 0.08286163955926895, 0.08301886916160583, 0.05534591153264046, 0.08191823959350586, 0.08301887661218643, 0.08301886916160583, 0.08301887661218643, 0.08301886916160583, 0.08301887661218643, 0.08301887661218643, 0.08301887661218643, 0.08301886916160583, 0.07547170668840408, 0.08301886916160583, 0.08270440995693207, 0.08286163955926895, 0.08207547664642334, 0.08301887661218643, 0.07955975085496902, 0.07987421751022339, 0.08301886916160583, 0.08301886916160583, 0.08301886916160583, 0.08301886916160583, 0.08301886916160583, 0.08301886916160583, 0.08301886916160583, 0.08081761747598648, 0.08301886916160583, 0.08301886916160583, 0.08301886916160583, 0.08301887661218643, 0.08301886916160583, 0.08301886916160583, 0.08301886916160583, 0.08160378038883209, 0.0823899358510971, 0.080660380423069, 0.08301886916160583, 0.08301886916160583, 0.08301886916160583, 0.08128931373357773, 0.08301887661218643, 0.08301887661218643, 0.08160378038883209, 0.08128931373357773, 0.07940252125263214, 0.08286163955926895], 'val_accs': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.006944444961845875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0009920635493472219, 0.006944444961845875, 0.0277777798473835, 0.014880952425301075, 0.0367063507437706, 0.02281746082007885, 0.0307539701461792, 0.0515873022377491, 0.02380952425301075, 0.078373022377491, 0.0, 0.0, 0.0009920635493472219, 0.007936508394777775, 0.01686508022248745, 0.0367063507437706, 0.0357142873108387, 0.0357142873108387, 0.0376984179019928, 0.0386904776096344, 0.0396825410425663, 0.0406746082007885, 0.0416666679084301, 0.0416666679084301, 0.0486111119389534, 0.0486111119389534, 0.0486111119389534, 0.0486111119389534, 0.0595238097012043, 0.0436507984995842, 0.0446428582072258, 0.0595238097012043, 0.065476194024086, 0.075396828353405, 0.0406746082007885, 0.0466269887983799, 0.0734127014875412, 0.0545634925365448, 0.0803571417927742, 0.014880952425301075, 0.0376984179019928, 0.0446428582072258, 0.0456349216401577, 0.0, 0.081349216401577, 0.0763888955116272, 0.0744047686457634, 0.0565476194024086, 0.0634920671582222, 0.0753968358039856, 0.0714285746216774, 0.0416666679084301, 0.068452388048172, 0.0416666679084301, 0.0833333358168602, 0.0555555522441864, 0.0744047686457634, 0.0664682537317276, 0.02579365484416485, 0.0406746082007885, 0.0476190485060215, 0.0644841268658638, 0.0545634925365448, 0.0595238097012043, 0.0575396828353405, 0.0525793619453907, 0.0783730149269104, 0.0992063581943512, 0.0436507984995842, 0.0545634925365448, 0.0833333358168602, 0.0694444477558136, 0.0962301641702652, 0.0843254029750824, 0.0793650820851326, 0.1160714253783226, 0.0446428582072258, 0.081349216401577, 0.0753968358039856, 0.0803571417927742, 0.0744047611951828, 0.0753968358039856, 0.0625000074505806, 0.08829365670681, 0.0873015969991684, 0.081349216401577, 0.0833333358168602, 0.0803571417927742, 0.081349216401577, 0.092261902987957, 0.1051587387919426, 0.0982142835855484, 0.1230158805847168, 0.0972222238779068, 0.0942460373044014, 0.1210317462682724, 0.0843254029750824, 0.0833333358168602, 0.1051587387919426, 0.0833333358168602, 0.0833333358168602, 0.0833333358168602, 0.0833333358168602, 0.0833333358168602, 0.0833333358168602, 0.0833333358168602, 0.0833333358168602, 0.0833333358168602, 0.0833333358168602, 0.0833333358168602, 0.0833333358168602, 0.0833333358168602, 0.0833333358168602, 0.0833333358168602, 0.0833333358168602, 0.0833333358168602, 0.0833333358168602, 0.0833333358168602, 0.0833333358168602, 0.0833333358168602, 0.0833333358168602, 0.0833333358168602, 0.0833333358168602, 0.0833333358168602, 0.0833333358168602, 0.0833333358168602, 0.0833333358168602, 0.0833333358168602, 0.0833333358168602, 0.0833333358168602, 0.0833333358168602, 0.0833333358168602, 0.0833333358168602, 0.0833333358168602, 0.0833333358168602, 0.0833333358168602, 0.0833333358168602, 0.0833333358168602, 0.0932539775967598, 0.0833333358168602, 0.0833333358168602, 0.0833333358168602, 0.0833333358168602, 0.0833333358168602, 0.0833333358168602, 0.0833333358168602, 0.0902777835726738, 0.0833333358168602, 0.0833333358168602, 0.0833333358168602], 'train_acc': 0.027921089968458546, 'val_acc': 0.039302766997025174, 'test_nrmse': 0.9894181247351195, 'y_test': [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1200.0, 2500.0, 3300.0, 11300.0, 13800.0, 12200.0, 8100.0, 4400.0, 2500.0, 3000.0, 3700.0, 300.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1300.0, 5800.0, 11300.0, 23400.0, 44600.0, 63500.0, 57800.0, 63900.0, 38600.0, 32400.0, 19400.0, 24300.0, 9700.0, 600.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 1100.0, 5000.0, 14500.0, 42800.0, 57800.0, 72500.0, 76200.0, 61500.0, 48100.0, 51700.0, 20400.0, 11100.0, 8400.0, 2000.0, 1100.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 700.0, 9100.0, 13200.0, 20300.0, 28900.0, 26800.0, 40600.0, 52300.0, 36200.0, 29900.0, 41400.0, 30500.0, 19300.0, 8300.0, 700.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2600.0, 4500.0, 6900.0, 6600.0, 17000.0, 16300.0, 32100.0, 22500.0, 14000.0, 9100.0, 5000.0, 4500.0, 400.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 400.0, 2800.0, 5100.0, 11700.0, 21900.0, 14800.0, 12900.0, 24100.0, 18200.0, 13200.0, 15500.0, 10600.0, 4700.0, 2100.0, 700.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 500.0, 7700.0, 18600.0, 14500.0, 22800.0, 34500.0, 23900.0, 46400.0, 25200.0, 20700.0, 19600.0, 28200.0, 14100.0, 6500.0, 1800.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1500.0, 4300.0, 6200.0, 17500.0, 11300.0, 9600.0, 10600.0, 11800.0, 7700.0, 3700.0, 3700.0, 3500.0, 2100.0, 900.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 400.0, 4100.0, 13300.0, 29500.0, 54500.0, 48100.0, 59800.0, 68100.0, 63900.0, 50800.0, 55000.0, 34800.0, 11000.0, 1600.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 400.0, 4600.0, 20100.0, 37100.0, 50200.0, 62400.0, 49300.0, 52100.0, 47400.0, 57700.0, 45600.0, 22000.0, 12600.0, 6500.0, 800.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 400.0, 4700.0, 7700.0, 29200.0, 28200.0, 29100.0, 42000.0, 41400.0, 26800.0, 13400.0, 6500.0, 3400.0, 900.0, 200.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 900.0, 4900.0, 9800.0, 13500.0, 25300.0, 29700.0, 41500.0, 24900.0, 8400.0, 17300.0, 14100.0, 2200.0, 500.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 300.0, 5600.0, 12200.0, 22100.0, 28200.0, 32800.0, 48700.0, 38200.0, 42600.0, 30200.0, 28600.0, 21100.0, 16000.0, 8000.0, 400.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 100.0, 700.0, 1900.0, 4000.0, 5500.0, 2700.0, 4300.0, 4600.0, 4100.0, 3800.0, 1800.0, 1000.0, 1000.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 400.0, 1200.0, 4300.0, 4300.0, 6000.0, 3700.0, 2000.0, 5300.0, 2800.0, 1200.0, 400.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 400.0, 3200.0, 6900.0, 12100.0, 31800.0, 31700.0, 44200.0, 34900.0, 24800.0, 32300.0, 21000.0, 16600.0, 7000.0, 3300.0, 200.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1400.0, 5100.0, 12300.0, 13700.0, 13200.0, 9700.0, 15500.0, 12700.0, 8200.0, 11100.0, 8300.0, 5200.0, 1200.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5200.0, 14100.0, 17500.0, 8400.0, 9800.0, 26200.0, 48100.0, 63700.0, 46200.0, 38200.0, 26100.0, 14000.0, 7200.0, 700.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1500.0, 8100.0, 19000.0, 22500.0, 22100.0, 53000.0, 41900.0, 33200.0, 50300.0, 43700.0, 35100.0, 20800.0, 6100.0, 800.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2000.0, 8200.0, 8100.0, 14400.0, 35800.0, 27800.0, 25000.0, 23000.0, 9000.0, 12300.0, 22200.0, 9800.0, 2200.0, 100.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 700.0, 2000.0, 4800.0, 5800.0, 7500.0, 6200.0, 8800.0, 9800.0, 7300.0, 6000.0, 4100.0, 1300.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 100.0, 600.0, 6400.0, 9800.0, 5400.0, 22000.0, 29800.0, 34600.0, 34400.0, 27500.0, 16100.0, 6300.0, 3500.0, 800.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 400.0, 8400.0, 7500.0, 8500.0, 22200.0, 28400.0, 30500.0, 34800.0, 40100.0, 52300.0, 32100.0, 26000.0, 9800.0, 2100.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1500.0, 5200.0, 6200.0, 8400.0, 10800.0, 10700.0, 10700.0, 12900.0, 14000.0, 10700.0, 14700.0, 7300.0, 3900.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 700.0, 500.0, 4700.0, 3200.0, 2400.0, 2100.0, 2100.0, 3100.0, 2000.0, 1400.0, 2100.0, 400.0, 400.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1200.0, 2100.0, 2600.0, 6900.0, 8100.0, 11100.0, 6500.0, 3000.0, 11400.0, 16600.0, 8100.0, 4700.0, 5000.0, 700.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 100.0, 2300.0, 4300.0, 15000.0, 15100.0, 27600.0, 32000.0, 56800.0, 19500.0, 32900.0, 25600.0, 9600.0, 20500.0, 2500.0, 100.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4200.0, 11100.0, 29600.0, 40300.0, 50900.0, 28700.0, 50700.0, 27300.0, 32500.0, 37200.0, 22900.0, 17800.0, 4000.0, 200.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1400.0, 4600.0, 6900.0, 11400.0, 15900.0, 23200.0, 19200.0, 15300.0, 5200.0, 5200.0, 1100.0, 1200.0, 200.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1700.0, 7700.0, 12500.0, 14000.0, 18700.0, 14500.0, 14300.0, 17900.0, 10400.0, 5900.0, 11400.0, 4200.0, 700.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 100.0, 2500.0, 6000.0, 19200.0, 20500.0, 16900.0, 15900.0, 18400.0, 9800.0, 8100.0, 7400.0, 8500.0, 3600.0, 6900.0, 100.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1700.0, 6000.0, 6400.0, 22200.0, 41100.0, 27600.0, 25900.0, 29600.0, 18500.0, 6900.0, 2500.0, 4000.0, 3900.0, 100.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3600.0, 11800.0, 29000.0, 39600.0, 58800.0, 61400.0, 44100.0, 45200.0, 46000.0, 28000.0, 29900.0, 8200.0, 2700.0, 400.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2600.0, 10400.0, 26400.0, 42400.0, 54500.0, 57900.0, 49900.0, 35700.0, 20600.0, 17300.0, 10700.0, 8500.0, 3900.0, 300.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1400.0, 11900.0, 21100.0, 22900.0, 46500.0, 35400.0, 44000.0, 43200.0, 31300.0, 20700.0, 13300.0, 8500.0, 4100.0, 300.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2100.0, 12700.0, 8700.0, 19600.0, 17900.0, 17800.0, 33400.0, 34900.0, 28400.0, 13700.0, 7700.0, 10900.0, 3000.0, 100.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3200.0, 10600.0, 19700.0, 21300.0, 34300.0, 35200.0, 36900.0, 38900.0, 40000.0, 15700.0, 8400.0, 6900.0, 2800.0, 100.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1500.0, 7600.0, 13000.0, 12000.0, 6000.0, 11000.0, 13900.0, 15300.0, 10200.0, 21100.0, 10200.0, 6100.0, 1300.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 800.0, 900.0, 1000.0, 2000.0, 2400.0, 4400.0, 3200.0, 2000.0, 3300.0, 3000.0, 5700.0, 1000.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 500.0, 2200.0, 1900.0, 3400.0, 4600.0, 5200.0, 3700.0, 3900.0, 400.0, 100.0, 100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 900.0, 6600.0, 100.0, 800.0, 1800.0, 10500.0, 4200.0, 7000.0, 2400.0, 2700.0, 1900.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3100.0, 10400.0, 23800.0, 30300.0, 67400.0, 36400.0, 34800.0, 56300.0, 31600.0, 25100.0, 14500.0, 7700.0, 1300.0, 650.0, 0.0, 0.0, 0.0, 0.0]], 'y_pred': [[0.0, 0.0, 8.182275772094727, 39.34773635864258, 106.60066223144531, 233.0365753173828, 346.1195068359375, 347.31158447265625, 347.4578552246094, 347.4776611328125, 347.48040771484375, 347.480712890625, 347.4807434082031, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125], [0.0, 0.0, 10.947441101074219, 46.59880828857422, 121.53588104248047, 268.1370849609375, 346.5568542480469, 347.3564758300781, 347.4638977050781, 347.47845458984375, 347.4804382324219, 347.4807434082031, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125], [0.0, 0.0, 11.907109260559082, 49.04384231567383, 126.06848907470703, 277.68939208984375, 346.6418151855469, 347.3674011230469, 347.4654235839844, 347.47869873046875, 347.4804992675781, 347.4807434082031, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125], [0.0, 0.0, 11.962655067443848, 49.11428451538086, 125.56639099121094, 274.73016357421875, 346.64544677734375, 347.36810302734375, 347.46551513671875, 347.4787292480469, 347.4804992675781, 347.4807434082031, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125], [0.0, 0.0, 10.696477890014648, 45.8927001953125, 119.19239044189453, 259.4757995605469, 346.52606201171875, 347.353515625, 347.4635314941406, 347.4783935546875, 347.4804382324219, 347.4807434082031, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125], [0.0, 0.0, 11.804716110229492, 48.851104736328125, 125.3919448852539, 275.1672058105469, 346.6382751464844, 347.3670959472656, 347.46539306640625, 347.47869873046875, 347.4804992675781, 347.4807434082031, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125], [0.0, 0.0, 12.93451976776123, 51.75489044189453, 130.30931091308594, 284.3110656738281, 346.7246398925781, 347.3784484863281, 347.4668884277344, 347.4789123535156, 347.4804992675781, 347.4807434082031, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125], [0.0, 0.0, 10.715606689453125, 45.96187973022461, 119.17862701416016, 258.8850402832031, 346.5278015136719, 347.35394287109375, 347.4635925292969, 347.4783630371094, 347.4804382324219, 347.4807434082031, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125], [0.0, 0.0, 10.471831321716309, 45.3693962097168, 118.41693115234375, 258.4518737792969, 346.5049743652344, 347.3508605957031, 347.4631042480469, 347.4783630371094, 347.4804382324219, 347.4807434082031, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125], [0.0, 0.0, 8.76577091217041, 40.87199401855469, 109.45606994628906, 238.1992645263672, 346.237060546875, 347.32305908203125, 347.45941162109375, 347.47784423828125, 347.48040771484375, 347.480712890625, 347.4807434082031, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125], [0.0, 0.0, 8.171103477478027, 39.34320068359375, 106.33528900146484, 231.34255981445312, 346.1017761230469, 347.3116455078125, 347.4578552246094, 347.4776611328125, 347.48040771484375, 347.480712890625, 347.4807434082031, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125], [0.0, 0.0, 8.610767364501953, 40.43122863769531, 108.97339630126953, 238.91912841796875, 346.21966552734375, 347.3197326660156, 347.45892333984375, 347.47784423828125, 347.48040771484375, 347.480712890625, 347.4807434082031, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125], [0.0, 0.0, 9.1510591506958, 41.77466583251953, 111.64071655273438, 244.7439727783203, 346.3113708496094, 347.32867431640625, 347.460205078125, 347.47796630859375, 347.48040771484375, 347.480712890625, 347.4807434082031, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125], [0.0, 0.0, 9.111202239990234, 41.677677154541016, 111.28368377685547, 243.2848663330078, 346.30169677734375, 347.3282775878906, 347.4600830078125, 347.47796630859375, 347.48040771484375, 347.480712890625, 347.4807434082031, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125], [0.0, 0.0, 10.825996398925781, 46.23551559448242, 120.64242553710938, 265.5562744140625, 346.5432434082031, 347.3548889160156, 347.4637145996094, 347.4784240722656, 347.4804382324219, 347.4807434082031, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125], [0.0, 0.0, 11.857003211975098, 49.00483322143555, 125.89701843261719, 276.8872375488281, 346.64215087890625, 347.3675231933594, 347.4654235839844, 347.47869873046875, 347.4804992675781, 347.4807434082031, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125], [0.0, 0.0, 12.258659362792969, 49.97150421142578, 127.26893615722656, 278.61187744140625, 346.67205810546875, 347.3715515136719, 347.4659729003906, 347.478759765625, 347.4804992675781, 347.4807434082031, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125], [0.0, 0.0, 12.400922775268555, 50.34605407714844, 127.63378143310547, 278.41827392578125, 346.6846618652344, 347.3732604980469, 347.4661865234375, 347.478759765625, 347.4804992675781, 347.4807434082031, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125], [0.0, 0.0, 9.721837043762207, 43.36110305786133, 114.19630432128906, 247.87716674804688, 346.39813232421875, 347.33941650390625, 347.4616394042969, 347.4781799316406, 347.4804382324219, 347.480712890625, 347.4807434082031, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125], [0.0, 0.0, 8.219206809997559, 39.4843635559082, 106.48058319091797, 231.03598022460938, 346.1067199707031, 347.31292724609375, 347.4580078125, 347.4776916503906, 347.48040771484375, 347.480712890625, 347.4807434082031, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125], [0.0, 0.0, 9.324652671813965, 42.2888069152832, 112.78570556640625, 247.6114959716797, 346.34832763671875, 347.33245849609375, 347.4606628417969, 347.4780578613281, 347.48040771484375, 347.480712890625, 347.4807434082031, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125], [0.0, 0.0, 10.181009292602539, 44.538780212402344, 117.13629150390625, 256.9195861816406, 346.466796875, 347.3458251953125, 347.4624938964844, 347.4783020019531, 347.4804382324219, 347.480712890625, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125], [0.0, 0.0, 9.294236183166504, 42.184425354003906, 112.28152465820312, 245.36524963378906, 346.3348693847656, 347.33172607421875, 347.4605712890625, 347.47802734375, 347.48040771484375, 347.480712890625, 347.4807434082031, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125], [0.0, 0.0, 8.996862411499023, 41.38209533691406, 110.62052154541016, 241.5407257080078, 346.2796325683594, 347.32635498046875, 347.4598388671875, 347.4779357910156, 347.48040771484375, 347.480712890625, 347.4807434082031, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125], [0.0, 0.0, 9.38304615020752, 42.42038345336914, 112.90159606933594, 247.3275604248047, 346.3536682128906, 347.33331298828125, 347.4607849121094, 347.47808837890625, 347.48040771484375, 347.480712890625, 347.4807434082031, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125], [0.0, 0.0, 10.126627922058105, 44.41931915283203, 117.1151351928711, 257.6437683105469, 346.4639892578125, 347.3453063964844, 347.46240234375, 347.478271484375, 347.4804382324219, 347.480712890625, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125], [0.0, 0.0, 11.578338623046875, 48.21379852294922, 124.13710021972656, 272.2852783203125, 346.61480712890625, 347.36407470703125, 347.4649658203125, 347.4786376953125, 347.4804992675781, 347.4807434082031, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125], [0.0, 0.0, 10.600366592407227, 45.615150451660156, 118.79793548583984, 259.1318054199219, 346.5129089355469, 347.351806640625, 347.46331787109375, 347.4783935546875, 347.4804382324219, 347.4807434082031, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125], [0.0, 0.0, 9.128786087036133, 41.785526275634766, 111.2779312133789, 242.25291442871094, 346.30426025390625, 347.3293762207031, 347.46026611328125, 347.47796630859375, 347.48040771484375, 347.480712890625, 347.4807434082031, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125], [0.0, 0.0, 9.718254089355469, 43.357662200927734, 114.68321990966797, 250.87347412109375, 346.40765380859375, 347.33941650390625, 347.4615783691406, 347.4781799316406, 347.4804382324219, 347.480712890625, 347.4807434082031, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125], [0.0, 0.0, 8.074131965637207, 39.10020446777344, 105.94154357910156, 230.89111328125, 346.08489990234375, 347.3097229003906, 347.45758056640625, 347.4776611328125, 347.48040771484375, 347.480712890625, 347.4807434082031, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125], [0.0, 0.0, 8.477391242980957, 40.10848617553711, 108.11470031738281, 236.1461639404297, 346.1841125488281, 347.31732177734375, 347.4586181640625, 347.47772216796875, 347.48040771484375, 347.480712890625, 347.4807434082031, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125], [0.0, 0.0, 7.846542835235596, 38.45142364501953, 104.60388946533203, 228.2225799560547, 346.015625, 347.30401611328125, 347.4568176269531, 347.4775085449219, 347.4803771972656, 347.480712890625, 347.4807434082031, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125], [0.0, 0.0, 7.0173187255859375, 36.31339645385742, 99.94416046142578, 217.769287109375, 345.6910705566406, 347.2840881347656, 347.4541320800781, 347.4771728515625, 347.4802551269531, 347.480712890625, 347.4807434082031, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125], [0.0, 0.0, 7.233375549316406, 36.83102035522461, 101.16112518310547, 220.89630126953125, 345.7982177734375, 347.2891540527344, 347.4548034667969, 347.4772644042969, 347.4802551269531, 347.480712890625, 347.4807434082031, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125], [0.0, 0.0, 6.995944023132324, 36.23221206665039, 99.88705444335938, 218.22169494628906, 345.70111083984375, 347.283447265625, 347.4540100097656, 347.4772033691406, 347.4802551269531, 347.480712890625, 347.4807434082031, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125], [0.0, 0.0, 6.985742092132568, 36.216976165771484, 99.87037658691406, 218.21365356445312, 345.7000427246094, 347.2833251953125, 347.4540100097656, 347.4771728515625, 347.4802551269531, 347.480712890625, 347.4807434082031, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125], [0.0, 0.0, 6.429779052734375, 34.80898666381836, 96.70618438720703, 211.15914916992188, 345.3819580078125, 347.2681884765625, 347.4519348144531, 347.4768981933594, 347.4802551269531, 347.480712890625, 347.4807434082031, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125], [0.0, 0.0, 7.423404216766357, 37.26862335205078, 102.31932067871094, 224.44271850585938, 345.89154052734375, 347.2931213378906, 347.455322265625, 347.477294921875, 347.4803161621094, 347.480712890625, 347.4807434082031, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125], [0.0, 0.0, 8.26768684387207, 39.441184997558594, 106.94205474853516, 234.72564697265625, 346.134765625, 347.3116149902344, 347.4578857421875, 347.4776611328125, 347.4803771972656, 347.480712890625, 347.4807434082031, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125], [0.0, 0.0, 8.832183837890625, 40.99812316894531, 110.1251449584961, 241.4717254638672, 346.2616271972656, 347.32373046875, 347.45947265625, 347.4778747558594, 347.48040771484375, 347.480712890625, 347.4807434082031, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125], [0.0, 0.0, 8.76523494720459, 40.82547378540039, 109.76090240478516, 240.58795166015625, 346.24761962890625, 347.3223876953125, 347.4593200683594, 347.47784423828125, 347.48040771484375, 347.480712890625, 347.4807434082031, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125, 347.48077392578125]], 'exp_name': 'solar power prediction using weather features', 'plant': 126, 'spot': 174, 'start_date': '20190820', 'end_date': '20200809', 'batch_size': 64, 'x_frames': 3, 'y_frames': 1, 'hid_dim': 256, 'optim': 'RMSprop', 'activation': 'relu', 'lss': 'MSE', 'lr': 0.001, 'epochs': 256, 'early_stop': 30, 'evaluation': 'NRMSE', 'features': \"[<FeatureType.SUNSHINE: '일조(hr)'>, <FeatureType.HUMIDITY: '습도(%)'>, <FeatureType.WIND_SPEED: '풍속(m/s)'>, <FeatureType.VISIBILITY: '시정(10m)'>, <FeatureType.GROUND_TEMPERATURE: '지면온도(°C)'>]\"}\n",
      "\n",
      "Namespace(activation='relu', batch_size=64, early_stop=30, end_date='20200809', epochs=256, evaluation='NRMSE', exp_name='solar power prediction using weather features', features=\"[<FeatureType.SUNSHINE: '일조(hr)'>, <FeatureType.HUMIDITY: '습도(%)'>, <FeatureType.WIND_SPEED: '풍속(m/s)'>, <FeatureType.VISIBILITY: '시정(10m)'>, <FeatureType.GROUND_TEMPERATURE: '지면온도(°C)'>, <FeatureType.WIND_DIRECTION: '풍향(16방위)'>]\", hid_dim=256, lr=0.001, lss='MSE', optim='RMSprop', plant=126, spot=174, start_date='20190820', x_frames=3, y_frames=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/256\n",
      "5/5 [==============================] - 1s 101ms/step - loss: 1316871808.0000 - accuracy: 0.1447 - val_loss: 855014272.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1316395776.0000 - accuracy: 0.0000e+00 - val_loss: 854879296.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1316294400.0000 - accuracy: 0.0000e+00 - val_loss: 854813376.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1316235136.0000 - accuracy: 0.0000e+00 - val_loss: 854764224.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1316186752.0000 - accuracy: 0.0000e+00 - val_loss: 854714240.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1316137856.0000 - accuracy: 0.0000e+00 - val_loss: 854667648.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1316092800.0000 - accuracy: 0.0000e+00 - val_loss: 854625920.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1316050816.0000 - accuracy: 0.0000e+00 - val_loss: 854583424.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/256\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 1316008320.0000 - accuracy: 0.0000e+00 - val_loss: 854538560.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315963776.0000 - accuracy: 0.0000e+00 - val_loss: 854492480.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315917952.0000 - accuracy: 0.0000e+00 - val_loss: 854447232.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315873664.0000 - accuracy: 0.0000e+00 - val_loss: 854402752.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315829248.0000 - accuracy: 0.0000e+00 - val_loss: 854357824.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315784960.0000 - accuracy: 0.0000e+00 - val_loss: 854313088.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315740416.0000 - accuracy: 0.0000e+00 - val_loss: 854271104.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315698176.0000 - accuracy: 0.0000e+00 - val_loss: 854228608.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315655936.0000 - accuracy: 0.0000e+00 - val_loss: 854182592.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/256\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1315610368.0000 - accuracy: 0.0000e+00 - val_loss: 854142016.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315569920.0000 - accuracy: 0.0000e+00 - val_loss: 854100352.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315532032.0000 - accuracy: 0.0000e+00 - val_loss: 854160064.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315516416.0000 - accuracy: 0.0000e+00 - val_loss: 854017856.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315445632.0000 - accuracy: 0.0000e+00 - val_loss: 853974656.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1315403008.0000 - accuracy: 0.0000e+00 - val_loss: 853926976.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1315356416.0000 - accuracy: 0.0000e+00 - val_loss: 853883968.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315313536.0000 - accuracy: 0.0000e+00 - val_loss: 853842816.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315272064.0000 - accuracy: 0.0000e+00 - val_loss: 853796864.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315226752.0000 - accuracy: 0.0000e+00 - val_loss: 853750080.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1315180928.0000 - accuracy: 0.0000e+00 - val_loss: 853706752.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315137920.0000 - accuracy: 0.0000e+00 - val_loss: 853666944.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315097856.0000 - accuracy: 0.0000e+00 - val_loss: 853623872.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1315054720.0000 - accuracy: 0.0000e+00 - val_loss: 853580736.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315011712.0000 - accuracy: 0.0000e+00 - val_loss: 853537152.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1314967552.0000 - accuracy: 0.0000e+00 - val_loss: 853492800.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314924288.0000 - accuracy: 0.0000e+00 - val_loss: 853449408.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314881152.0000 - accuracy: 0.0000e+00 - val_loss: 853407616.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314838912.0000 - accuracy: 0.0000e+00 - val_loss: 853363584.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1314795136.0000 - accuracy: 0.0000e+00 - val_loss: 853316544.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314748928.0000 - accuracy: 0.0000e+00 - val_loss: 853274624.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314706944.0000 - accuracy: 0.0000e+00 - val_loss: 853228672.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314662272.0000 - accuracy: 0.0013 - val_loss: 853184512.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314617728.0000 - accuracy: 0.0000e+00 - val_loss: 853142272.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314575360.0000 - accuracy: 0.0000e+00 - val_loss: 853094208.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314528768.0000 - accuracy: 0.0000e+00 - val_loss: 853054976.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314489088.0000 - accuracy: 0.0000e+00 - val_loss: 853010624.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314444800.0000 - accuracy: 0.0000e+00 - val_loss: 852962752.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1314398464.0000 - accuracy: 0.0000e+00 - val_loss: 852922752.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314358144.0000 - accuracy: 0.0000e+00 - val_loss: 852880640.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314316160.0000 - accuracy: 0.0000e+00 - val_loss: 852836544.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314272256.0000 - accuracy: 0.0000e+00 - val_loss: 852797248.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 11ms/step - loss: 1314232576.0000 - accuracy: 0.0000e+00 - val_loss: 852752256.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314188288.0000 - accuracy: 0.0000e+00 - val_loss: 852710464.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314146432.0000 - accuracy: 0.0000e+00 - val_loss: 852667264.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314103296.0000 - accuracy: 0.0000e+00 - val_loss: 852620160.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314057088.0000 - accuracy: 0.0000e+00 - val_loss: 852578432.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314015488.0000 - accuracy: 0.0000e+00 - val_loss: 852534720.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1313972224.0000 - accuracy: 0.0024 - val_loss: 852489344.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313926656.0000 - accuracy: 0.0000e+00 - val_loss: 852446336.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313883904.0000 - accuracy: 0.0000e+00 - val_loss: 852403840.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313841408.0000 - accuracy: 9.4340e-04 - val_loss: 852358592.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1313796608.0000 - accuracy: 0.0057 - val_loss: 852314688.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313752960.0000 - accuracy: 0.0091 - val_loss: 852272640.0000 - val_accuracy: 0.0020\n",
      "Epoch 62/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313711232.0000 - accuracy: 0.0036 - val_loss: 852232000.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313670144.0000 - accuracy: 0.0110 - val_loss: 852183360.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313623040.0000 - accuracy: 9.4340e-04 - val_loss: 852143552.0000 - val_accuracy: 0.0129\n",
      "Epoch 65/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1313583104.0000 - accuracy: 0.0285 - val_loss: 852102784.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313541888.0000 - accuracy: 0.0186 - val_loss: 852061056.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313500288.0000 - accuracy: 6.2893e-04 - val_loss: 852015808.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313455616.0000 - accuracy: 0.0000e+00 - val_loss: 851974272.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313413760.0000 - accuracy: 0.0000e+00 - val_loss: 851927040.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313367680.0000 - accuracy: 0.0028 - val_loss: 851884416.0000 - val_accuracy: 9.9206e-04\n",
      "Epoch 71/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313324800.0000 - accuracy: 0.0124 - val_loss: 851843264.0000 - val_accuracy: 0.0030\n",
      "Epoch 72/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1313283200.0000 - accuracy: 0.0170 - val_loss: 851798144.0000 - val_accuracy: 0.0030\n",
      "Epoch 73/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313238400.0000 - accuracy: 0.0225 - val_loss: 851752768.0000 - val_accuracy: 0.0139\n",
      "Epoch 74/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313193344.0000 - accuracy: 0.0108 - val_loss: 851705984.0000 - val_accuracy: 0.0308\n",
      "Epoch 75/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1313147904.0000 - accuracy: 0.0250 - val_loss: 851669184.0000 - val_accuracy: 0.0615\n",
      "Epoch 76/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313110272.0000 - accuracy: 0.0274 - val_loss: 851623744.0000 - val_accuracy: 0.0030\n",
      "Epoch 77/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313066752.0000 - accuracy: 6.2893e-04 - val_loss: 851579264.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313021440.0000 - accuracy: 0.0000e+00 - val_loss: 851536384.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312978688.0000 - accuracy: 9.4340e-04 - val_loss: 851490624.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312933504.0000 - accuracy: 0.0000e+00 - val_loss: 851448960.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312891904.0000 - accuracy: 6.2893e-04 - val_loss: 851405888.0000 - val_accuracy: 0.0040\n",
      "Epoch 82/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312848512.0000 - accuracy: 0.0091 - val_loss: 851377600.0000 - val_accuracy: 0.0496\n",
      "Epoch 83/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312806144.0000 - accuracy: 0.0107 - val_loss: 851319936.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1312762880.0000 - accuracy: 0.0050 - val_loss: 851273600.0000 - val_accuracy: 0.0069\n",
      "Epoch 85/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312717440.0000 - accuracy: 0.0182 - val_loss: 851233472.0000 - val_accuracy: 0.0188\n",
      "Epoch 86/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312676352.0000 - accuracy: 0.0280 - val_loss: 851187200.0000 - val_accuracy: 0.0288\n",
      "Epoch 87/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312630784.0000 - accuracy: 0.0325 - val_loss: 851144320.0000 - val_accuracy: 0.0238\n",
      "Epoch 88/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312587904.0000 - accuracy: 0.0354 - val_loss: 851101120.0000 - val_accuracy: 0.0417\n",
      "Epoch 89/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312544512.0000 - accuracy: 0.0514 - val_loss: 851054976.0000 - val_accuracy: 0.0387\n",
      "Epoch 90/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1312499840.0000 - accuracy: 0.0388 - val_loss: 851016768.0000 - val_accuracy: 0.0823\n",
      "Epoch 91/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312457600.0000 - accuracy: 0.0426 - val_loss: 850974016.0000 - val_accuracy: 0.0833\n",
      "Epoch 92/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312417024.0000 - accuracy: 0.0414 - val_loss: 850927232.0000 - val_accuracy: 0.0417\n",
      "Epoch 93/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312375040.0000 - accuracy: 0.0594 - val_loss: 850883904.0000 - val_accuracy: 0.0417\n",
      "Epoch 94/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1312331136.0000 - accuracy: 0.0410 - val_loss: 850837888.0000 - val_accuracy: 0.0417\n",
      "Epoch 95/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312286080.0000 - accuracy: 0.0256 - val_loss: 850792576.0000 - val_accuracy: 0.0417\n",
      "Epoch 96/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312241408.0000 - accuracy: 0.0401 - val_loss: 850751360.0000 - val_accuracy: 0.0327\n",
      "Epoch 97/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312200192.0000 - accuracy: 0.0096 - val_loss: 850705344.0000 - val_accuracy: 0.0417\n",
      "Epoch 98/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312154368.0000 - accuracy: 0.0368 - val_loss: 850662464.0000 - val_accuracy: 0.0417\n",
      "Epoch 99/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312113280.0000 - accuracy: 0.0396 - val_loss: 850620224.0000 - val_accuracy: 0.0417\n",
      "Epoch 100/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312069888.0000 - accuracy: 0.0384 - val_loss: 850578496.0000 - val_accuracy: 0.0417\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 101/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312027520.0000 - accuracy: 0.0403 - val_loss: 850532736.0000 - val_accuracy: 0.0377\n",
      "Epoch 102/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311982208.0000 - accuracy: 0.0379 - val_loss: 850493248.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 103/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1311939456.0000 - accuracy: 0.0325 - val_loss: 850449536.0000 - val_accuracy: 0.0159\n",
      "Epoch 104/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311897856.0000 - accuracy: 0.0118 - val_loss: 850404416.0000 - val_accuracy: 0.0407\n",
      "Epoch 105/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311855232.0000 - accuracy: 0.0390 - val_loss: 850360640.0000 - val_accuracy: 0.0605\n",
      "Epoch 106/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311812352.0000 - accuracy: 0.0821 - val_loss: 850318784.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 107/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311768576.0000 - accuracy: 1.5723e-04 - val_loss: 850270528.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 108/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311722112.0000 - accuracy: 0.0261 - val_loss: 850228928.0000 - val_accuracy: 0.0417\n",
      "Epoch 109/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311680768.0000 - accuracy: 0.0415 - val_loss: 850185920.0000 - val_accuracy: 0.0417\n",
      "Epoch 110/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1311638272.0000 - accuracy: 0.0478 - val_loss: 850145088.0000 - val_accuracy: 0.0417\n",
      "Epoch 111/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311596544.0000 - accuracy: 0.0313 - val_loss: 850102976.0000 - val_accuracy: 0.0417\n",
      "Epoch 112/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311554560.0000 - accuracy: 0.0322 - val_loss: 850055936.0000 - val_accuracy: 0.0417\n",
      "Epoch 113/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1311508352.0000 - accuracy: 0.0404 - val_loss: 850012864.0000 - val_accuracy: 0.0417\n",
      "Epoch 114/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311466240.0000 - accuracy: 0.0310 - val_loss: 849971712.0000 - val_accuracy: 0.0417\n",
      "Epoch 115/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311424768.0000 - accuracy: 0.0415 - val_loss: 849928192.0000 - val_accuracy: 0.0417\n",
      "Epoch 116/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311384832.0000 - accuracy: 0.0239 - val_loss: 849883648.0000 - val_accuracy: 0.0417\n",
      "Epoch 117/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311337344.0000 - accuracy: 0.0447 - val_loss: 849842176.0000 - val_accuracy: 0.0417\n",
      "Epoch 118/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311295232.0000 - accuracy: 0.0407 - val_loss: 849797696.0000 - val_accuracy: 0.0417\n",
      "Epoch 119/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311250944.0000 - accuracy: 0.0220 - val_loss: 849751360.0000 - val_accuracy: 0.0417\n",
      "Epoch 120/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311206912.0000 - accuracy: 0.0451 - val_loss: 849709056.0000 - val_accuracy: 0.0833\n",
      "Epoch 121/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311163264.0000 - accuracy: 0.0789 - val_loss: 849665856.0000 - val_accuracy: 0.0387\n",
      "Epoch 122/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1311120512.0000 - accuracy: 0.0272 - val_loss: 849622912.0000 - val_accuracy: 0.0417\n",
      "Epoch 123/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311077504.0000 - accuracy: 0.0189 - val_loss: 849577024.0000 - val_accuracy: 0.0417\n",
      "Epoch 124/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311032832.0000 - accuracy: 0.0363 - val_loss: 849532608.0000 - val_accuracy: 0.0417\n",
      "Epoch 125/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310988672.0000 - accuracy: 0.0351 - val_loss: 849491776.0000 - val_accuracy: 0.0417\n",
      "Epoch 126/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310947712.0000 - accuracy: 0.0325 - val_loss: 849447232.0000 - val_accuracy: 0.0605\n",
      "Epoch 127/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310902144.0000 - accuracy: 0.0236 - val_loss: 849401536.0000 - val_accuracy: 0.0109\n",
      "Epoch 128/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310857856.0000 - accuracy: 0.0164 - val_loss: 849366848.0000 - val_accuracy: 0.1141\n",
      "Epoch 129/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310816640.0000 - accuracy: 0.0564 - val_loss: 849313984.0000 - val_accuracy: 0.0417\n",
      "Epoch 130/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310770560.0000 - accuracy: 0.0456 - val_loss: 849272448.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 131/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1310729344.0000 - accuracy: 0.0118 - val_loss: 849303168.0000 - val_accuracy: 0.0714\n",
      "Epoch 132/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1310705280.0000 - accuracy: 0.0492 - val_loss: 849189248.0000 - val_accuracy: 0.0337\n",
      "Epoch 133/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310645760.0000 - accuracy: 0.0358 - val_loss: 849145280.0000 - val_accuracy: 0.0417\n",
      "Epoch 134/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310602496.0000 - accuracy: 0.0401 - val_loss: 849101760.0000 - val_accuracy: 0.0278\n",
      "Epoch 135/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310559104.0000 - accuracy: 0.0288 - val_loss: 849057792.0000 - val_accuracy: 0.0347\n",
      "Epoch 136/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310515584.0000 - accuracy: 0.0418 - val_loss: 849011264.0000 - val_accuracy: 0.0367\n",
      "Epoch 137/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1310470016.0000 - accuracy: 0.0509 - val_loss: 848969152.0000 - val_accuracy: 0.0417\n",
      "Epoch 138/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310428032.0000 - accuracy: 0.0366 - val_loss: 848923968.0000 - val_accuracy: 0.0417\n",
      "Epoch 139/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310383232.0000 - accuracy: 0.0398 - val_loss: 848882240.0000 - val_accuracy: 0.0417\n",
      "Epoch 140/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1310341760.0000 - accuracy: 0.0387 - val_loss: 848838528.0000 - val_accuracy: 0.0417\n",
      "Epoch 141/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1310298624.0000 - accuracy: 0.0404 - val_loss: 848794176.0000 - val_accuracy: 0.0417\n",
      "Epoch 142/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310254848.0000 - accuracy: 0.0524 - val_loss: 848754304.0000 - val_accuracy: 0.0417\n",
      "Epoch 143/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310213888.0000 - accuracy: 0.0487 - val_loss: 848727872.0000 - val_accuracy: 0.1012\n",
      "Epoch 144/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310173056.0000 - accuracy: 0.0634 - val_loss: 848668992.0000 - val_accuracy: 0.0427\n",
      "Epoch 145/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1310127232.0000 - accuracy: 0.0527 - val_loss: 848626816.0000 - val_accuracy: 0.0615\n",
      "Epoch 146/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310083328.0000 - accuracy: 0.0753 - val_loss: 848580096.0000 - val_accuracy: 0.0734\n",
      "Epoch 147/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310038528.0000 - accuracy: 0.0849 - val_loss: 848535552.0000 - val_accuracy: 0.0833\n",
      "Epoch 148/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309996416.0000 - accuracy: 0.0906 - val_loss: 848491264.0000 - val_accuracy: 0.0734\n",
      "Epoch 149/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309953536.0000 - accuracy: 0.0808 - val_loss: 848445440.0000 - val_accuracy: 0.0456\n",
      "Epoch 150/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309907840.0000 - accuracy: 0.0723 - val_loss: 848404800.0000 - val_accuracy: 0.0417\n",
      "Epoch 151/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1309866624.0000 - accuracy: 0.0415 - val_loss: 848361344.0000 - val_accuracy: 0.0417\n",
      "Epoch 152/256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 11ms/step - loss: 1309823744.0000 - accuracy: 0.0415 - val_loss: 848317184.0000 - val_accuracy: 0.0417\n",
      "Epoch 153/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309779840.0000 - accuracy: 0.0415 - val_loss: 848270848.0000 - val_accuracy: 0.0417\n",
      "Epoch 154/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309734656.0000 - accuracy: 0.0415 - val_loss: 848230528.0000 - val_accuracy: 0.0417\n",
      "Epoch 155/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309694592.0000 - accuracy: 0.0418 - val_loss: 848189632.0000 - val_accuracy: 0.0417\n",
      "Epoch 156/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309653888.0000 - accuracy: 0.0421 - val_loss: 848149376.0000 - val_accuracy: 0.0665\n",
      "Epoch 157/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1309612416.0000 - accuracy: 0.0495 - val_loss: 848107392.0000 - val_accuracy: 0.0744\n",
      "Epoch 158/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309566464.0000 - accuracy: 0.0645 - val_loss: 848059328.0000 - val_accuracy: 0.0417\n",
      "Epoch 159/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309523328.0000 - accuracy: 0.0481 - val_loss: 848018368.0000 - val_accuracy: 0.0675\n",
      "Epoch 160/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1309479680.0000 - accuracy: 0.0748 - val_loss: 847973120.0000 - val_accuracy: 0.0387\n",
      "Epoch 161/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309435904.0000 - accuracy: 0.0513 - val_loss: 847989248.0000 - val_accuracy: 0.1032\n",
      "Epoch 162/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309399552.0000 - accuracy: 0.0604 - val_loss: 847887680.0000 - val_accuracy: 0.0387\n",
      "Epoch 163/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309351552.0000 - accuracy: 0.0417 - val_loss: 847844480.0000 - val_accuracy: 0.0397\n",
      "Epoch 164/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309307776.0000 - accuracy: 0.0509 - val_loss: 847800896.0000 - val_accuracy: 0.0685\n",
      "Epoch 165/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309261056.0000 - accuracy: 0.0657 - val_loss: 847759488.0000 - val_accuracy: 0.0685\n",
      "Epoch 166/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309219584.0000 - accuracy: 0.0731 - val_loss: 847710080.0000 - val_accuracy: 0.0407\n",
      "Epoch 167/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1309175040.0000 - accuracy: 0.0590 - val_loss: 847680960.0000 - val_accuracy: 0.0823\n",
      "Epoch 168/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309136640.0000 - accuracy: 0.0575 - val_loss: 847634048.0000 - val_accuracy: 0.0665\n",
      "Epoch 169/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309094016.0000 - accuracy: 0.0700 - val_loss: 847596992.0000 - val_accuracy: 0.0704\n",
      "Epoch 170/256\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1309051392.0000 - accuracy: 0.0712 - val_loss: 847543744.0000 - val_accuracy: 0.0714\n",
      "Epoch 171/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309004672.0000 - accuracy: 0.0759 - val_loss: 847497408.0000 - val_accuracy: 0.0556\n",
      "Epoch 172/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308961920.0000 - accuracy: 0.0704 - val_loss: 847465216.0000 - val_accuracy: 0.0804\n",
      "Epoch 173/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308924800.0000 - accuracy: 0.0698 - val_loss: 847412096.0000 - val_accuracy: 0.0565\n",
      "Epoch 174/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308879232.0000 - accuracy: 0.0645 - val_loss: 847371712.0000 - val_accuracy: 0.0605\n",
      "Epoch 175/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308835072.0000 - accuracy: 0.0774 - val_loss: 847325888.0000 - val_accuracy: 0.0694\n",
      "Epoch 176/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308789248.0000 - accuracy: 0.0825 - val_loss: 847281792.0000 - val_accuracy: 0.0704\n",
      "Epoch 177/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308752896.0000 - accuracy: 0.0590 - val_loss: 847241088.0000 - val_accuracy: 0.0675\n",
      "Epoch 178/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308705152.0000 - accuracy: 0.0825 - val_loss: 847203776.0000 - val_accuracy: 0.0813\n",
      "Epoch 179/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1308664064.0000 - accuracy: 0.0731 - val_loss: 847171776.0000 - val_accuracy: 0.0962\n",
      "Epoch 180/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308630656.0000 - accuracy: 0.0786 - val_loss: 847117440.0000 - val_accuracy: 0.0843\n",
      "Epoch 181/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308587136.0000 - accuracy: 0.0778 - val_loss: 847073856.0000 - val_accuracy: 0.0754\n",
      "Epoch 182/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1308541184.0000 - accuracy: 0.0525 - val_loss: 847025600.0000 - val_accuracy: 0.0754\n",
      "Epoch 183/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308495488.0000 - accuracy: 0.0708 - val_loss: 846981632.0000 - val_accuracy: 0.0744\n",
      "Epoch 184/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308451456.0000 - accuracy: 0.0511 - val_loss: 846936960.0000 - val_accuracy: 0.0635\n",
      "Epoch 185/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308406528.0000 - accuracy: 0.0539 - val_loss: 846912064.0000 - val_accuracy: 0.0823\n",
      "Epoch 186/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308365184.0000 - accuracy: 0.0717 - val_loss: 846850048.0000 - val_accuracy: 0.0714\n",
      "Epoch 187/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308324096.0000 - accuracy: 0.0684 - val_loss: 846802816.0000 - val_accuracy: 0.0704\n",
      "Epoch 188/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308276992.0000 - accuracy: 0.0712 - val_loss: 846761600.0000 - val_accuracy: 0.0645\n",
      "Epoch 189/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1308234752.0000 - accuracy: 0.0601 - val_loss: 846723392.0000 - val_accuracy: 0.0734\n",
      "Epoch 190/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308193536.0000 - accuracy: 0.0588 - val_loss: 846691584.0000 - val_accuracy: 0.0942\n",
      "Epoch 191/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308151808.0000 - accuracy: 0.0483 - val_loss: 846632256.0000 - val_accuracy: 0.0694\n",
      "Epoch 192/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1308105856.0000 - accuracy: 0.0596 - val_loss: 846590528.0000 - val_accuracy: 0.0645\n",
      "Epoch 193/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308065152.0000 - accuracy: 0.0524 - val_loss: 846551552.0000 - val_accuracy: 0.0327\n",
      "Epoch 194/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308024064.0000 - accuracy: 0.0456 - val_loss: 846506880.0000 - val_accuracy: 0.0357\n",
      "Epoch 195/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1307978240.0000 - accuracy: 0.0522 - val_loss: 846470656.0000 - val_accuracy: 0.0823\n",
      "Epoch 196/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307941376.0000 - accuracy: 0.0428 - val_loss: 846421696.0000 - val_accuracy: 0.0675\n",
      "Epoch 197/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307892864.0000 - accuracy: 0.0660 - val_loss: 846376960.0000 - val_accuracy: 0.0734\n",
      "Epoch 198/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1307850880.0000 - accuracy: 0.0484 - val_loss: 846335296.0000 - val_accuracy: 0.0714\n",
      "Epoch 199/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307806592.0000 - accuracy: 0.0689 - val_loss: 846317952.0000 - val_accuracy: 0.0843\n",
      "Epoch 200/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307769856.0000 - accuracy: 0.0642 - val_loss: 846251328.0000 - val_accuracy: 0.0605\n",
      "Epoch 201/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1307724544.0000 - accuracy: 0.0615 - val_loss: 846207936.0000 - val_accuracy: 0.0724\n",
      "Epoch 202/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307679104.0000 - accuracy: 0.0792 - val_loss: 846161344.0000 - val_accuracy: 0.0784\n",
      "Epoch 203/256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 11ms/step - loss: 1307635712.0000 - accuracy: 0.0664 - val_loss: 846125248.0000 - val_accuracy: 0.0804\n",
      "Epoch 204/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307594624.0000 - accuracy: 0.0659 - val_loss: 846080384.0000 - val_accuracy: 0.0754\n",
      "Epoch 205/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307553664.0000 - accuracy: 0.0582 - val_loss: 846032576.0000 - val_accuracy: 0.0704\n",
      "Epoch 206/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307508608.0000 - accuracy: 0.0547 - val_loss: 845988800.0000 - val_accuracy: 0.0595\n",
      "Epoch 207/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307462656.0000 - accuracy: 0.0580 - val_loss: 845976512.0000 - val_accuracy: 0.0913\n",
      "Epoch 208/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1307418624.0000 - accuracy: 0.0719 - val_loss: 845903360.0000 - val_accuracy: 0.0694\n",
      "Epoch 209/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307377536.0000 - accuracy: 0.0711 - val_loss: 845861376.0000 - val_accuracy: 0.0675\n",
      "Epoch 210/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307333632.0000 - accuracy: 0.0693 - val_loss: 845811200.0000 - val_accuracy: 0.0427\n",
      "Epoch 211/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307286528.0000 - accuracy: 0.0478 - val_loss: 845766848.0000 - val_accuracy: 0.0556\n",
      "Epoch 212/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307241216.0000 - accuracy: 0.0594 - val_loss: 845732160.0000 - val_accuracy: 0.0665\n",
      "Epoch 213/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307203072.0000 - accuracy: 0.0659 - val_loss: 845690496.0000 - val_accuracy: 0.0655\n",
      "Epoch 214/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307161600.0000 - accuracy: 0.0671 - val_loss: 845650240.0000 - val_accuracy: 0.0665\n",
      "Epoch 215/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307120384.0000 - accuracy: 0.0709 - val_loss: 845608064.0000 - val_accuracy: 0.0774\n",
      "Epoch 216/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307078400.0000 - accuracy: 0.0692 - val_loss: 845566144.0000 - val_accuracy: 0.0734\n",
      "Epoch 217/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1307036544.0000 - accuracy: 0.0687 - val_loss: 845528320.0000 - val_accuracy: 0.0694\n",
      "Epoch 218/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306993024.0000 - accuracy: 0.0695 - val_loss: 845480320.0000 - val_accuracy: 0.0704\n",
      "Epoch 219/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306950272.0000 - accuracy: 0.0711 - val_loss: 845454976.0000 - val_accuracy: 0.0804\n",
      "Epoch 220/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306905216.0000 - accuracy: 0.0726 - val_loss: 845408256.0000 - val_accuracy: 0.0823\n",
      "Epoch 221/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306860416.0000 - accuracy: 0.0769 - val_loss: 845369856.0000 - val_accuracy: 0.0853\n",
      "Epoch 222/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1306821248.0000 - accuracy: 0.0739 - val_loss: 845300992.0000 - val_accuracy: 0.0804\n",
      "Epoch 223/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306781184.0000 - accuracy: 0.0755 - val_loss: 845255552.0000 - val_accuracy: 0.0744\n",
      "Epoch 224/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1306729216.0000 - accuracy: 0.0728 - val_loss: 845223808.0000 - val_accuracy: 0.0804\n",
      "Epoch 225/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306684672.0000 - accuracy: 0.0774 - val_loss: 845175488.0000 - val_accuracy: 0.0813\n",
      "Epoch 226/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306642816.0000 - accuracy: 0.0774 - val_loss: 845124736.0000 - val_accuracy: 0.0804\n",
      "Epoch 227/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1306604544.0000 - accuracy: 0.0745 - val_loss: 845082112.0000 - val_accuracy: 0.0675\n",
      "Epoch 228/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306562176.0000 - accuracy: 0.0692 - val_loss: 845042240.0000 - val_accuracy: 0.0764\n",
      "Epoch 229/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306519808.0000 - accuracy: 0.0774 - val_loss: 844997312.0000 - val_accuracy: 0.0565\n",
      "Epoch 230/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306474240.0000 - accuracy: 0.0648 - val_loss: 844957376.0000 - val_accuracy: 0.0744\n",
      "Epoch 231/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306429824.0000 - accuracy: 0.0852 - val_loss: 844920448.0000 - val_accuracy: 0.0784\n",
      "Epoch 232/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306389760.0000 - accuracy: 0.0840 - val_loss: 844893312.0000 - val_accuracy: 0.1002\n",
      "Epoch 233/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306351104.0000 - accuracy: 0.0819 - val_loss: 844829248.0000 - val_accuracy: 0.0685\n",
      "Epoch 234/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306308736.0000 - accuracy: 0.0774 - val_loss: 844800960.0000 - val_accuracy: 0.0992\n",
      "Epoch 235/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306267648.0000 - accuracy: 0.0917 - val_loss: 844747072.0000 - val_accuracy: 0.0784\n",
      "Epoch 236/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1306223744.0000 - accuracy: 0.0803 - val_loss: 844722304.0000 - val_accuracy: 0.0972\n",
      "Epoch 237/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306182400.0000 - accuracy: 0.0827 - val_loss: 844685632.0000 - val_accuracy: 0.1032\n",
      "Epoch 238/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306137728.0000 - accuracy: 0.0906 - val_loss: 844636032.0000 - val_accuracy: 0.1002\n",
      "Epoch 239/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306093440.0000 - accuracy: 0.0964 - val_loss: 844579200.0000 - val_accuracy: 0.0833\n",
      "Epoch 240/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306050560.0000 - accuracy: 0.0899 - val_loss: 844529472.0000 - val_accuracy: 0.0833\n",
      "Epoch 241/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306017408.0000 - accuracy: 0.0829 - val_loss: 844484032.0000 - val_accuracy: 0.0833\n",
      "Epoch 242/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1305970176.0000 - accuracy: 0.0808 - val_loss: 844446208.0000 - val_accuracy: 0.0804\n",
      "Epoch 243/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1305917952.0000 - accuracy: 0.0898 - val_loss: 844407168.0000 - val_accuracy: 0.0823\n",
      "Epoch 244/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1305878144.0000 - accuracy: 0.0869 - val_loss: 844371968.0000 - val_accuracy: 0.1052\n",
      "Epoch 245/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1305834368.0000 - accuracy: 0.0994 - val_loss: 844312448.0000 - val_accuracy: 0.0784\n",
      "Epoch 246/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1305792768.0000 - accuracy: 0.0799 - val_loss: 844295808.0000 - val_accuracy: 0.1220\n",
      "Epoch 247/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1305746560.0000 - accuracy: 0.1019 - val_loss: 844222656.0000 - val_accuracy: 0.0833\n",
      "Epoch 248/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1305709952.0000 - accuracy: 0.0844 - val_loss: 844181824.0000 - val_accuracy: 0.0804\n",
      "Epoch 249/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1305661184.0000 - accuracy: 0.0832 - val_loss: 844142592.0000 - val_accuracy: 0.0823\n",
      "Epoch 250/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1305617280.0000 - accuracy: 0.0873 - val_loss: 844135104.0000 - val_accuracy: 0.1111\n",
      "Epoch 251/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1305578752.0000 - accuracy: 0.0858 - val_loss: 844059776.0000 - val_accuracy: 0.0813\n",
      "Epoch 252/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1305533568.0000 - accuracy: 0.0943 - val_loss: 844010944.0000 - val_accuracy: 0.0823\n",
      "Epoch 253/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1305486976.0000 - accuracy: 0.0937 - val_loss: 843992896.0000 - val_accuracy: 0.1071\n",
      "Epoch 254/256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 11ms/step - loss: 1305446016.0000 - accuracy: 0.0921 - val_loss: 843937088.0000 - val_accuracy: 0.1042\n",
      "Epoch 255/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1305402496.0000 - accuracy: 0.0984 - val_loss: 843887744.0000 - val_accuracy: 0.0853\n",
      "Epoch 256/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1305358976.0000 - accuracy: 0.1002 - val_loss: 843843584.0000 - val_accuracy: 0.0833\n",
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            [(None, 72, 6)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_10 (LSTM)                  [(None, 256), (None, 269312      input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_5 (RepeatVector)  (None, 24, 256)      0           lstm_10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_11 (LSTM)                  [(None, 24, 256), (N 525312      repeat_vector_5[0][0]            \n",
      "                                                                 lstm_10[0][1]                    \n",
      "                                                                 lstm_10[0][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 24, 1)        257         lstm_11[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 794,881\n",
      "Trainable params: 794,881\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Took 19.83 sec for training the model\n",
      "{'train_losses': [1316871808.0, 1316395776.0, 1316294400.0, 1316235136.0, 1316186752.0, 1316137856.0, 1316092800.0, 1316050816.0, 1316008320.0, 1315963776.0, 1315917952.0, 1315873664.0, 1315829248.0, 1315784960.0, 1315740416.0, 1315698176.0, 1315655936.0, 1315610368.0, 1315569920.0, 1315532032.0, 1315516416.0, 1315445632.0, 1315403008.0, 1315356416.0, 1315313536.0, 1315272064.0, 1315226752.0, 1315180928.0, 1315137920.0, 1315097856.0, 1315054720.0, 1315011712.0, 1314967552.0, 1314924288.0, 1314881152.0, 1314838912.0, 1314795136.0, 1314748928.0, 1314706944.0, 1314662272.0, 1314617728.0, 1314575360.0, 1314528768.0, 1314489088.0, 1314444800.0, 1314398464.0, 1314358144.0, 1314316160.0, 1314272256.0, 1314232576.0, 1314188288.0, 1314146432.0, 1314103296.0, 1314057088.0, 1314015488.0, 1313972224.0, 1313926656.0, 1313883904.0, 1313841408.0, 1313796608.0, 1313752960.0, 1313711232.0, 1313670144.0, 1313623040.0, 1313583104.0, 1313541888.0, 1313500288.0, 1313455616.0, 1313413760.0, 1313367680.0, 1313324800.0, 1313283200.0, 1313238400.0, 1313193344.0, 1313147904.0, 1313110272.0, 1313066752.0, 1313021440.0, 1312978688.0, 1312933504.0, 1312891904.0, 1312848512.0, 1312806144.0, 1312762880.0, 1312717440.0, 1312676352.0, 1312630784.0, 1312587904.0, 1312544512.0, 1312499840.0, 1312457600.0, 1312417024.0, 1312375040.0, 1312331136.0, 1312286080.0, 1312241408.0, 1312200192.0, 1312154368.0, 1312113280.0, 1312069888.0, 1312027520.0, 1311982208.0, 1311939456.0, 1311897856.0, 1311855232.0, 1311812352.0, 1311768576.0, 1311722112.0, 1311680768.0, 1311638272.0, 1311596544.0, 1311554560.0, 1311508352.0, 1311466240.0, 1311424768.0, 1311384832.0, 1311337344.0, 1311295232.0, 1311250944.0, 1311206912.0, 1311163264.0, 1311120512.0, 1311077504.0, 1311032832.0, 1310988672.0, 1310947712.0, 1310902144.0, 1310857856.0, 1310816640.0, 1310770560.0, 1310729344.0, 1310705280.0, 1310645760.0, 1310602496.0, 1310559104.0, 1310515584.0, 1310470016.0, 1310428032.0, 1310383232.0, 1310341760.0, 1310298624.0, 1310254848.0, 1310213888.0, 1310173056.0, 1310127232.0, 1310083328.0, 1310038528.0, 1309996416.0, 1309953536.0, 1309907840.0, 1309866624.0, 1309823744.0, 1309779840.0, 1309734656.0, 1309694592.0, 1309653888.0, 1309612416.0, 1309566464.0, 1309523328.0, 1309479680.0, 1309435904.0, 1309399552.0, 1309351552.0, 1309307776.0, 1309261056.0, 1309219584.0, 1309175040.0, 1309136640.0, 1309094016.0, 1309051392.0, 1309004672.0, 1308961920.0, 1308924800.0, 1308879232.0, 1308835072.0, 1308789248.0, 1308752896.0, 1308705152.0, 1308664064.0, 1308630656.0, 1308587136.0, 1308541184.0, 1308495488.0, 1308451456.0, 1308406528.0, 1308365184.0, 1308324096.0, 1308276992.0, 1308234752.0, 1308193536.0, 1308151808.0, 1308105856.0, 1308065152.0, 1308024064.0, 1307978240.0, 1307941376.0, 1307892864.0, 1307850880.0, 1307806592.0, 1307769856.0, 1307724544.0, 1307679104.0, 1307635712.0, 1307594624.0, 1307553664.0, 1307508608.0, 1307462656.0, 1307418624.0, 1307377536.0, 1307333632.0, 1307286528.0, 1307241216.0, 1307203072.0, 1307161600.0, 1307120384.0, 1307078400.0, 1307036544.0, 1306993024.0, 1306950272.0, 1306905216.0, 1306860416.0, 1306821248.0, 1306781184.0, 1306729216.0, 1306684672.0, 1306642816.0, 1306604544.0, 1306562176.0, 1306519808.0, 1306474240.0, 1306429824.0, 1306389760.0, 1306351104.0, 1306308736.0, 1306267648.0, 1306223744.0, 1306182400.0, 1306137728.0, 1306093440.0, 1306050560.0, 1306017408.0, 1305970176.0, 1305917952.0, 1305878144.0, 1305834368.0, 1305792768.0, 1305746560.0, 1305709952.0, 1305661184.0, 1305617280.0, 1305578752.0, 1305533568.0, 1305486976.0, 1305446016.0, 1305402496.0, 1305358976.0], 'val_losses': [855014272.0, 854879296.0, 854813376.0, 854764224.0, 854714240.0, 854667648.0, 854625920.0, 854583424.0, 854538560.0, 854492480.0, 854447232.0, 854402752.0, 854357824.0, 854313088.0, 854271104.0, 854228608.0, 854182592.0, 854142016.0, 854100352.0, 854160064.0, 854017856.0, 853974656.0, 853926976.0, 853883968.0, 853842816.0, 853796864.0, 853750080.0, 853706752.0, 853666944.0, 853623872.0, 853580736.0, 853537152.0, 853492800.0, 853449408.0, 853407616.0, 853363584.0, 853316544.0, 853274624.0, 853228672.0, 853184512.0, 853142272.0, 853094208.0, 853054976.0, 853010624.0, 852962752.0, 852922752.0, 852880640.0, 852836544.0, 852797248.0, 852752256.0, 852710464.0, 852667264.0, 852620160.0, 852578432.0, 852534720.0, 852489344.0, 852446336.0, 852403840.0, 852358592.0, 852314688.0, 852272640.0, 852232000.0, 852183360.0, 852143552.0, 852102784.0, 852061056.0, 852015808.0, 851974272.0, 851927040.0, 851884416.0, 851843264.0, 851798144.0, 851752768.0, 851705984.0, 851669184.0, 851623744.0, 851579264.0, 851536384.0, 851490624.0, 851448960.0, 851405888.0, 851377600.0, 851319936.0, 851273600.0, 851233472.0, 851187200.0, 851144320.0, 851101120.0, 851054976.0, 851016768.0, 850974016.0, 850927232.0, 850883904.0, 850837888.0, 850792576.0, 850751360.0, 850705344.0, 850662464.0, 850620224.0, 850578496.0, 850532736.0, 850493248.0, 850449536.0, 850404416.0, 850360640.0, 850318784.0, 850270528.0, 850228928.0, 850185920.0, 850145088.0, 850102976.0, 850055936.0, 850012864.0, 849971712.0, 849928192.0, 849883648.0, 849842176.0, 849797696.0, 849751360.0, 849709056.0, 849665856.0, 849622912.0, 849577024.0, 849532608.0, 849491776.0, 849447232.0, 849401536.0, 849366848.0, 849313984.0, 849272448.0, 849303168.0, 849189248.0, 849145280.0, 849101760.0, 849057792.0, 849011264.0, 848969152.0, 848923968.0, 848882240.0, 848838528.0, 848794176.0, 848754304.0, 848727872.0, 848668992.0, 848626816.0, 848580096.0, 848535552.0, 848491264.0, 848445440.0, 848404800.0, 848361344.0, 848317184.0, 848270848.0, 848230528.0, 848189632.0, 848149376.0, 848107392.0, 848059328.0, 848018368.0, 847973120.0, 847989248.0, 847887680.0, 847844480.0, 847800896.0, 847759488.0, 847710080.0, 847680960.0, 847634048.0, 847596992.0, 847543744.0, 847497408.0, 847465216.0, 847412096.0, 847371712.0, 847325888.0, 847281792.0, 847241088.0, 847203776.0, 847171776.0, 847117440.0, 847073856.0, 847025600.0, 846981632.0, 846936960.0, 846912064.0, 846850048.0, 846802816.0, 846761600.0, 846723392.0, 846691584.0, 846632256.0, 846590528.0, 846551552.0, 846506880.0, 846470656.0, 846421696.0, 846376960.0, 846335296.0, 846317952.0, 846251328.0, 846207936.0, 846161344.0, 846125248.0, 846080384.0, 846032576.0, 845988800.0, 845976512.0, 845903360.0, 845861376.0, 845811200.0, 845766848.0, 845732160.0, 845690496.0, 845650240.0, 845608064.0, 845566144.0, 845528320.0, 845480320.0, 845454976.0, 845408256.0, 845369856.0, 845300992.0, 845255552.0, 845223808.0, 845175488.0, 845124736.0, 845082112.0, 845042240.0, 844997312.0, 844957376.0, 844920448.0, 844893312.0, 844829248.0, 844800960.0, 844747072.0, 844722304.0, 844685632.0, 844636032.0, 844579200.0, 844529472.0, 844484032.0, 844446208.0, 844407168.0, 844371968.0, 844312448.0, 844295808.0, 844222656.0, 844181824.0, 844142592.0, 844135104.0, 844059776.0, 844010944.0, 843992896.0, 843937088.0, 843887744.0, 843843584.0], 'train_accs': [0.1446540802717209, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0012578616151586175, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002358490601181984, 0.0, 0.0, 0.0009433962404727936, 0.0056603774428367615, 0.009119497612118721, 0.0036163523327559233, 0.011006289161741734, 0.0009433962404727936, 0.02845912054181099, 0.018553460016846657, 0.0006289308075793087, 0.0, 0.0, 0.0028301889542490244, 0.012421384453773499, 0.016981132328510284, 0.022484276443719864, 0.0108490576967597, 0.02500000037252903, 0.027358490973711014, 0.0006289308075793087, 0.0, 0.0009433962404727936, 0.0, 0.0006289308075793087, 0.009119497612118721, 0.010691824369132519, 0.00503144646063447, 0.018238995224237442, 0.027987422421574593, 0.03254717215895653, 0.03537735715508461, 0.0514150932431221, 0.03883648291230202, 0.04261006414890289, 0.041352204978466034, 0.059433966875076294, 0.04103773459792137, 0.02562893182039261, 0.04009433835744858, 0.009591195732355118, 0.03679245337843895, 0.03962264209985733, 0.03836478292942047, 0.04025157168507576, 0.037893082946538925, 0.03254716843366623, 0.01179245300590992, 0.0389937087893486, 0.08207546919584274, 0.0001572327018948272, 0.026100629940629005, 0.041509438306093216, 0.04779874160885811, 0.03128930926322937, 0.032232705503702164, 0.04040880873799324, 0.030974844470620155, 0.04150943458080292, 0.023899370804429054, 0.04465408995747566, 0.040723271667957306, 0.022012580186128616, 0.04512578621506691, 0.0789308249950409, 0.027201255783438683, 0.01886792667210102, 0.036320753395557404, 0.035062894225120544, 0.03254716843366623, 0.02358490601181984, 0.016352202743291855, 0.05644654855132103, 0.045597486197948456, 0.01179245300590992, 0.04921383783221245, 0.035849057137966156, 0.040094342082738876, 0.028773585334420204, 0.04182389751076698, 0.05094340071082115, 0.036635223776102066, 0.03977987915277481, 0.03867924585938454, 0.04040880873799324, 0.052358489483594894, 0.0487421378493309, 0.06336478143930435, 0.05267295986413956, 0.0753144696354866, 0.08490566164255142, 0.09056603908538818, 0.08081761747598648, 0.07232704013586044, 0.041509438306093216, 0.041509438306093216, 0.041509438306093216, 0.041509438306093216, 0.04182390123605728, 0.042138367891311646, 0.04952830448746681, 0.06446541100740433, 0.04811320826411247, 0.07484277337789536, 0.05125786364078522, 0.06037735939025879, 0.0416666679084301, 0.05094339698553085, 0.06572327762842178, 0.07311321049928665, 0.05896226316690445, 0.05754717066884041, 0.0699685588479042, 0.07122641801834106, 0.07594339549541473, 0.07044025510549545, 0.06981132179498672, 0.06446541100740433, 0.07735849171876907, 0.08254718035459518, 0.05896226316690445, 0.08254717290401459, 0.07311321794986725, 0.07861635088920593, 0.07783018797636032, 0.052515726536512375, 0.07075471431016922, 0.051100634038448334, 0.053930822759866714, 0.07169812172651291, 0.06839623302221298, 0.07122642546892166, 0.060062892735004425, 0.058805033564567566, 0.04827044531702995, 0.05959119647741318, 0.052358489483594894, 0.045597486197948456, 0.05220125615596771, 0.042767301201820374, 0.06603773683309555, 0.04842767119407654, 0.06886792182922363, 0.06415094435214996, 0.06147799268364906, 0.07924528419971466, 0.06635220348834991, 0.06588050723075867, 0.05817610025405884, 0.054716985672712326, 0.058018870651721954, 0.07185535132884979, 0.07106918841600418, 0.06933962553739548, 0.04779874160885811, 0.059433966875076294, 0.06588050723075867, 0.06713836640119553, 0.0709119513630867, 0.0691823959350586, 0.06871069222688675, 0.06949685513973236, 0.07106918841600418, 0.0726415142416954, 0.07688680291175842, 0.07389937341213226, 0.07547169923782349, 0.07279874384403229, 0.07735849171876907, 0.07735849171876907, 0.0745282992720604, 0.0691823959350586, 0.07735849171876907, 0.06477987766265869, 0.08522012829780579, 0.08396226912736893, 0.08191823959350586, 0.07735849916934967, 0.09166666120290756, 0.08034591376781464, 0.08270440995693207, 0.09056604653596878, 0.09638365358114243, 0.08993710577487946, 0.08286163955926895, 0.08081761747598648, 0.08977986872196198, 0.08694969117641449, 0.09937106817960739, 0.07987421751022339, 0.1018868014216423, 0.08443396538496017, 0.08317611366510391, 0.08726415783166885, 0.08584906160831451, 0.09433963149785995, 0.09371069073677063, 0.09213837236166, 0.0984276756644249, 0.1001572385430336], 'val_accs': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0019841270986944437, 0.0, 0.0, 0.012896825559437275, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0009920635493472219, 0.0029761905316263437, 0.0029761905316263437, 0.01388888992369175, 0.0307539701461792, 0.0615079402923584, 0.0029761905316263437, 0.0, 0.0, 0.0, 0.0, 0.003968254197388887, 0.0496031790971756, 0.0, 0.0069444440305233, 0.0188492089509964, 0.02876984141767025, 0.02380952425301075, 0.0416666679084301, 0.0386904776096344, 0.0823412761092186, 0.0833333358168602, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.032738097012043, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0376984179019928, 0.0, 0.01587301678955555, 0.0406746082007885, 0.0605158731341362, 0.0, 0.0, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0833333358168602, 0.0386904776096344, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0605158731341362, 0.01091269962489605, 0.1140873059630394, 0.0416666679084301, 0.0, 0.0714285746216774, 0.0337301604449749, 0.0416666679084301, 0.0277777798473835, 0.0347222276031971, 0.0367063507437706, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.1011904776096344, 0.042658731341362, 0.0615079402923584, 0.0734127014875412, 0.0833333358168602, 0.0734127014875412, 0.0456349216401577, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0416666679084301, 0.0664682537317276, 0.0744047611951828, 0.0416666679084301, 0.0674603208899498, 0.0386904776096344, 0.1031746193766594, 0.0386904776096344, 0.0396825410425663, 0.068452388048172, 0.0684523805975914, 0.0406746044754982, 0.0823412761092186, 0.0664682537317276, 0.0704365149140358, 0.0714285746216774, 0.055555559694767, 0.0803571417927742, 0.0565476194024086, 0.0605158731341362, 0.0694444477558136, 0.0704365149140358, 0.0674603208899498, 0.081349216401577, 0.0962301641702652, 0.0843254029750824, 0.075396828353405, 0.075396828353405, 0.0744047686457634, 0.0634920671582222, 0.0823412761092186, 0.0714285746216774, 0.0704365149140358, 0.0644841343164444, 0.0734127014875412, 0.0942460373044014, 0.0694444477558136, 0.0644841343164444, 0.032738097012043, 0.0357142873108387, 0.0823412761092186, 0.0674603208899498, 0.0734127014875412, 0.0714285746216774, 0.0843253955245018, 0.0605158731341362, 0.072420634329319, 0.078373022377491, 0.0803571417927742, 0.075396828353405, 0.0704365149140358, 0.0595238097012043, 0.0912698432803154, 0.0694444477558136, 0.0674603208899498, 0.042658731341362, 0.055555559694767, 0.0664682537317276, 0.065476194024086, 0.0664682537317276, 0.0773809552192688, 0.0734127014875412, 0.0694444477558136, 0.0704365149140358, 0.0803571492433548, 0.0823412761092186, 0.085317462682724, 0.0803571417927742, 0.0744047686457634, 0.0803571417927742, 0.081349216401577, 0.0803571417927742, 0.0674603208899498, 0.0763888955116272, 0.0565476194024086, 0.0744047611951828, 0.078373022377491, 0.1001984179019928, 0.068452388048172, 0.0992063581943512, 0.078373022377491, 0.0972222238779068, 0.1031746044754982, 0.1001984179019928, 0.0833333358168602, 0.0833333358168602, 0.0833333358168602, 0.0803571417927742, 0.0823412761092186, 0.1051587387919426, 0.078373022377491, 0.122023805975914, 0.0833333358168602, 0.0803571417927742, 0.0823412761092186, 0.111111119389534, 0.081349216401577, 0.0823412761092186, 0.1071428582072258, 0.1041666641831398, 0.085317462682724, 0.0833333358168602], 'train_acc': 0.040758895092551484, 'val_acc': 0.04232933595130817, 'test_nrmse': 0.9894542816061612, 'y_test': [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1200.0, 2500.0, 3300.0, 11300.0, 13800.0, 12200.0, 8100.0, 4400.0, 2500.0, 3000.0, 3700.0, 300.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1300.0, 5800.0, 11300.0, 23400.0, 44600.0, 63500.0, 57800.0, 63900.0, 38600.0, 32400.0, 19400.0, 24300.0, 9700.0, 600.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 1100.0, 5000.0, 14500.0, 42800.0, 57800.0, 72500.0, 76200.0, 61500.0, 48100.0, 51700.0, 20400.0, 11100.0, 8400.0, 2000.0, 1100.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 700.0, 9100.0, 13200.0, 20300.0, 28900.0, 26800.0, 40600.0, 52300.0, 36200.0, 29900.0, 41400.0, 30500.0, 19300.0, 8300.0, 700.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2600.0, 4500.0, 6900.0, 6600.0, 17000.0, 16300.0, 32100.0, 22500.0, 14000.0, 9100.0, 5000.0, 4500.0, 400.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 400.0, 2800.0, 5100.0, 11700.0, 21900.0, 14800.0, 12900.0, 24100.0, 18200.0, 13200.0, 15500.0, 10600.0, 4700.0, 2100.0, 700.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 500.0, 7700.0, 18600.0, 14500.0, 22800.0, 34500.0, 23900.0, 46400.0, 25200.0, 20700.0, 19600.0, 28200.0, 14100.0, 6500.0, 1800.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1500.0, 4300.0, 6200.0, 17500.0, 11300.0, 9600.0, 10600.0, 11800.0, 7700.0, 3700.0, 3700.0, 3500.0, 2100.0, 900.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 400.0, 4100.0, 13300.0, 29500.0, 54500.0, 48100.0, 59800.0, 68100.0, 63900.0, 50800.0, 55000.0, 34800.0, 11000.0, 1600.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 400.0, 4600.0, 20100.0, 37100.0, 50200.0, 62400.0, 49300.0, 52100.0, 47400.0, 57700.0, 45600.0, 22000.0, 12600.0, 6500.0, 800.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 400.0, 4700.0, 7700.0, 29200.0, 28200.0, 29100.0, 42000.0, 41400.0, 26800.0, 13400.0, 6500.0, 3400.0, 900.0, 200.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 900.0, 4900.0, 9800.0, 13500.0, 25300.0, 29700.0, 41500.0, 24900.0, 8400.0, 17300.0, 14100.0, 2200.0, 500.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 300.0, 5600.0, 12200.0, 22100.0, 28200.0, 32800.0, 48700.0, 38200.0, 42600.0, 30200.0, 28600.0, 21100.0, 16000.0, 8000.0, 400.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 100.0, 700.0, 1900.0, 4000.0, 5500.0, 2700.0, 4300.0, 4600.0, 4100.0, 3800.0, 1800.0, 1000.0, 1000.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 400.0, 1200.0, 4300.0, 4300.0, 6000.0, 3700.0, 2000.0, 5300.0, 2800.0, 1200.0, 400.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 400.0, 3200.0, 6900.0, 12100.0, 31800.0, 31700.0, 44200.0, 34900.0, 24800.0, 32300.0, 21000.0, 16600.0, 7000.0, 3300.0, 200.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1400.0, 5100.0, 12300.0, 13700.0, 13200.0, 9700.0, 15500.0, 12700.0, 8200.0, 11100.0, 8300.0, 5200.0, 1200.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5200.0, 14100.0, 17500.0, 8400.0, 9800.0, 26200.0, 48100.0, 63700.0, 46200.0, 38200.0, 26100.0, 14000.0, 7200.0, 700.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1500.0, 8100.0, 19000.0, 22500.0, 22100.0, 53000.0, 41900.0, 33200.0, 50300.0, 43700.0, 35100.0, 20800.0, 6100.0, 800.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2000.0, 8200.0, 8100.0, 14400.0, 35800.0, 27800.0, 25000.0, 23000.0, 9000.0, 12300.0, 22200.0, 9800.0, 2200.0, 100.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 700.0, 2000.0, 4800.0, 5800.0, 7500.0, 6200.0, 8800.0, 9800.0, 7300.0, 6000.0, 4100.0, 1300.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 100.0, 600.0, 6400.0, 9800.0, 5400.0, 22000.0, 29800.0, 34600.0, 34400.0, 27500.0, 16100.0, 6300.0, 3500.0, 800.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 400.0, 8400.0, 7500.0, 8500.0, 22200.0, 28400.0, 30500.0, 34800.0, 40100.0, 52300.0, 32100.0, 26000.0, 9800.0, 2100.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1500.0, 5200.0, 6200.0, 8400.0, 10800.0, 10700.0, 10700.0, 12900.0, 14000.0, 10700.0, 14700.0, 7300.0, 3900.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 700.0, 500.0, 4700.0, 3200.0, 2400.0, 2100.0, 2100.0, 3100.0, 2000.0, 1400.0, 2100.0, 400.0, 400.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1200.0, 2100.0, 2600.0, 6900.0, 8100.0, 11100.0, 6500.0, 3000.0, 11400.0, 16600.0, 8100.0, 4700.0, 5000.0, 700.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 100.0, 2300.0, 4300.0, 15000.0, 15100.0, 27600.0, 32000.0, 56800.0, 19500.0, 32900.0, 25600.0, 9600.0, 20500.0, 2500.0, 100.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4200.0, 11100.0, 29600.0, 40300.0, 50900.0, 28700.0, 50700.0, 27300.0, 32500.0, 37200.0, 22900.0, 17800.0, 4000.0, 200.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1400.0, 4600.0, 6900.0, 11400.0, 15900.0, 23200.0, 19200.0, 15300.0, 5200.0, 5200.0, 1100.0, 1200.0, 200.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1700.0, 7700.0, 12500.0, 14000.0, 18700.0, 14500.0, 14300.0, 17900.0, 10400.0, 5900.0, 11400.0, 4200.0, 700.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 100.0, 2500.0, 6000.0, 19200.0, 20500.0, 16900.0, 15900.0, 18400.0, 9800.0, 8100.0, 7400.0, 8500.0, 3600.0, 6900.0, 100.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1700.0, 6000.0, 6400.0, 22200.0, 41100.0, 27600.0, 25900.0, 29600.0, 18500.0, 6900.0, 2500.0, 4000.0, 3900.0, 100.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3600.0, 11800.0, 29000.0, 39600.0, 58800.0, 61400.0, 44100.0, 45200.0, 46000.0, 28000.0, 29900.0, 8200.0, 2700.0, 400.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2600.0, 10400.0, 26400.0, 42400.0, 54500.0, 57900.0, 49900.0, 35700.0, 20600.0, 17300.0, 10700.0, 8500.0, 3900.0, 300.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1400.0, 11900.0, 21100.0, 22900.0, 46500.0, 35400.0, 44000.0, 43200.0, 31300.0, 20700.0, 13300.0, 8500.0, 4100.0, 300.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2100.0, 12700.0, 8700.0, 19600.0, 17900.0, 17800.0, 33400.0, 34900.0, 28400.0, 13700.0, 7700.0, 10900.0, 3000.0, 100.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3200.0, 10600.0, 19700.0, 21300.0, 34300.0, 35200.0, 36900.0, 38900.0, 40000.0, 15700.0, 8400.0, 6900.0, 2800.0, 100.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1500.0, 7600.0, 13000.0, 12000.0, 6000.0, 11000.0, 13900.0, 15300.0, 10200.0, 21100.0, 10200.0, 6100.0, 1300.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 800.0, 900.0, 1000.0, 2000.0, 2400.0, 4400.0, 3200.0, 2000.0, 3300.0, 3000.0, 5700.0, 1000.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 500.0, 2200.0, 1900.0, 3400.0, 4600.0, 5200.0, 3700.0, 3900.0, 400.0, 100.0, 100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 900.0, 6600.0, 100.0, 800.0, 1800.0, 10500.0, 4200.0, 7000.0, 2400.0, 2700.0, 1900.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3100.0, 10400.0, 23800.0, 30300.0, 67400.0, 36400.0, 34800.0, 56300.0, 31600.0, 25100.0, 14500.0, 7700.0, 1300.0, 650.0, 0.0, 0.0, 0.0, 0.0]], 'y_pred': [[0.0, 0.0, 5.682033538818359, 31.00566291809082, 72.44886779785156, 171.3776397705078, 344.39276123046875, 346.1357727050781, 346.29095458984375, 346.31207275390625, 346.3149108886719, 346.3153381347656, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375], [0.0, 0.0, 2.3796539306640625, 23.285682678222656, 59.297908782958984, 131.90811157226562, 336.0907897949219, 346.0530700683594, 346.2797546386719, 346.310546875, 346.314697265625, 346.3152160644531, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375], [0.0, 0.0, 7.356983661651611, 33.934844970703125, 78.01197814941406, 196.51699829101562, 345.1145324707031, 346.1679992675781, 346.2953796386719, 346.3126220703125, 346.3149719238281, 346.3153381347656, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375], [0.0, 0.0, 16.907705307006836, 56.360145568847656, 124.13304901123047, 329.2924499511719, 345.87554931640625, 346.255615234375, 346.3072814941406, 346.3143005371094, 346.31524658203125, 346.3153991699219, 346.3153991699219, 346.3153991699219, 346.3153991699219, 346.3153991699219, 346.3153991699219, 346.3153991699219, 346.3153991699219, 346.3153991699219, 346.3153991699219, 346.3153991699219, 346.3153991699219, 346.3153991699219], [0.0, 0.0, 1.285462737083435, 22.937633514404297, 58.60247039794922, 126.38492584228516, 331.9236755371094, 346.0550842285156, 346.2799987792969, 346.31060791015625, 346.314697265625, 346.3152770996094, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375], [0.0, 0.0, 2.2002854347229004, 23.098962783813477, 58.384029388427734, 126.78614044189453, 332.2167663574219, 346.03961181640625, 346.2779235839844, 346.3102722167969, 346.3146667480469, 346.3152160644531, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375], [0.0, 0.0, 2.6380414962768555, 22.50531768798828, 57.90436553955078, 130.6654815673828, 335.3614196777344, 346.0267028808594, 346.2761535644531, 346.30999755859375, 346.31463623046875, 346.3152160644531, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656], [0.0, 0.0, 1.9128546714782715, 20.751388549804688, 54.32523727416992, 120.28364562988281, 326.4462890625, 345.9726867675781, 346.2687683105469, 346.30902099609375, 346.3144836425781, 346.3152160644531, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656], [0.0, 0.0, 1.5970087051391602, 20.32429313659668, 53.54335403442383, 117.65689849853516, 323.1025085449219, 345.9530029296875, 346.26611328125, 346.3086853027344, 346.3144226074219, 346.3152160644531, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656], [0.0, 0.0, 3.0668482780456543, 23.855436325073242, 60.32810974121094, 136.10353088378906, 338.08056640625, 346.0502624511719, 346.27935791015625, 346.3104553222656, 346.314697265625, 346.3152160644531, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656], [0.0, 0.0, 5.1740498542785645, 29.573253631591797, 70.78252410888672, 169.90382385253906, 344.3851013183594, 346.1398620605469, 346.29156494140625, 346.3121337890625, 346.3149108886719, 346.3153381347656, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375], [0.0, 0.0, 1.623213768005371, 21.757596969604492, 56.126792907714844, 121.8709487915039, 327.8594055175781, 346.0181579589844, 346.2749938964844, 346.3098449707031, 346.31463623046875, 346.3152160644531, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375], [0.0, 0.0, 2.788752555847168, 24.149511337280273, 60.58135986328125, 134.48141479492188, 337.3623352050781, 346.0638732910156, 346.2812194824219, 346.3106994628906, 346.314697265625, 346.3152160644531, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375], [0.0, 0.0, 5.556899547576904, 30.339433670043945, 72.20628356933594, 175.1524658203125, 344.5907897949219, 346.1427917480469, 346.29193115234375, 346.3121643066406, 346.3149108886719, 346.3153381347656, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375], [0.0, 0.0, 2.2002410888671875, 23.201139450073242, 58.980804443359375, 129.88912963867188, 334.7723083496094, 346.0511779785156, 346.27947998046875, 346.31048583984375, 346.314697265625, 346.31524658203125, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375], [0.0, 0.0, 3.4876699447631836, 25.361587524414062, 62.740692138671875, 141.32395935058594, 340.1051025390625, 346.0833740234375, 346.2838439941406, 346.3110656738281, 346.31475830078125, 346.31524658203125, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375], [0.0, 0.0, 4.838522434234619, 27.7287540435791, 67.72283172607422, 160.73123168945312, 343.580322265625, 346.1084899902344, 346.2872619628906, 346.3115539550781, 346.3148498535156, 346.3153076171875, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656], [0.0, 0.0, 3.140336513519287, 24.24734878540039, 61.21786880493164, 139.25082397460938, 339.4349670410156, 346.0656433105469, 346.2814025878906, 346.31072998046875, 346.314697265625, 346.3152160644531, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656], [0.0, 0.0, 1.7972157001495361, 20.980302810668945, 54.592735290527344, 119.42227172851562, 325.1668395996094, 345.9807434082031, 346.2698669433594, 346.3091735839844, 346.31451416015625, 346.3152160644531, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656], [0.0, 0.0, 2.1648025512695312, 21.914060592651367, 56.33534622192383, 123.49211883544922, 329.4536437988281, 346.00146484375, 346.2726745605469, 346.3095703125, 346.3145751953125, 346.3152160644531, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656], [0.0, 0.0, 2.640109062194824, 22.8402042388916, 58.064205169677734, 128.36953735351562, 333.5473327636719, 346.0241394042969, 346.2757873535156, 346.3099670410156, 346.31463623046875, 346.3152160644531, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656], [0.0, 0.0, 2.2301135063171387, 22.00687026977539, 56.69007873535156, 125.37853240966797, 331.36572265625, 346.01190185546875, 346.27410888671875, 346.3097839355469, 346.3146057128906, 346.3152160644531, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656], [0.0, 0.0, 4.685766696929932, 27.550689697265625, 66.96739959716797, 156.52809143066406, 343.1824035644531, 346.108642578125, 346.2873229980469, 346.3115539550781, 346.3148498535156, 346.3153076171875, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375], [0.0, 0.0, 5.319982528686523, 30.058351516723633, 71.65750885009766, 173.21514892578125, 344.5703125, 346.147216796875, 346.29254150390625, 346.3122863769531, 346.3149108886719, 346.3153381347656, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375], [0.0, 0.0, 1.3011658191680908, 21.260272979736328, 54.97407150268555, 117.71451568603516, 322.4736022949219, 345.9972229003906, 346.27215576171875, 346.3094787597656, 346.3145751953125, 346.3152160644531, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375, 346.31536865234375], [0.0, 0.0, 1.482147216796875, 20.816200256347656, 54.22713088989258, 117.59944152832031, 322.7770690917969, 345.9865417480469, 346.2706604003906, 346.3092956542969, 346.3145446777344, 346.3152160644531, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656], [0.0, 0.0, 2.439439058303833, 21.936031341552734, 56.85747528076172, 127.99183654785156, 333.5689697265625, 346.0096130371094, 346.2738037109375, 346.30975341796875, 346.3145751953125, 346.3152160644531, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656], [0.0, 0.0, 3.328773021697998, 24.045381546020508, 60.8017463684082, 138.5198211669922, 339.0098876953125, 346.0497131347656, 346.279296875, 346.3104248046875, 346.3146667480469, 346.3152160644531, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656], [0.0, 0.0, 2.2644619941711426, 22.021835327148438, 56.6389274597168, 125.28175354003906, 331.3211975097656, 346.01654052734375, 346.2747497558594, 346.30987548828125, 346.3146057128906, 346.3152160644531, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656], [0.0, 0.0, 0.8881691098213196, 18.977645874023438, 50.66071701049805, 109.98277282714844, 310.880615234375, 345.93377685546875, 346.26348876953125, 346.3083190917969, 346.3144226074219, 346.315185546875, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656], [0.0, 0.0, 2.3436684608459473, 21.893857955932617, 56.25257873535156, 123.81990814208984, 329.75732421875, 345.9965515136719, 346.27203369140625, 346.3094787597656, 346.3145446777344, 346.3152160644531, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656], [0.0, 0.0, 2.3683247566223145, 22.18982696533203, 56.78736877441406, 125.22254943847656, 331.21466064453125, 346.0203552246094, 346.2752685546875, 346.3099060058594, 346.3146057128906, 346.3152160644531, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656], [0.0, 0.0, 0.6363962888717651, 18.776208877563477, 50.19116973876953, 107.78759002685547, 305.7212219238281, 345.9129638671875, 346.2607116699219, 346.30792236328125, 346.31439208984375, 346.315185546875, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656], [0.0, 0.0, 2.49418044090271, 22.745391845703125, 57.75792694091797, 126.8156967163086, 332.37335205078125, 346.02569580078125, 346.2759704589844, 346.30999755859375, 346.31463623046875, 346.3152160644531, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656], [0.0, 0.0, 2.8751883506774902, 23.818649291992188, 59.7934684753418, 132.3008270263672, 336.1112976074219, 346.0506286621094, 346.27935791015625, 346.31048583984375, 346.314697265625, 346.3152160644531, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656], [0.0, 0.0, 2.282987594604492, 22.78720474243164, 57.88780975341797, 126.52909851074219, 332.136962890625, 346.0305480957031, 346.27667236328125, 346.31005859375, 346.31463623046875, 346.3152160644531, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656], [0.0, 0.0, 2.212230920791626, 22.581924438476562, 57.374420166015625, 124.62200164794922, 330.3529357910156, 346.01971435546875, 346.2751770019531, 346.30987548828125, 346.31463623046875, 346.3152160644531, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656], [0.0, 0.0, 1.8417363166809082, 21.805089950561523, 55.99082565307617, 121.35662841796875, 327.1930236816406, 346.0097351074219, 346.2738037109375, 346.3097229003906, 346.3145751953125, 346.3152160644531, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656], [0.0, 0.0, 1.6191149950027466, 21.192344665527344, 54.84143829345703, 118.65866088867188, 324.03662109375, 345.9945373535156, 346.2717590332031, 346.3094177246094, 346.3145751953125, 346.3152160644531, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656], [0.0, 0.0, 2.4464821815490723, 22.92196273803711, 58.262001037597656, 128.53831481933594, 333.8100280761719, 346.0382995605469, 346.2777099609375, 346.3102722167969, 346.31463623046875, 346.3152160644531, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656], [0.0, 0.0, 1.9234788417816162, 21.53279685974121, 55.43836212158203, 120.50591278076172, 326.2699890136719, 345.997802734375, 346.2721862792969, 346.3094787597656, 346.3145751953125, 346.3152160644531, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656], [0.0, 0.0, 2.7816085815429688, 23.67778778076172, 59.72563552856445, 132.69493103027344, 336.40765380859375, 346.050537109375, 346.2793884277344, 346.31048583984375, 346.314697265625, 346.3152160644531, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656, 346.3153381347656]], 'exp_name': 'solar power prediction using weather features', 'plant': 126, 'spot': 174, 'start_date': '20190820', 'end_date': '20200809', 'batch_size': 64, 'x_frames': 3, 'y_frames': 1, 'hid_dim': 256, 'optim': 'RMSprop', 'activation': 'relu', 'lss': 'MSE', 'lr': 0.001, 'epochs': 256, 'early_stop': 30, 'evaluation': 'NRMSE', 'features': \"[<FeatureType.SUNSHINE: '일조(hr)'>, <FeatureType.HUMIDITY: '습도(%)'>, <FeatureType.WIND_SPEED: '풍속(m/s)'>, <FeatureType.VISIBILITY: '시정(10m)'>, <FeatureType.GROUND_TEMPERATURE: '지면온도(°C)'>, <FeatureType.WIND_DIRECTION: '풍향(16방위)'>]\"}\n",
      "\n",
      "Namespace(activation='relu', batch_size=64, early_stop=30, end_date='20200809', epochs=256, evaluation='NRMSE', exp_name='solar power prediction using weather features', features=\"[<FeatureType.SUNSHINE: '일조(hr)'>, <FeatureType.HUMIDITY: '습도(%)'>, <FeatureType.WIND_SPEED: '풍속(m/s)'>, <FeatureType.VISIBILITY: '시정(10m)'>, <FeatureType.GROUND_TEMPERATURE: '지면온도(°C)'>, <FeatureType.WIND_DIRECTION: '풍향(16방위)'>, <FeatureType.STEAM_PRESSURE: '현지기압(hPa)'>]\", hid_dim=256, lr=0.001, lss='MSE', optim='RMSprop', plant=126, spot=174, start_date='20190820', x_frames=3, y_frames=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/256\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 1316820096.0000 - accuracy: 0.1316 - val_loss: 854954560.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1316348032.0000 - accuracy: 0.0000e+00 - val_loss: 854842048.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1316260608.0000 - accuracy: 0.0000e+00 - val_loss: 854783232.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1316205440.0000 - accuracy: 0.0000e+00 - val_loss: 854734720.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1316158464.0000 - accuracy: 0.0000e+00 - val_loss: 854687232.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1316111232.0000 - accuracy: 0.0000e+00 - val_loss: 854641024.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1316066432.0000 - accuracy: 0.0000e+00 - val_loss: 854599552.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1316024832.0000 - accuracy: 0.0000e+00 - val_loss: 854557632.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315982592.0000 - accuracy: 0.0000e+00 - val_loss: 854512960.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315938176.0000 - accuracy: 0.0000e+00 - val_loss: 854468224.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315894144.0000 - accuracy: 0.0000e+00 - val_loss: 854423424.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315849344.0000 - accuracy: 0.0000e+00 - val_loss: 854377536.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315804032.0000 - accuracy: 0.0000e+00 - val_loss: 854331200.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315757568.0000 - accuracy: 0.0000e+00 - val_loss: 854284992.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315712896.0000 - accuracy: 0.0000e+00 - val_loss: 854244096.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315671552.0000 - accuracy: 0.0000e+00 - val_loss: 854202176.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1315629568.0000 - accuracy: 0.0000e+00 - val_loss: 854155264.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315583360.0000 - accuracy: 0.0000e+00 - val_loss: 854114880.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315542656.0000 - accuracy: 0.0000e+00 - val_loss: 854073216.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315501184.0000 - accuracy: 0.0000e+00 - val_loss: 854032256.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315477248.0000 - accuracy: 0.0000e+00 - val_loss: 853987840.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315414784.0000 - accuracy: 0.0000e+00 - val_loss: 853944000.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315372416.0000 - accuracy: 0.0000e+00 - val_loss: 853896064.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315324928.0000 - accuracy: 0.0000e+00 - val_loss: 853851776.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315281280.0000 - accuracy: 0.0000e+00 - val_loss: 853810048.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1315239552.0000 - accuracy: 0.0000e+00 - val_loss: 853763712.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315193856.0000 - accuracy: 0.0000e+00 - val_loss: 853717504.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315148544.0000 - accuracy: 0.0000e+00 - val_loss: 853674368.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315105536.0000 - accuracy: 0.0000e+00 - val_loss: 853634496.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315065344.0000 - accuracy: 0.0000e+00 - val_loss: 853591296.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315022080.0000 - accuracy: 0.0000e+00 - val_loss: 853548096.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314979072.0000 - accuracy: 0.0000e+00 - val_loss: 853504512.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314935936.0000 - accuracy: 0.0000e+00 - val_loss: 853461312.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1314893056.0000 - accuracy: 0.0000e+00 - val_loss: 853418176.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314849792.0000 - accuracy: 0.0000e+00 - val_loss: 853376256.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1314807680.0000 - accuracy: 0.0000e+00 - val_loss: 853332352.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314763904.0000 - accuracy: 0.0000e+00 - val_loss: 853285056.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314717184.0000 - accuracy: 0.0000e+00 - val_loss: 853242240.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314674816.0000 - accuracy: 0.0000e+00 - val_loss: 853196224.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314629248.0000 - accuracy: 0.0000e+00 - val_loss: 853151872.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314585216.0000 - accuracy: 0.0000e+00 - val_loss: 853109440.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314542464.0000 - accuracy: 0.0000e+00 - val_loss: 853061056.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314495872.0000 - accuracy: 0.0000e+00 - val_loss: 853021760.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314455936.0000 - accuracy: 0.0000e+00 - val_loss: 852977344.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1314411392.0000 - accuracy: 0.0000e+00 - val_loss: 852929216.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314365184.0000 - accuracy: 0.0000e+00 - val_loss: 852889024.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314324480.0000 - accuracy: 0.0000e+00 - val_loss: 852846720.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314282240.0000 - accuracy: 0.0000e+00 - val_loss: 852802432.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314238336.0000 - accuracy: 0.0000e+00 - val_loss: 852762944.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 11ms/step - loss: 1314198400.0000 - accuracy: 0.0000e+00 - val_loss: 852717888.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314153984.0000 - accuracy: 0.0000e+00 - val_loss: 852677760.0000 - val_accuracy: 0.0407\n",
      "Epoch 52/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314111744.0000 - accuracy: 0.0101 - val_loss: 852632640.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314068608.0000 - accuracy: 0.0000e+00 - val_loss: 852585344.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314022272.0000 - accuracy: 0.0000e+00 - val_loss: 852543360.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1313980416.0000 - accuracy: 0.0000e+00 - val_loss: 852499712.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313936768.0000 - accuracy: 0.0000e+00 - val_loss: 852453952.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313891584.0000 - accuracy: 0.0000e+00 - val_loss: 852410880.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313848960.0000 - accuracy: 0.0000e+00 - val_loss: 852368320.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313806080.0000 - accuracy: 0.0000e+00 - val_loss: 852322816.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313761152.0000 - accuracy: 0.0000e+00 - val_loss: 852278784.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313717504.0000 - accuracy: 0.0000e+00 - val_loss: 852236800.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313675520.0000 - accuracy: 0.0000e+00 - val_loss: 852195904.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313634304.0000 - accuracy: 0.0000e+00 - val_loss: 852146944.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1313587072.0000 - accuracy: 0.0000e+00 - val_loss: 852107072.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313547136.0000 - accuracy: 0.0000e+00 - val_loss: 852065984.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313505536.0000 - accuracy: 0.0000e+00 - val_loss: 852024064.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313463680.0000 - accuracy: 0.0000e+00 - val_loss: 851978432.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313418624.0000 - accuracy: 0.0000e+00 - val_loss: 851936896.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313376640.0000 - accuracy: 0.0000e+00 - val_loss: 851889664.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313330432.0000 - accuracy: 0.0000e+00 - val_loss: 851846784.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313287680.0000 - accuracy: 0.0000e+00 - val_loss: 851805504.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313246336.0000 - accuracy: 0.0000e+00 - val_loss: 851760256.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313201408.0000 - accuracy: 0.0000e+00 - val_loss: 851714368.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1313155840.0000 - accuracy: 0.0000e+00 - val_loss: 851668224.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313110528.0000 - accuracy: 0.0000e+00 - val_loss: 851629568.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313071488.0000 - accuracy: 0.0000e+00 - val_loss: 851585152.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313027200.0000 - accuracy: 0.0000e+00 - val_loss: 851540544.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312983168.0000 - accuracy: 0.0000e+00 - val_loss: 851497664.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312940416.0000 - accuracy: 0.0000e+00 - val_loss: 851451392.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312894976.0000 - accuracy: 0.0000e+00 - val_loss: 851409856.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312853504.0000 - accuracy: 0.0000e+00 - val_loss: 851366592.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312810624.0000 - accuracy: 0.0000e+00 - val_loss: 851323392.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1312767232.0000 - accuracy: 0.0000e+00 - val_loss: 851280192.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312724352.0000 - accuracy: 0.0000e+00 - val_loss: 851233856.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312679040.0000 - accuracy: 0.0000e+00 - val_loss: 851193344.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312637824.0000 - accuracy: 0.0000e+00 - val_loss: 851147136.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312592384.0000 - accuracy: 0.0000e+00 - val_loss: 851103936.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312549248.0000 - accuracy: 0.0000e+00 - val_loss: 851060160.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312505856.0000 - accuracy: 0.0000e+00 - val_loss: 851014592.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312460928.0000 - accuracy: 0.0000e+00 - val_loss: 850971392.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312418048.0000 - accuracy: 0.0000e+00 - val_loss: 850929152.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312375936.0000 - accuracy: 0.0000e+00 - val_loss: 850886464.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1312333568.0000 - accuracy: 0.0000e+00 - val_loss: 850842880.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312289664.0000 - accuracy: 0.0000e+00 - val_loss: 850796864.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312243968.0000 - accuracy: 0.0000e+00 - val_loss: 850751168.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312199552.0000 - accuracy: 0.0000e+00 - val_loss: 850709632.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312157440.0000 - accuracy: 0.0000e+00 - val_loss: 850663424.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312112384.0000 - accuracy: 0.0000e+00 - val_loss: 850620800.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 12ms/step - loss: 1312069376.0000 - accuracy: 0.0000e+00 - val_loss: 850578112.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312027008.0000 - accuracy: 0.0000e+00 - val_loss: 850535744.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 101/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311984896.0000 - accuracy: 0.0000e+00 - val_loss: 850489920.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 102/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1311939584.0000 - accuracy: 0.0000e+00 - val_loss: 850448064.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 103/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311897728.0000 - accuracy: 0.0000e+00 - val_loss: 850404416.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 104/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311854208.0000 - accuracy: 0.0000e+00 - val_loss: 850361600.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 105/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311811584.0000 - accuracy: 0.0000e+00 - val_loss: 850317504.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 106/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311768064.0000 - accuracy: 0.0000e+00 - val_loss: 850274688.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 107/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311724928.0000 - accuracy: 0.0000e+00 - val_loss: 850226304.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 108/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311678336.0000 - accuracy: 0.0000e+00 - val_loss: 850184896.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 109/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1311636352.0000 - accuracy: 0.0000e+00 - val_loss: 850141696.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 110/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311593856.0000 - accuracy: 0.0000e+00 - val_loss: 850100544.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 111/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311552256.0000 - accuracy: 0.0000e+00 - val_loss: 850058368.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 112/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1311510144.0000 - accuracy: 0.0000e+00 - val_loss: 850011200.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 113/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311463808.0000 - accuracy: 0.0000e+00 - val_loss: 849968192.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 114/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311420928.0000 - accuracy: 0.0000e+00 - val_loss: 849926720.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 115/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311379712.0000 - accuracy: 0.0000e+00 - val_loss: 849883008.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 116/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311335680.0000 - accuracy: 0.0000e+00 - val_loss: 849838272.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 117/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311291776.0000 - accuracy: 0.0000e+00 - val_loss: 849796544.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 118/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311250048.0000 - accuracy: 0.0000e+00 - val_loss: 849751872.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 119/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311205632.0000 - accuracy: 0.0000e+00 - val_loss: 849705728.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 120/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1311160192.0000 - accuracy: 0.0000e+00 - val_loss: 849663424.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 121/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1311118336.0000 - accuracy: 0.0000e+00 - val_loss: 849619648.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 122/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311074688.0000 - accuracy: 0.0000e+00 - val_loss: 849576512.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 123/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311031296.0000 - accuracy: 0.0000e+00 - val_loss: 849530688.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 124/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310986368.0000 - accuracy: 0.0000e+00 - val_loss: 849486144.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 125/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310942208.0000 - accuracy: 0.0000e+00 - val_loss: 849445056.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 126/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310900736.0000 - accuracy: 0.0000e+00 - val_loss: 849398528.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 127/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1310855296.0000 - accuracy: 0.0000e+00 - val_loss: 849354240.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 128/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310811136.0000 - accuracy: 0.0000e+00 - val_loss: 849312896.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 129/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310769920.0000 - accuracy: 0.0000e+00 - val_loss: 849266368.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 130/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310724096.0000 - accuracy: 0.0000e+00 - val_loss: 849224256.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 131/256\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1310681856.0000 - accuracy: 0.0000e+00 - val_loss: 849181440.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 132/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310639616.0000 - accuracy: 0.0000e+00 - val_loss: 849140608.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 133/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310598144.0000 - accuracy: 0.0000e+00 - val_loss: 849096576.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 134/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310554752.0000 - accuracy: 0.0000e+00 - val_loss: 849052928.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 135/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310511104.0000 - accuracy: 0.0000e+00 - val_loss: 849008832.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 136/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310467968.0000 - accuracy: 0.0000e+00 - val_loss: 848962048.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 137/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310421760.0000 - accuracy: 0.0000e+00 - val_loss: 848920000.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 138/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310379520.0000 - accuracy: 0.0000e+00 - val_loss: 848874752.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 139/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310334848.0000 - accuracy: 0.0000e+00 - val_loss: 848833024.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 140/256\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1310292864.0000 - accuracy: 0.0000e+00 - val_loss: 848789504.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 141/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310249728.0000 - accuracy: 0.0000e+00 - val_loss: 848744832.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 142/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310206464.0000 - accuracy: 0.0000e+00 - val_loss: 848704832.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 143/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310165376.0000 - accuracy: 0.0000e+00 - val_loss: 848663040.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 144/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310124032.0000 - accuracy: 0.0000e+00 - val_loss: 848618944.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 145/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310080256.0000 - accuracy: 0.0000e+00 - val_loss: 848576832.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 146/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310037632.0000 - accuracy: 0.0000e+00 - val_loss: 848529280.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 147/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1309991424.0000 - accuracy: 0.0000e+00 - val_loss: 848483968.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 148/256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 11ms/step - loss: 1309946368.0000 - accuracy: 0.0000e+00 - val_loss: 848441152.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 149/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309903488.0000 - accuracy: 0.0000e+00 - val_loss: 848395008.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 150/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1309858560.0000 - accuracy: 0.0000e+00 - val_loss: 848353472.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 151/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309816064.0000 - accuracy: 0.0000e+00 - val_loss: 848309888.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 152/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309772928.0000 - accuracy: 0.0000e+00 - val_loss: 848265536.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 153/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309728896.0000 - accuracy: 0.0000e+00 - val_loss: 848219200.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 154/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309683712.0000 - accuracy: 0.0000e+00 - val_loss: 848179072.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 155/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309643392.0000 - accuracy: 0.0000e+00 - val_loss: 848138368.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 156/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309602560.0000 - accuracy: 0.0000e+00 - val_loss: 848097280.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 157/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309561216.0000 - accuracy: 0.0000e+00 - val_loss: 848050176.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 158/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309515392.0000 - accuracy: 0.0000e+00 - val_loss: 848007040.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 159/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1309472512.0000 - accuracy: 0.0000e+00 - val_loss: 847964672.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 160/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309430272.0000 - accuracy: 0.0000e+00 - val_loss: 847920448.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 161/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309386240.0000 - accuracy: 0.0000e+00 - val_loss: 847880320.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 162/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309345536.0000 - accuracy: 0.0000e+00 - val_loss: 847834240.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 163/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309300608.0000 - accuracy: 0.0000e+00 - val_loss: 847791232.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 164/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309257600.0000 - accuracy: 0.0000e+00 - val_loss: 847745152.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 165/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309212544.0000 - accuracy: 0.0000e+00 - val_loss: 847702720.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 166/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309170176.0000 - accuracy: 0.0000e+00 - val_loss: 847655680.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 167/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309123968.0000 - accuracy: 0.0000e+00 - val_loss: 847616192.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 168/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309084160.0000 - accuracy: 0.0000e+00 - val_loss: 847577856.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 169/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1309044608.0000 - accuracy: 0.0000e+00 - val_loss: 847535168.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 170/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309002752.0000 - accuracy: 0.0000e+00 - val_loss: 847487168.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 171/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308955904.0000 - accuracy: 0.0000e+00 - val_loss: 847443456.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 172/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308912256.0000 - accuracy: 0.0000e+00 - val_loss: 847402048.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 173/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308871296.0000 - accuracy: 0.0000e+00 - val_loss: 847357632.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 174/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308827136.0000 - accuracy: 0.0000e+00 - val_loss: 847316992.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 175/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1308785792.0000 - accuracy: 0.0000e+00 - val_loss: 847270464.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 176/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308740736.0000 - accuracy: 0.0000e+00 - val_loss: 847227392.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 177/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308697856.0000 - accuracy: 0.0000e+00 - val_loss: 847186496.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 178/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1308656384.0000 - accuracy: 0.0000e+00 - val_loss: 847142336.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 179/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308613248.0000 - accuracy: 0.0000e+00 - val_loss: 847102912.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 180/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308573056.0000 - accuracy: 0.0000e+00 - val_loss: 847060992.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 181/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308530304.0000 - accuracy: 0.0000e+00 - val_loss: 847014592.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 182/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308485632.0000 - accuracy: 0.0000e+00 - val_loss: 846968320.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 183/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308439936.0000 - accuracy: 0.0000e+00 - val_loss: 846923776.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 184/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308395904.0000 - accuracy: 0.0000e+00 - val_loss: 846880384.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 185/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308352640.0000 - accuracy: 0.0000e+00 - val_loss: 846839232.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 186/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308310784.0000 - accuracy: 0.0000e+00 - val_loss: 846792704.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 187/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308265600.0000 - accuracy: 0.0000e+00 - val_loss: 846745920.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 188/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1308219904.0000 - accuracy: 0.0000e+00 - val_loss: 846704320.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 189/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308177920.0000 - accuracy: 0.0000e+00 - val_loss: 846661760.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 190/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308135040.0000 - accuracy: 0.0000e+00 - val_loss: 846619904.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 191/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308092544.0000 - accuracy: 0.0000e+00 - val_loss: 846575744.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 192/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308049792.0000 - accuracy: 0.0000e+00 - val_loss: 846532736.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 193/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308007168.0000 - accuracy: 0.0000e+00 - val_loss: 846491136.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 194/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307965568.0000 - accuracy: 0.0000e+00 - val_loss: 846447360.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 195/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307922048.0000 - accuracy: 0.0000e+00 - val_loss: 846407360.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 196/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307881728.0000 - accuracy: 0.0000e+00 - val_loss: 846363392.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 197/256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 12ms/step - loss: 1307837440.0000 - accuracy: 0.0000e+00 - val_loss: 846319232.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 198/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307793536.0000 - accuracy: 0.0000e+00 - val_loss: 846276480.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 199/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307751424.0000 - accuracy: 0.0000e+00 - val_loss: 846237120.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 200/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307711488.0000 - accuracy: 0.0000e+00 - val_loss: 846192256.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 201/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307667456.0000 - accuracy: 0.0000e+00 - val_loss: 846148352.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 202/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307623424.0000 - accuracy: 0.0000e+00 - val_loss: 846100160.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 203/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307577600.0000 - accuracy: 0.0000e+00 - val_loss: 846058176.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 204/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307535744.0000 - accuracy: 0.0000e+00 - val_loss: 846018688.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 205/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307495168.0000 - accuracy: 0.0000e+00 - val_loss: 845972352.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 206/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1307449344.0000 - accuracy: 0.0000e+00 - val_loss: 845928960.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 207/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1307406080.0000 - accuracy: 0.0000e+00 - val_loss: 845886016.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 208/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307362944.0000 - accuracy: 0.0000e+00 - val_loss: 845842624.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 209/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307320448.0000 - accuracy: 0.0000e+00 - val_loss: 845800000.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 210/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307277824.0000 - accuracy: 0.0000e+00 - val_loss: 845750272.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 211/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307230208.0000 - accuracy: 0.0000e+00 - val_loss: 845705600.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 212/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307186304.0000 - accuracy: 0.0000e+00 - val_loss: 845668224.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 213/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307148032.0000 - accuracy: 0.0000e+00 - val_loss: 845627968.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 214/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307107200.0000 - accuracy: 0.0000e+00 - val_loss: 845587520.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 215/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307066368.0000 - accuracy: 0.0000e+00 - val_loss: 845541504.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 216/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1307021056.0000 - accuracy: 0.0000e+00 - val_loss: 845499648.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 217/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306978944.0000 - accuracy: 0.0000e+00 - val_loss: 845459264.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 218/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306938368.0000 - accuracy: 0.0000e+00 - val_loss: 845417792.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 219/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306896128.0000 - accuracy: 0.0000e+00 - val_loss: 845369472.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 220/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306849664.0000 - accuracy: 0.0000e+00 - val_loss: 845324992.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 221/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306805888.0000 - accuracy: 0.0000e+00 - val_loss: 845282624.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 222/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306763264.0000 - accuracy: 0.0000e+00 - val_loss: 845237696.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 223/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306719488.0000 - accuracy: 0.0000e+00 - val_loss: 845192448.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 224/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1306674176.0000 - accuracy: 0.0000e+00 - val_loss: 845147200.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 225/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306629632.0000 - accuracy: 0.0000e+00 - val_loss: 845105920.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 226/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1306588032.0000 - accuracy: 0.0000e+00 - val_loss: 845062720.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 227/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306545280.0000 - accuracy: 0.0000e+00 - val_loss: 845020800.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 228/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306503296.0000 - accuracy: 0.0000e+00 - val_loss: 844978368.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 229/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306461056.0000 - accuracy: 0.0000e+00 - val_loss: 844933120.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 230/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306417152.0000 - accuracy: 0.0000e+00 - val_loss: 844890624.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 231/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306374656.0000 - accuracy: 0.0000e+00 - val_loss: 844850496.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 232/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306334336.0000 - accuracy: 0.0000e+00 - val_loss: 844808384.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 233/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306292352.0000 - accuracy: 0.0000e+00 - val_loss: 844764992.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 234/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306248832.0000 - accuracy: 0.0000e+00 - val_loss: 844722752.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 235/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1306206976.0000 - accuracy: 0.0000e+00 - val_loss: 844683136.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 236/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306167040.0000 - accuracy: 0.0000e+00 - val_loss: 844642432.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 237/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306125568.0000 - accuracy: 0.0000e+00 - val_loss: 844597120.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 238/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306081792.0000 - accuracy: 0.0000e+00 - val_loss: 844553664.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 239/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306038144.0000 - accuracy: 0.0000e+00 - val_loss: 844509888.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 240/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1305994624.0000 - accuracy: 0.0000e+00 - val_loss: 844466304.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 241/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1305950848.0000 - accuracy: 0.0000e+00 - val_loss: 844419840.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 242/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1305905664.0000 - accuracy: 0.0000e+00 - val_loss: 844375104.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 243/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1305861504.0000 - accuracy: 0.0000e+00 - val_loss: 844335232.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 244/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1305821184.0000 - accuracy: 0.0000e+00 - val_loss: 844292480.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 245/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1305778816.0000 - accuracy: 0.0000e+00 - val_loss: 844247936.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 246/256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 11ms/step - loss: 1305734656.0000 - accuracy: 0.0000e+00 - val_loss: 844204160.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 247/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1305690880.0000 - accuracy: 0.0000e+00 - val_loss: 844157824.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 248/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1305645568.0000 - accuracy: 0.0000e+00 - val_loss: 844115008.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 249/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1305602688.0000 - accuracy: 0.0000e+00 - val_loss: 844070400.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 250/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1305559040.0000 - accuracy: 0.0000e+00 - val_loss: 844032384.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 251/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1305519488.0000 - accuracy: 0.0000e+00 - val_loss: 843989888.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 252/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1305477248.0000 - accuracy: 0.0000e+00 - val_loss: 843941568.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 253/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1305430656.0000 - accuracy: 0.0000e+00 - val_loss: 843899456.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 254/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1305388032.0000 - accuracy: 0.0000e+00 - val_loss: 843854144.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 255/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1305343616.0000 - accuracy: 0.0000e+00 - val_loss: 843811584.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 256/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1305301760.0000 - accuracy: 0.0000e+00 - val_loss: 843772096.0000 - val_accuracy: 0.0000e+00\n",
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            [(None, 72, 7)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_12 (LSTM)                  [(None, 256), (None, 270336      input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_6 (RepeatVector)  (None, 24, 256)      0           lstm_12[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_13 (LSTM)                  [(None, 24, 256), (N 525312      repeat_vector_6[0][0]            \n",
      "                                                                 lstm_12[0][1]                    \n",
      "                                                                 lstm_12[0][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 24, 1)        257         lstm_13[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 795,905\n",
      "Trainable params: 795,905\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Took 19.94 sec for training the model\n",
      "{'train_losses': [1316820096.0, 1316348032.0, 1316260608.0, 1316205440.0, 1316158464.0, 1316111232.0, 1316066432.0, 1316024832.0, 1315982592.0, 1315938176.0, 1315894144.0, 1315849344.0, 1315804032.0, 1315757568.0, 1315712896.0, 1315671552.0, 1315629568.0, 1315583360.0, 1315542656.0, 1315501184.0, 1315477248.0, 1315414784.0, 1315372416.0, 1315324928.0, 1315281280.0, 1315239552.0, 1315193856.0, 1315148544.0, 1315105536.0, 1315065344.0, 1315022080.0, 1314979072.0, 1314935936.0, 1314893056.0, 1314849792.0, 1314807680.0, 1314763904.0, 1314717184.0, 1314674816.0, 1314629248.0, 1314585216.0, 1314542464.0, 1314495872.0, 1314455936.0, 1314411392.0, 1314365184.0, 1314324480.0, 1314282240.0, 1314238336.0, 1314198400.0, 1314153984.0, 1314111744.0, 1314068608.0, 1314022272.0, 1313980416.0, 1313936768.0, 1313891584.0, 1313848960.0, 1313806080.0, 1313761152.0, 1313717504.0, 1313675520.0, 1313634304.0, 1313587072.0, 1313547136.0, 1313505536.0, 1313463680.0, 1313418624.0, 1313376640.0, 1313330432.0, 1313287680.0, 1313246336.0, 1313201408.0, 1313155840.0, 1313110528.0, 1313071488.0, 1313027200.0, 1312983168.0, 1312940416.0, 1312894976.0, 1312853504.0, 1312810624.0, 1312767232.0, 1312724352.0, 1312679040.0, 1312637824.0, 1312592384.0, 1312549248.0, 1312505856.0, 1312460928.0, 1312418048.0, 1312375936.0, 1312333568.0, 1312289664.0, 1312243968.0, 1312199552.0, 1312157440.0, 1312112384.0, 1312069376.0, 1312027008.0, 1311984896.0, 1311939584.0, 1311897728.0, 1311854208.0, 1311811584.0, 1311768064.0, 1311724928.0, 1311678336.0, 1311636352.0, 1311593856.0, 1311552256.0, 1311510144.0, 1311463808.0, 1311420928.0, 1311379712.0, 1311335680.0, 1311291776.0, 1311250048.0, 1311205632.0, 1311160192.0, 1311118336.0, 1311074688.0, 1311031296.0, 1310986368.0, 1310942208.0, 1310900736.0, 1310855296.0, 1310811136.0, 1310769920.0, 1310724096.0, 1310681856.0, 1310639616.0, 1310598144.0, 1310554752.0, 1310511104.0, 1310467968.0, 1310421760.0, 1310379520.0, 1310334848.0, 1310292864.0, 1310249728.0, 1310206464.0, 1310165376.0, 1310124032.0, 1310080256.0, 1310037632.0, 1309991424.0, 1309946368.0, 1309903488.0, 1309858560.0, 1309816064.0, 1309772928.0, 1309728896.0, 1309683712.0, 1309643392.0, 1309602560.0, 1309561216.0, 1309515392.0, 1309472512.0, 1309430272.0, 1309386240.0, 1309345536.0, 1309300608.0, 1309257600.0, 1309212544.0, 1309170176.0, 1309123968.0, 1309084160.0, 1309044608.0, 1309002752.0, 1308955904.0, 1308912256.0, 1308871296.0, 1308827136.0, 1308785792.0, 1308740736.0, 1308697856.0, 1308656384.0, 1308613248.0, 1308573056.0, 1308530304.0, 1308485632.0, 1308439936.0, 1308395904.0, 1308352640.0, 1308310784.0, 1308265600.0, 1308219904.0, 1308177920.0, 1308135040.0, 1308092544.0, 1308049792.0, 1308007168.0, 1307965568.0, 1307922048.0, 1307881728.0, 1307837440.0, 1307793536.0, 1307751424.0, 1307711488.0, 1307667456.0, 1307623424.0, 1307577600.0, 1307535744.0, 1307495168.0, 1307449344.0, 1307406080.0, 1307362944.0, 1307320448.0, 1307277824.0, 1307230208.0, 1307186304.0, 1307148032.0, 1307107200.0, 1307066368.0, 1307021056.0, 1306978944.0, 1306938368.0, 1306896128.0, 1306849664.0, 1306805888.0, 1306763264.0, 1306719488.0, 1306674176.0, 1306629632.0, 1306588032.0, 1306545280.0, 1306503296.0, 1306461056.0, 1306417152.0, 1306374656.0, 1306334336.0, 1306292352.0, 1306248832.0, 1306206976.0, 1306167040.0, 1306125568.0, 1306081792.0, 1306038144.0, 1305994624.0, 1305950848.0, 1305905664.0, 1305861504.0, 1305821184.0, 1305778816.0, 1305734656.0, 1305690880.0, 1305645568.0, 1305602688.0, 1305559040.0, 1305519488.0, 1305477248.0, 1305430656.0, 1305388032.0, 1305343616.0, 1305301760.0], 'val_losses': [854954560.0, 854842048.0, 854783232.0, 854734720.0, 854687232.0, 854641024.0, 854599552.0, 854557632.0, 854512960.0, 854468224.0, 854423424.0, 854377536.0, 854331200.0, 854284992.0, 854244096.0, 854202176.0, 854155264.0, 854114880.0, 854073216.0, 854032256.0, 853987840.0, 853944000.0, 853896064.0, 853851776.0, 853810048.0, 853763712.0, 853717504.0, 853674368.0, 853634496.0, 853591296.0, 853548096.0, 853504512.0, 853461312.0, 853418176.0, 853376256.0, 853332352.0, 853285056.0, 853242240.0, 853196224.0, 853151872.0, 853109440.0, 853061056.0, 853021760.0, 852977344.0, 852929216.0, 852889024.0, 852846720.0, 852802432.0, 852762944.0, 852717888.0, 852677760.0, 852632640.0, 852585344.0, 852543360.0, 852499712.0, 852453952.0, 852410880.0, 852368320.0, 852322816.0, 852278784.0, 852236800.0, 852195904.0, 852146944.0, 852107072.0, 852065984.0, 852024064.0, 851978432.0, 851936896.0, 851889664.0, 851846784.0, 851805504.0, 851760256.0, 851714368.0, 851668224.0, 851629568.0, 851585152.0, 851540544.0, 851497664.0, 851451392.0, 851409856.0, 851366592.0, 851323392.0, 851280192.0, 851233856.0, 851193344.0, 851147136.0, 851103936.0, 851060160.0, 851014592.0, 850971392.0, 850929152.0, 850886464.0, 850842880.0, 850796864.0, 850751168.0, 850709632.0, 850663424.0, 850620800.0, 850578112.0, 850535744.0, 850489920.0, 850448064.0, 850404416.0, 850361600.0, 850317504.0, 850274688.0, 850226304.0, 850184896.0, 850141696.0, 850100544.0, 850058368.0, 850011200.0, 849968192.0, 849926720.0, 849883008.0, 849838272.0, 849796544.0, 849751872.0, 849705728.0, 849663424.0, 849619648.0, 849576512.0, 849530688.0, 849486144.0, 849445056.0, 849398528.0, 849354240.0, 849312896.0, 849266368.0, 849224256.0, 849181440.0, 849140608.0, 849096576.0, 849052928.0, 849008832.0, 848962048.0, 848920000.0, 848874752.0, 848833024.0, 848789504.0, 848744832.0, 848704832.0, 848663040.0, 848618944.0, 848576832.0, 848529280.0, 848483968.0, 848441152.0, 848395008.0, 848353472.0, 848309888.0, 848265536.0, 848219200.0, 848179072.0, 848138368.0, 848097280.0, 848050176.0, 848007040.0, 847964672.0, 847920448.0, 847880320.0, 847834240.0, 847791232.0, 847745152.0, 847702720.0, 847655680.0, 847616192.0, 847577856.0, 847535168.0, 847487168.0, 847443456.0, 847402048.0, 847357632.0, 847316992.0, 847270464.0, 847227392.0, 847186496.0, 847142336.0, 847102912.0, 847060992.0, 847014592.0, 846968320.0, 846923776.0, 846880384.0, 846839232.0, 846792704.0, 846745920.0, 846704320.0, 846661760.0, 846619904.0, 846575744.0, 846532736.0, 846491136.0, 846447360.0, 846407360.0, 846363392.0, 846319232.0, 846276480.0, 846237120.0, 846192256.0, 846148352.0, 846100160.0, 846058176.0, 846018688.0, 845972352.0, 845928960.0, 845886016.0, 845842624.0, 845800000.0, 845750272.0, 845705600.0, 845668224.0, 845627968.0, 845587520.0, 845541504.0, 845499648.0, 845459264.0, 845417792.0, 845369472.0, 845324992.0, 845282624.0, 845237696.0, 845192448.0, 845147200.0, 845105920.0, 845062720.0, 845020800.0, 844978368.0, 844933120.0, 844890624.0, 844850496.0, 844808384.0, 844764992.0, 844722752.0, 844683136.0, 844642432.0, 844597120.0, 844553664.0, 844509888.0, 844466304.0, 844419840.0, 844375104.0, 844335232.0, 844292480.0, 844247936.0, 844204160.0, 844157824.0, 844115008.0, 844070400.0, 844032384.0, 843989888.0, 843941568.0, 843899456.0, 843854144.0, 843811584.0, 843772096.0], 'train_accs': [0.13160377740859985, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01006289292126894, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'val_accs': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0406746082007885, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'train_acc': 0.00055338543097605, 'val_acc': 0.00015888518828433007, 'test_nrmse': 0.9893934829501271, 'y_test': [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1200.0, 2500.0, 3300.0, 11300.0, 13800.0, 12200.0, 8100.0, 4400.0, 2500.0, 3000.0, 3700.0, 300.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1300.0, 5800.0, 11300.0, 23400.0, 44600.0, 63500.0, 57800.0, 63900.0, 38600.0, 32400.0, 19400.0, 24300.0, 9700.0, 600.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 1100.0, 5000.0, 14500.0, 42800.0, 57800.0, 72500.0, 76200.0, 61500.0, 48100.0, 51700.0, 20400.0, 11100.0, 8400.0, 2000.0, 1100.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 700.0, 9100.0, 13200.0, 20300.0, 28900.0, 26800.0, 40600.0, 52300.0, 36200.0, 29900.0, 41400.0, 30500.0, 19300.0, 8300.0, 700.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2600.0, 4500.0, 6900.0, 6600.0, 17000.0, 16300.0, 32100.0, 22500.0, 14000.0, 9100.0, 5000.0, 4500.0, 400.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 400.0, 2800.0, 5100.0, 11700.0, 21900.0, 14800.0, 12900.0, 24100.0, 18200.0, 13200.0, 15500.0, 10600.0, 4700.0, 2100.0, 700.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 500.0, 7700.0, 18600.0, 14500.0, 22800.0, 34500.0, 23900.0, 46400.0, 25200.0, 20700.0, 19600.0, 28200.0, 14100.0, 6500.0, 1800.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1500.0, 4300.0, 6200.0, 17500.0, 11300.0, 9600.0, 10600.0, 11800.0, 7700.0, 3700.0, 3700.0, 3500.0, 2100.0, 900.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 400.0, 4100.0, 13300.0, 29500.0, 54500.0, 48100.0, 59800.0, 68100.0, 63900.0, 50800.0, 55000.0, 34800.0, 11000.0, 1600.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 400.0, 4600.0, 20100.0, 37100.0, 50200.0, 62400.0, 49300.0, 52100.0, 47400.0, 57700.0, 45600.0, 22000.0, 12600.0, 6500.0, 800.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 400.0, 4700.0, 7700.0, 29200.0, 28200.0, 29100.0, 42000.0, 41400.0, 26800.0, 13400.0, 6500.0, 3400.0, 900.0, 200.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 900.0, 4900.0, 9800.0, 13500.0, 25300.0, 29700.0, 41500.0, 24900.0, 8400.0, 17300.0, 14100.0, 2200.0, 500.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 300.0, 5600.0, 12200.0, 22100.0, 28200.0, 32800.0, 48700.0, 38200.0, 42600.0, 30200.0, 28600.0, 21100.0, 16000.0, 8000.0, 400.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 100.0, 700.0, 1900.0, 4000.0, 5500.0, 2700.0, 4300.0, 4600.0, 4100.0, 3800.0, 1800.0, 1000.0, 1000.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 400.0, 1200.0, 4300.0, 4300.0, 6000.0, 3700.0, 2000.0, 5300.0, 2800.0, 1200.0, 400.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 400.0, 3200.0, 6900.0, 12100.0, 31800.0, 31700.0, 44200.0, 34900.0, 24800.0, 32300.0, 21000.0, 16600.0, 7000.0, 3300.0, 200.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1400.0, 5100.0, 12300.0, 13700.0, 13200.0, 9700.0, 15500.0, 12700.0, 8200.0, 11100.0, 8300.0, 5200.0, 1200.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5200.0, 14100.0, 17500.0, 8400.0, 9800.0, 26200.0, 48100.0, 63700.0, 46200.0, 38200.0, 26100.0, 14000.0, 7200.0, 700.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1500.0, 8100.0, 19000.0, 22500.0, 22100.0, 53000.0, 41900.0, 33200.0, 50300.0, 43700.0, 35100.0, 20800.0, 6100.0, 800.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2000.0, 8200.0, 8100.0, 14400.0, 35800.0, 27800.0, 25000.0, 23000.0, 9000.0, 12300.0, 22200.0, 9800.0, 2200.0, 100.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 700.0, 2000.0, 4800.0, 5800.0, 7500.0, 6200.0, 8800.0, 9800.0, 7300.0, 6000.0, 4100.0, 1300.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 100.0, 600.0, 6400.0, 9800.0, 5400.0, 22000.0, 29800.0, 34600.0, 34400.0, 27500.0, 16100.0, 6300.0, 3500.0, 800.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 400.0, 8400.0, 7500.0, 8500.0, 22200.0, 28400.0, 30500.0, 34800.0, 40100.0, 52300.0, 32100.0, 26000.0, 9800.0, 2100.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1500.0, 5200.0, 6200.0, 8400.0, 10800.0, 10700.0, 10700.0, 12900.0, 14000.0, 10700.0, 14700.0, 7300.0, 3900.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 700.0, 500.0, 4700.0, 3200.0, 2400.0, 2100.0, 2100.0, 3100.0, 2000.0, 1400.0, 2100.0, 400.0, 400.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1200.0, 2100.0, 2600.0, 6900.0, 8100.0, 11100.0, 6500.0, 3000.0, 11400.0, 16600.0, 8100.0, 4700.0, 5000.0, 700.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 100.0, 2300.0, 4300.0, 15000.0, 15100.0, 27600.0, 32000.0, 56800.0, 19500.0, 32900.0, 25600.0, 9600.0, 20500.0, 2500.0, 100.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4200.0, 11100.0, 29600.0, 40300.0, 50900.0, 28700.0, 50700.0, 27300.0, 32500.0, 37200.0, 22900.0, 17800.0, 4000.0, 200.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1400.0, 4600.0, 6900.0, 11400.0, 15900.0, 23200.0, 19200.0, 15300.0, 5200.0, 5200.0, 1100.0, 1200.0, 200.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1700.0, 7700.0, 12500.0, 14000.0, 18700.0, 14500.0, 14300.0, 17900.0, 10400.0, 5900.0, 11400.0, 4200.0, 700.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 100.0, 2500.0, 6000.0, 19200.0, 20500.0, 16900.0, 15900.0, 18400.0, 9800.0, 8100.0, 7400.0, 8500.0, 3600.0, 6900.0, 100.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1700.0, 6000.0, 6400.0, 22200.0, 41100.0, 27600.0, 25900.0, 29600.0, 18500.0, 6900.0, 2500.0, 4000.0, 3900.0, 100.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3600.0, 11800.0, 29000.0, 39600.0, 58800.0, 61400.0, 44100.0, 45200.0, 46000.0, 28000.0, 29900.0, 8200.0, 2700.0, 400.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2600.0, 10400.0, 26400.0, 42400.0, 54500.0, 57900.0, 49900.0, 35700.0, 20600.0, 17300.0, 10700.0, 8500.0, 3900.0, 300.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1400.0, 11900.0, 21100.0, 22900.0, 46500.0, 35400.0, 44000.0, 43200.0, 31300.0, 20700.0, 13300.0, 8500.0, 4100.0, 300.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2100.0, 12700.0, 8700.0, 19600.0, 17900.0, 17800.0, 33400.0, 34900.0, 28400.0, 13700.0, 7700.0, 10900.0, 3000.0, 100.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3200.0, 10600.0, 19700.0, 21300.0, 34300.0, 35200.0, 36900.0, 38900.0, 40000.0, 15700.0, 8400.0, 6900.0, 2800.0, 100.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1500.0, 7600.0, 13000.0, 12000.0, 6000.0, 11000.0, 13900.0, 15300.0, 10200.0, 21100.0, 10200.0, 6100.0, 1300.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 800.0, 900.0, 1000.0, 2000.0, 2400.0, 4400.0, 3200.0, 2000.0, 3300.0, 3000.0, 5700.0, 1000.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 500.0, 2200.0, 1900.0, 3400.0, 4600.0, 5200.0, 3700.0, 3900.0, 400.0, 100.0, 100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 900.0, 6600.0, 100.0, 800.0, 1800.0, 10500.0, 4200.0, 7000.0, 2400.0, 2700.0, 1900.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3100.0, 10400.0, 23800.0, 30300.0, 67400.0, 36400.0, 34800.0, 56300.0, 31600.0, 25100.0, 14500.0, 7700.0, 1300.0, 650.0, 0.0, 0.0, 0.0, 0.0]], 'y_pred': [[14.054636001586914, 35.41887283325195, 58.45894241333008, 97.08182525634766, 148.2602996826172, 210.4718017578125, 347.2406921386719, 348.25665283203125, 348.3245849609375, 348.33380126953125, 348.33502197265625, 348.335205078125, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031], [14.054373741149902, 35.4373893737793, 58.48463439941406, 97.08686065673828, 148.24655151367188, 210.46224975585938, 347.2401123046875, 348.2565002441406, 348.3245544433594, 348.33380126953125, 348.33502197265625, 348.335205078125, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031], [14.054790496826172, 35.45234298706055, 58.50712203979492, 97.1247329711914, 148.2874755859375, 210.5032196044922, 347.2427062988281, 348.2566223144531, 348.3245544433594, 348.33380126953125, 348.33502197265625, 348.335205078125, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031], [14.055440902709961, 35.42398452758789, 58.46756362915039, 97.10347747802734, 148.289794921875, 210.50814819335938, 347.2428894042969, 348.2567443847656, 348.3245849609375, 348.33380126953125, 348.33502197265625, 348.335205078125, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031], [14.059416770935059, 35.426021575927734, 58.461856842041016, 97.0636215209961, 148.22853088378906, 210.43568420410156, 347.23858642578125, 348.2565612792969, 348.3245849609375, 348.33380126953125, 348.33502197265625, 348.335205078125, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031], [14.059545516967773, 35.42799377441406, 58.45030212402344, 96.94717407226562, 148.03701782226562, 210.2033233642578, 347.224365234375, 348.2559509277344, 348.32452392578125, 348.3337707519531, 348.33502197265625, 348.335205078125, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031], [14.060563087463379, 35.439510345458984, 58.45343780517578, 96.85448455810547, 147.87461853027344, 210.0096435546875, 347.21234130859375, 348.25543212890625, 348.3244323730469, 348.3337707519531, 348.33502197265625, 348.335205078125, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031], [14.05963134765625, 35.44333267211914, 58.462162017822266, 96.87885284423828, 147.9076690673828, 210.04884338378906, 347.21484375, 348.2555236816406, 348.3244323730469, 348.3337707519531, 348.33502197265625, 348.335205078125, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031], [14.058659553527832, 35.44622039794922, 58.4659538269043, 96.87350463867188, 147.89401245117188, 210.0312957763672, 347.2137451171875, 348.2554626464844, 348.3244323730469, 348.3337707519531, 348.33502197265625, 348.335205078125, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031], [14.05820083618164, 35.43930435180664, 58.46769714355469, 96.95860290527344, 148.0409698486328, 210.209228515625, 347.2247619628906, 348.2559509277344, 348.3244934082031, 348.3337707519531, 348.33502197265625, 348.335205078125, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031], [14.05690860748291, 35.4302978515625, 58.46525192260742, 97.02694702148438, 148.1612091064453, 210.35369873046875, 347.23358154296875, 348.2563171386719, 348.32452392578125, 348.3337707519531, 348.33502197265625, 348.335205078125, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031], [14.058953285217285, 35.44247055053711, 58.47092056274414, 96.9573974609375, 148.03494262695312, 210.20062255859375, 347.2242126464844, 348.25592041015625, 348.32452392578125, 348.3337707519531, 348.33502197265625, 348.335205078125, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031], [14.057291030883789, 35.442596435546875, 58.47713851928711, 96.99564361572266, 148.0949249267578, 210.2729949951172, 347.2287292480469, 348.2560729980469, 348.32452392578125, 348.3337707519531, 348.33502197265625, 348.335205078125, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031], [14.057418823242188, 35.42698669433594, 58.45960235595703, 97.02075958251953, 148.1555633544922, 210.34625244140625, 347.2331237792969, 348.2563171386719, 348.32452392578125, 348.3337707519531, 348.33502197265625, 348.335205078125, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031], [14.05958366394043, 35.43101119995117, 58.457698822021484, 96.97498321533203, 148.0789794921875, 210.25503540039062, 347.2275695800781, 348.2560729980469, 348.32452392578125, 348.3337707519531, 348.33502197265625, 348.335205078125, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031], [14.057271003723145, 35.43828201293945, 58.46922302246094, 96.976318359375, 148.06919860839844, 210.2419891357422, 347.2267761230469, 348.25604248046875, 348.32452392578125, 348.3337707519531, 348.33502197265625, 348.335205078125, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031], [14.05682373046875, 35.4359245300293, 58.46919631958008, 96.99694061279297, 148.10597229003906, 210.28765869140625, 347.2295837402344, 348.25616455078125, 348.32452392578125, 348.3337707519531, 348.33502197265625, 348.335205078125, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031], [14.058942794799805, 35.43845748901367, 58.46794128417969, 96.97618103027344, 148.07186889648438, 210.2469482421875, 347.2270812988281, 348.25604248046875, 348.32452392578125, 348.3337707519531, 348.33502197265625, 348.335205078125, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031], [14.060125350952148, 35.439823150634766, 58.45685958862305, 96.87771606445312, 147.91014099121094, 210.05111694335938, 347.2149353027344, 348.2555236816406, 348.3244323730469, 348.3337707519531, 348.33502197265625, 348.335205078125, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031], [14.05967903137207, 35.431400299072266, 58.4492301940918, 96.90169525146484, 147.961669921875, 210.11526489257812, 347.2188720703125, 348.2557067871094, 348.3244934082031, 348.3337707519531, 348.33502197265625, 348.335205078125, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031], [14.059971809387207, 35.429931640625, 58.44590377807617, 96.89335632324219, 147.94979858398438, 210.10011291503906, 347.2179260253906, 348.25567626953125, 348.324462890625, 348.3337707519531, 348.33502197265625, 348.335205078125, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031], [14.059359550476074, 35.43357467651367, 58.454036712646484, 96.91488647460938, 147.9782257080078, 210.13377380371094, 347.22003173828125, 348.2557678222656, 348.3244934082031, 348.3337707519531, 348.33502197265625, 348.335205078125, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031], [14.058303833007812, 35.425811767578125, 58.45150375366211, 96.97149658203125, 148.0798797607422, 210.2569580078125, 347.2276611328125, 348.256103515625, 348.32452392578125, 348.3337707519531, 348.33502197265625, 348.335205078125, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031], [14.058485984802246, 35.417755126953125, 58.4476432800293, 97.02859497070312, 148.181884765625, 210.37937927246094, 347.2350769042969, 348.2564392089844, 348.3245544433594, 348.33380126953125, 348.33502197265625, 348.335205078125, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031], [14.059976577758789, 35.4289436340332, 58.451133728027344, 96.94792938232422, 148.03884887695312, 210.20639038085938, 347.2245788574219, 348.2559814453125, 348.32452392578125, 348.3337707519531, 348.33502197265625, 348.335205078125, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031], [14.058526992797852, 35.438629150390625, 58.46269226074219, 96.92396545410156, 147.98468017578125, 210.1413116455078, 347.2205505371094, 348.2557678222656, 348.324462890625, 348.3337707519531, 348.33502197265625, 348.335205078125, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031], [14.057001113891602, 35.451297760009766, 58.48143768310547, 96.9337158203125, 147.98399353027344, 210.14022827148438, 347.2205810546875, 348.2557373046875, 348.3244934082031, 348.3337707519531, 348.33502197265625, 348.335205078125, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031], [14.058950424194336, 35.44748306274414, 58.47120666503906, 96.90705871582031, 147.9471893310547, 210.09539794921875, 347.2177429199219, 348.255615234375, 348.3244323730469, 348.3337707519531, 348.33502197265625, 348.335205078125, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031], [14.060688018798828, 35.44167709350586, 58.460933685302734, 96.89437866210938, 147.9365692138672, 210.08413696289062, 347.21697998046875, 348.2555847167969, 348.324462890625, 348.3337707519531, 348.33502197265625, 348.335205078125, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031], [14.061333656311035, 35.44192886352539, 58.45688247680664, 96.86182403564453, 147.884765625, 210.02296447753906, 347.21319580078125, 348.2554626464844, 348.32440185546875, 348.3337707519531, 348.33502197265625, 348.335205078125, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031], [14.060386657714844, 35.4300422668457, 58.443546295166016, 96.87578582763672, 147.92190551757812, 210.06710815429688, 347.2159118652344, 348.255615234375, 348.3244323730469, 348.3337707519531, 348.33502197265625, 348.335205078125, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031], [14.061505317687988, 35.4279670715332, 58.43826675415039, 96.86102294921875, 147.900634765625, 210.04112243652344, 347.2142333984375, 348.2555236816406, 348.3244323730469, 348.3337707519531, 348.33502197265625, 348.335205078125, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031], [14.062640190124512, 35.42813491821289, 58.43143081665039, 96.81227111816406, 147.8236083984375, 209.94900512695312, 347.2084655761719, 348.2552795410156, 348.32440185546875, 348.3337707519531, 348.33502197265625, 348.335205078125, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031], [14.061347007751465, 35.42317199707031, 58.4306755065918, 96.84880828857422, 147.88739013671875, 210.0253448486328, 347.2132873535156, 348.2555236816406, 348.3244323730469, 348.3337707519531, 348.33502197265625, 348.335205078125, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031], [14.059812545776367, 35.42144775390625, 58.437774658203125, 96.91533660888672, 147.99534606933594, 210.15478515625, 347.2213134765625, 348.255859375, 348.3244934082031, 348.3337707519531, 348.33502197265625, 348.335205078125, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031], [14.059732437133789, 35.42546081542969, 58.444580078125, 96.92882537841797, 148.0125274658203, 210.17559814453125, 347.2226257324219, 348.2558898925781, 348.3244934082031, 348.3337707519531, 348.33502197265625, 348.335205078125, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031], [14.059946060180664, 35.425567626953125, 58.441139221191406, 96.90109252929688, 147.96705627441406, 210.11990356445312, 347.21917724609375, 348.2557373046875, 348.324462890625, 348.3337707519531, 348.33502197265625, 348.335205078125, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031], [14.060949325561523, 35.425479888916016, 58.43870544433594, 96.888427734375, 147.9479217529297, 210.09779357910156, 347.2177734375, 348.25567626953125, 348.324462890625, 348.3337707519531, 348.33502197265625, 348.335205078125, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031], [14.061054229736328, 35.42616271972656, 58.43920135498047, 96.8853988647461, 147.94253540039062, 210.09144592285156, 347.2173767089844, 348.25567626953125, 348.324462890625, 348.3337707519531, 348.33502197265625, 348.335205078125, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031], [14.059581756591797, 35.429203033447266, 58.44824981689453, 96.91637420654297, 147.98716735839844, 210.14483642578125, 347.2207336425781, 348.25579833984375, 348.3244934082031, 348.3337707519531, 348.33502197265625, 348.335205078125, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031], [14.059367179870605, 35.43516540527344, 58.45512771606445, 96.90652465820312, 147.96261596679688, 210.11465454101562, 347.2189025878906, 348.2557067871094, 348.324462890625, 348.3337707519531, 348.33502197265625, 348.335205078125, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031], [14.057918548583984, 35.4354362487793, 58.464786529541016, 96.97435760498047, 148.07061767578125, 210.24453735351562, 347.2268981933594, 348.2560729980469, 348.32452392578125, 348.3337707519531, 348.33502197265625, 348.335205078125, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031, 348.3352355957031]], 'exp_name': 'solar power prediction using weather features', 'plant': 126, 'spot': 174, 'start_date': '20190820', 'end_date': '20200809', 'batch_size': 64, 'x_frames': 3, 'y_frames': 1, 'hid_dim': 256, 'optim': 'RMSprop', 'activation': 'relu', 'lss': 'MSE', 'lr': 0.001, 'epochs': 256, 'early_stop': 30, 'evaluation': 'NRMSE', 'features': \"[<FeatureType.SUNSHINE: '일조(hr)'>, <FeatureType.HUMIDITY: '습도(%)'>, <FeatureType.WIND_SPEED: '풍속(m/s)'>, <FeatureType.VISIBILITY: '시정(10m)'>, <FeatureType.GROUND_TEMPERATURE: '지면온도(°C)'>, <FeatureType.WIND_DIRECTION: '풍향(16방위)'>, <FeatureType.STEAM_PRESSURE: '현지기압(hPa)'>]\"}\n",
      "\n",
      "Namespace(activation='relu', batch_size=64, early_stop=30, end_date='20200809', epochs=256, evaluation='NRMSE', exp_name='solar power prediction using weather features', features=\"[<FeatureType.SUNSHINE: '일조(hr)'>, <FeatureType.HUMIDITY: '습도(%)'>, <FeatureType.WIND_SPEED: '풍속(m/s)'>, <FeatureType.VISIBILITY: '시정(10m)'>, <FeatureType.GROUND_TEMPERATURE: '지면온도(°C)'>, <FeatureType.WIND_DIRECTION: '풍향(16방위)'>, <FeatureType.STEAM_PRESSURE: '현지기압(hPa)'>, <FeatureType.TEMPERATURE: '기온(°C)'>]\", hid_dim=256, lr=0.001, lss='MSE', optim='RMSprop', plant=126, spot=174, start_date='20190820', x_frames=3, y_frames=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/256\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 1316863104.0000 - accuracy: 0.1316 - val_loss: 855009792.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1316392576.0000 - accuracy: 0.0000e+00 - val_loss: 854877120.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1316294912.0000 - accuracy: 0.0000e+00 - val_loss: 854816448.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1316238592.0000 - accuracy: 0.0000e+00 - val_loss: 854767808.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1316191104.0000 - accuracy: 0.0000e+00 - val_loss: 854719232.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1316143616.0000 - accuracy: 0.0000e+00 - val_loss: 854674304.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1316099584.0000 - accuracy: 0.0000e+00 - val_loss: 854633024.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1316058240.0000 - accuracy: 0.0000e+00 - val_loss: 854591168.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1316015872.0000 - accuracy: 0.0000e+00 - val_loss: 854546560.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315971968.0000 - accuracy: 0.0000e+00 - val_loss: 854502464.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315928320.0000 - accuracy: 0.0000e+00 - val_loss: 854458496.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315884800.0000 - accuracy: 0.0000e+00 - val_loss: 854414592.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315841024.0000 - accuracy: 0.0000e+00 - val_loss: 854370112.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315797248.0000 - accuracy: 0.0000e+00 - val_loss: 854326208.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1315754112.0000 - accuracy: 0.0000e+00 - val_loss: 854286464.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315714048.0000 - accuracy: 0.0000e+00 - val_loss: 854245504.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315672832.0000 - accuracy: 0.0000e+00 - val_loss: 854199424.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315627520.0000 - accuracy: 0.0000e+00 - val_loss: 854160064.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315587840.0000 - accuracy: 0.0000e+00 - val_loss: 854119168.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315546880.0000 - accuracy: 0.0000e+00 - val_loss: 854076096.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315504128.0000 - accuracy: 0.0000e+00 - val_loss: 854032704.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315462144.0000 - accuracy: 0.0000e+00 - val_loss: 854004864.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315456640.0000 - accuracy: 0.0000e+00 - val_loss: 853972992.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315385984.0000 - accuracy: 0.0000e+00 - val_loss: 853904320.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1315334016.0000 - accuracy: 0.0000e+00 - val_loss: 853863168.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315292288.0000 - accuracy: 0.0000e+00 - val_loss: 853816640.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1315245952.0000 - accuracy: 0.0000e+00 - val_loss: 853768384.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1315199232.0000 - accuracy: 0.0000e+00 - val_loss: 853725056.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1315155968.0000 - accuracy: 0.0000e+00 - val_loss: 853685376.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1315116032.0000 - accuracy: 0.0000e+00 - val_loss: 853642176.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1315072256.0000 - accuracy: 0.0000e+00 - val_loss: 853596928.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1315027328.0000 - accuracy: 0.0000e+00 - val_loss: 853551808.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1314982528.0000 - accuracy: 0.0000e+00 - val_loss: 853507968.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/256\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1314939392.0000 - accuracy: 0.0000e+00 - val_loss: 853464512.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1314895872.0000 - accuracy: 0.0000e+00 - val_loss: 853422464.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1314853632.0000 - accuracy: 0.0000e+00 - val_loss: 853378176.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1314809600.0000 - accuracy: 0.0000e+00 - val_loss: 853331008.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1314763264.0000 - accuracy: 0.0000e+00 - val_loss: 853288832.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314721152.0000 - accuracy: 0.0000e+00 - val_loss: 853242816.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1314675840.0000 - accuracy: 0.0000e+00 - val_loss: 853198336.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1314631680.0000 - accuracy: 0.0000e+00 - val_loss: 853156160.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314588928.0000 - accuracy: 0.0000e+00 - val_loss: 853107840.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314542208.0000 - accuracy: 0.0000e+00 - val_loss: 853068480.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/256\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1314502400.0000 - accuracy: 0.0000e+00 - val_loss: 853024000.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314457856.0000 - accuracy: 0.0000e+00 - val_loss: 852975808.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314411520.0000 - accuracy: 0.0000e+00 - val_loss: 852935744.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1314371072.0000 - accuracy: 0.0000e+00 - val_loss: 852893376.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1314328704.0000 - accuracy: 0.0000e+00 - val_loss: 852849216.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314284800.0000 - accuracy: 0.0000e+00 - val_loss: 852809600.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 12ms/step - loss: 1314244864.0000 - accuracy: 0.0000e+00 - val_loss: 852764480.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314200320.0000 - accuracy: 0.0000e+00 - val_loss: 852722560.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314158464.0000 - accuracy: 0.0000e+00 - val_loss: 852679360.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1314114944.0000 - accuracy: 0.0000e+00 - val_loss: 852631936.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1314068864.0000 - accuracy: 0.0000e+00 - val_loss: 852590016.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1314027008.0000 - accuracy: 0.0000e+00 - val_loss: 852546432.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1313983104.0000 - accuracy: 0.0000e+00 - val_loss: 852500672.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313937920.0000 - accuracy: 0.0000e+00 - val_loss: 852457472.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313895168.0000 - accuracy: 0.0000e+00 - val_loss: 852414976.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313852544.0000 - accuracy: 0.0000e+00 - val_loss: 852369536.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/256\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1313807488.0000 - accuracy: 0.0000e+00 - val_loss: 852325440.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1313763840.0000 - accuracy: 0.0000e+00 - val_loss: 852283392.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1313721856.0000 - accuracy: 0.0000e+00 - val_loss: 852242624.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/256\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1313680768.0000 - accuracy: 0.0000e+00 - val_loss: 852193600.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313633536.0000 - accuracy: 0.0000e+00 - val_loss: 852153664.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313594496.0000 - accuracy: 0.0000e+00 - val_loss: 852112512.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313551872.0000 - accuracy: 0.0000e+00 - val_loss: 852070592.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313509888.0000 - accuracy: 0.0000e+00 - val_loss: 852025024.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313464960.0000 - accuracy: 0.0000e+00 - val_loss: 851983488.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313423104.0000 - accuracy: 0.0000e+00 - val_loss: 851936384.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313376768.0000 - accuracy: 0.0000e+00 - val_loss: 851893504.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313334016.0000 - accuracy: 0.0000e+00 - val_loss: 851852352.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1313292416.0000 - accuracy: 0.0000e+00 - val_loss: 851806912.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313247744.0000 - accuracy: 0.0000e+00 - val_loss: 851761280.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313202304.0000 - accuracy: 0.0000e+00 - val_loss: 851714816.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313156992.0000 - accuracy: 0.0000e+00 - val_loss: 851676416.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313117824.0000 - accuracy: 0.0000e+00 - val_loss: 851631808.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1313073664.0000 - accuracy: 0.0000e+00 - val_loss: 851587264.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313029504.0000 - accuracy: 0.0000e+00 - val_loss: 851544384.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312986752.0000 - accuracy: 0.0000e+00 - val_loss: 851498112.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312941312.0000 - accuracy: 0.0000e+00 - val_loss: 851456512.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312899712.0000 - accuracy: 0.0000e+00 - val_loss: 851413184.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1312856960.0000 - accuracy: 0.0000e+00 - val_loss: 851369792.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312813440.0000 - accuracy: 0.0000e+00 - val_loss: 851326656.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312770688.0000 - accuracy: 0.0000e+00 - val_loss: 851280448.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312725120.0000 - accuracy: 0.0000e+00 - val_loss: 851239872.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312684288.0000 - accuracy: 0.0000e+00 - val_loss: 851193728.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312638592.0000 - accuracy: 0.0000e+00 - val_loss: 851150464.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1312595712.0000 - accuracy: 0.0000e+00 - val_loss: 851106560.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1312552192.0000 - accuracy: 0.0000e+00 - val_loss: 851061120.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312507264.0000 - accuracy: 0.0000e+00 - val_loss: 851017920.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/256\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1312464384.0000 - accuracy: 0.0000e+00 - val_loss: 850975616.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1312422144.0000 - accuracy: 0.0000e+00 - val_loss: 850932992.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1312379904.0000 - accuracy: 0.0071 - val_loss: 850889408.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312335872.0000 - accuracy: 0.0000e+00 - val_loss: 850843264.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312290304.0000 - accuracy: 0.0000e+00 - val_loss: 850797632.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312245760.0000 - accuracy: 9.4340e-04 - val_loss: 850756096.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312203648.0000 - accuracy: 0.0000e+00 - val_loss: 850709760.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312158720.0000 - accuracy: 0.0019 - val_loss: 850667136.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 11ms/step - loss: 1312115712.0000 - accuracy: 0.0000e+00 - val_loss: 850624384.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312073216.0000 - accuracy: 0.0038 - val_loss: 850582080.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 101/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1312030976.0000 - accuracy: 0.0000e+00 - val_loss: 850536320.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 102/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311985664.0000 - accuracy: 4.7170e-04 - val_loss: 850494336.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 103/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311943808.0000 - accuracy: 4.7170e-04 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 104/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313146496.0000 - accuracy: 0.1083 - val_loss: 850414720.0000 - val_accuracy: 0.0188\n",
      "Epoch 105/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1311864320.0000 - accuracy: 0.0041 - val_loss: 850369664.0000 - val_accuracy: 0.0208\n",
      "Epoch 106/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311819392.0000 - accuracy: 0.0052 - val_loss: 850326080.0000 - val_accuracy: 0.0208\n",
      "Epoch 107/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311775872.0000 - accuracy: 0.0044 - val_loss: 850277312.0000 - val_accuracy: 0.0208\n",
      "Epoch 108/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311728768.0000 - accuracy: 0.0046 - val_loss: 850235584.0000 - val_accuracy: 0.0208\n",
      "Epoch 109/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1311686784.0000 - accuracy: 0.0046 - val_loss: 850192256.0000 - val_accuracy: 0.0218\n",
      "Epoch 110/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1311644032.0000 - accuracy: 0.0055 - val_loss: 850151040.0000 - val_accuracy: 0.0228\n",
      "Epoch 111/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311602432.0000 - accuracy: 0.0049 - val_loss: 850108736.0000 - val_accuracy: 0.0258\n",
      "Epoch 112/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311559936.0000 - accuracy: 0.0060 - val_loss: 850061504.0000 - val_accuracy: 0.0258\n",
      "Epoch 113/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311513728.0000 - accuracy: 0.0060 - val_loss: 850018624.0000 - val_accuracy: 0.0268\n",
      "Epoch 114/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311471232.0000 - accuracy: 0.0049 - val_loss: 849977152.0000 - val_accuracy: 0.0288\n",
      "Epoch 115/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311429760.0000 - accuracy: 0.0075 - val_loss: 849933184.0000 - val_accuracy: 0.0278\n",
      "Epoch 116/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311385984.0000 - accuracy: 0.0052 - val_loss: 849888512.0000 - val_accuracy: 0.0327\n",
      "Epoch 117/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311341824.0000 - accuracy: 0.0074 - val_loss: 849846848.0000 - val_accuracy: 0.0317\n",
      "Epoch 118/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311300352.0000 - accuracy: 0.0075 - val_loss: 849802176.0000 - val_accuracy: 0.0317\n",
      "Epoch 119/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311255680.0000 - accuracy: 0.0047 - val_loss: 849756032.0000 - val_accuracy: 0.0347\n",
      "Epoch 120/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1311210368.0000 - accuracy: 0.0072 - val_loss: 849713728.0000 - val_accuracy: 0.0367\n",
      "Epoch 121/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311168256.0000 - accuracy: 0.0110 - val_loss: 849669824.0000 - val_accuracy: 0.0308\n",
      "Epoch 122/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311124864.0000 - accuracy: 0.0075 - val_loss: 849626816.0000 - val_accuracy: 0.0327\n",
      "Epoch 123/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311081600.0000 - accuracy: 0.0052 - val_loss: 849581120.0000 - val_accuracy: 0.0377\n",
      "Epoch 124/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311036544.0000 - accuracy: 0.0097 - val_loss: 849536448.0000 - val_accuracy: 0.0347\n",
      "Epoch 125/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1310992256.0000 - accuracy: 0.0097 - val_loss: 849495296.0000 - val_accuracy: 0.0337\n",
      "Epoch 126/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310950912.0000 - accuracy: 0.0080 - val_loss: 849448960.0000 - val_accuracy: 0.0337\n",
      "Epoch 127/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1310905216.0000 - accuracy: 0.0113 - val_loss: 849404480.0000 - val_accuracy: 0.0208\n",
      "Epoch 128/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310861184.0000 - accuracy: 0.0039 - val_loss: 849363520.0000 - val_accuracy: 0.0407\n",
      "Epoch 129/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1310819840.0000 - accuracy: 0.0159 - val_loss: 849316608.0000 - val_accuracy: 0.0139\n",
      "Epoch 130/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310774144.0000 - accuracy: 0.0047 - val_loss: 849274368.0000 - val_accuracy: 0.0278\n",
      "Epoch 131/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310732032.0000 - accuracy: 0.0068 - val_loss: 849232576.0000 - val_accuracy: 0.0417\n",
      "Epoch 132/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310689536.0000 - accuracy: 0.0123 - val_loss: 849190912.0000 - val_accuracy: 0.0208\n",
      "Epoch 133/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310648192.0000 - accuracy: 0.0090 - val_loss: 849146816.0000 - val_accuracy: 0.0278\n",
      "Epoch 134/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310604928.0000 - accuracy: 0.0083 - val_loss: 849103168.0000 - val_accuracy: 0.0407\n",
      "Epoch 135/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310561152.0000 - accuracy: 0.0102 - val_loss: 849084608.0000 - val_accuracy: 0.0913\n",
      "Epoch 136/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310518016.0000 - accuracy: 0.0088 - val_loss: 849012352.0000 - val_accuracy: 0.0278\n",
      "Epoch 137/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310471680.0000 - accuracy: 0.0085 - val_loss: 848970112.0000 - val_accuracy: 0.0367\n",
      "Epoch 138/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310429440.0000 - accuracy: 0.0080 - val_loss: 848925056.0000 - val_accuracy: 0.0407\n",
      "Epoch 139/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1310384768.0000 - accuracy: 0.0110 - val_loss: 848883840.0000 - val_accuracy: 0.0427\n",
      "Epoch 140/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310342784.0000 - accuracy: 0.0115 - val_loss: 848846080.0000 - val_accuracy: 0.0575\n",
      "Epoch 141/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310300160.0000 - accuracy: 0.0165 - val_loss: 848801472.0000 - val_accuracy: 0.0724\n",
      "Epoch 142/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310255488.0000 - accuracy: 0.0303 - val_loss: 848754880.0000 - val_accuracy: 0.0407\n",
      "Epoch 143/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1310214912.0000 - accuracy: 0.0175 - val_loss: 848736064.0000 - val_accuracy: 0.0992\n",
      "Epoch 144/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310173312.0000 - accuracy: 0.0230 - val_loss: 848668992.0000 - val_accuracy: 0.0417\n",
      "Epoch 145/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310129152.0000 - accuracy: 0.0219 - val_loss: 848626944.0000 - val_accuracy: 0.0407\n",
      "Epoch 146/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1310086912.0000 - accuracy: 0.0145 - val_loss: 848579264.0000 - val_accuracy: 0.0427\n",
      "Epoch 147/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1310040448.0000 - accuracy: 0.0414 - val_loss: 848534016.0000 - val_accuracy: 0.0506\n",
      "Epoch 148/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1309995648.0000 - accuracy: 0.0431 - val_loss: 848491072.0000 - val_accuracy: 0.0466\n",
      "Epoch 149/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1309952128.0000 - accuracy: 0.0398 - val_loss: 848445568.0000 - val_accuracy: 0.0685\n",
      "Epoch 150/256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 11ms/step - loss: 1309906688.0000 - accuracy: 0.0491 - val_loss: 848404480.0000 - val_accuracy: 0.0258\n",
      "Epoch 151/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309865856.0000 - accuracy: 0.0064 - val_loss: 848360768.0000 - val_accuracy: 0.0337\n",
      "Epoch 152/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309822464.0000 - accuracy: 0.0096 - val_loss: 848316096.0000 - val_accuracy: 0.0397\n",
      "Epoch 153/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309778048.0000 - accuracy: 0.0203 - val_loss: 848269312.0000 - val_accuracy: 0.0407\n",
      "Epoch 154/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309731712.0000 - accuracy: 0.0453 - val_loss: 848228928.0000 - val_accuracy: 0.0595\n",
      "Epoch 155/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309691392.0000 - accuracy: 0.0448 - val_loss: 848189440.0000 - val_accuracy: 0.0754\n",
      "Epoch 156/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309651968.0000 - accuracy: 0.0447 - val_loss: 848152896.0000 - val_accuracy: 0.0913\n",
      "Epoch 157/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309609344.0000 - accuracy: 0.0492 - val_loss: 848104512.0000 - val_accuracy: 0.0893\n",
      "Epoch 158/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1309563392.0000 - accuracy: 0.0742 - val_loss: 848056704.0000 - val_accuracy: 0.0685\n",
      "Epoch 159/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309521280.0000 - accuracy: 0.0398 - val_loss: 848015360.0000 - val_accuracy: 0.0794\n",
      "Epoch 160/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309478656.0000 - accuracy: 0.0520 - val_loss: 847970432.0000 - val_accuracy: 0.0714\n",
      "Epoch 161/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309433216.0000 - accuracy: 0.0590 - val_loss: 847938688.0000 - val_accuracy: 0.0982\n",
      "Epoch 162/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1309395712.0000 - accuracy: 0.0528 - val_loss: 847884288.0000 - val_accuracy: 0.0764\n",
      "Epoch 163/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1309349248.0000 - accuracy: 0.0379 - val_loss: 847841984.0000 - val_accuracy: 0.0794\n",
      "Epoch 164/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1309305472.0000 - accuracy: 0.0440 - val_loss: 847800832.0000 - val_accuracy: 0.1002\n",
      "Epoch 165/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1309259392.0000 - accuracy: 0.0607 - val_loss: 847752896.0000 - val_accuracy: 0.0764\n",
      "Epoch 166/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309216640.0000 - accuracy: 0.0692 - val_loss: 847707584.0000 - val_accuracy: 0.0903\n",
      "Epoch 167/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1309170048.0000 - accuracy: 0.0742 - val_loss: 847669568.0000 - val_accuracy: 0.0982\n",
      "Epoch 168/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309132928.0000 - accuracy: 0.0602 - val_loss: 847629760.0000 - val_accuracy: 0.1002\n",
      "Epoch 169/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309092224.0000 - accuracy: 0.0741 - val_loss: 847587456.0000 - val_accuracy: 0.0992\n",
      "Epoch 170/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309048320.0000 - accuracy: 0.0835 - val_loss: 847537664.0000 - val_accuracy: 0.0853\n",
      "Epoch 171/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1309001600.0000 - accuracy: 0.0822 - val_loss: 847492800.0000 - val_accuracy: 0.0774\n",
      "Epoch 172/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308958336.0000 - accuracy: 0.0772 - val_loss: 847458880.0000 - val_accuracy: 0.1121\n",
      "Epoch 173/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308917504.0000 - accuracy: 0.0764 - val_loss: 847408384.0000 - val_accuracy: 0.0992\n",
      "Epoch 174/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308872320.0000 - accuracy: 0.0962 - val_loss: 847376704.0000 - val_accuracy: 0.1230\n",
      "Epoch 175/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308831232.0000 - accuracy: 0.0976 - val_loss: 847320192.0000 - val_accuracy: 0.0913\n",
      "Epoch 176/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1308785152.0000 - accuracy: 0.1049 - val_loss: 847280448.0000 - val_accuracy: 0.1240\n",
      "Epoch 177/256\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1308741888.0000 - accuracy: 0.1071 - val_loss: 847270848.0000 - val_accuracy: 0.1667\n",
      "Epoch 178/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1308703360.0000 - accuracy: 0.0932 - val_loss: 847191872.0000 - val_accuracy: 0.0942\n",
      "Epoch 179/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1308657536.0000 - accuracy: 0.0994 - val_loss: 847153920.0000 - val_accuracy: 0.1220\n",
      "Epoch 180/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1308616960.0000 - accuracy: 0.1088 - val_loss: 847111808.0000 - val_accuracy: 0.1230\n",
      "Epoch 181/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308573440.0000 - accuracy: 0.1126 - val_loss: 847063808.0000 - val_accuracy: 0.0923\n",
      "Epoch 182/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308530048.0000 - accuracy: 0.0942 - val_loss: 847018880.0000 - val_accuracy: 0.1240\n",
      "Epoch 183/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308483200.0000 - accuracy: 0.1156 - val_loss: 846979200.0000 - val_accuracy: 0.1250\n",
      "Epoch 184/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308439040.0000 - accuracy: 0.1173 - val_loss: 846932672.0000 - val_accuracy: 0.1250\n",
      "Epoch 185/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308395264.0000 - accuracy: 0.1203 - val_loss: 846893568.0000 - val_accuracy: 0.1250\n",
      "Epoch 186/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1308354304.0000 - accuracy: 0.1228 - val_loss: 846845184.0000 - val_accuracy: 0.1240\n",
      "Epoch 187/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308307968.0000 - accuracy: 0.1239 - val_loss: 846797504.0000 - val_accuracy: 0.1220\n",
      "Epoch 188/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308261888.0000 - accuracy: 0.1244 - val_loss: 846757504.0000 - val_accuracy: 0.1260\n",
      "Epoch 189/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308220544.0000 - accuracy: 0.1283 - val_loss: 846713728.0000 - val_accuracy: 0.1250\n",
      "Epoch 190/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308176896.0000 - accuracy: 0.1255 - val_loss: 846669120.0000 - val_accuracy: 0.1250\n",
      "Epoch 191/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308133376.0000 - accuracy: 0.1308 - val_loss: 846629056.0000 - val_accuracy: 0.1250\n",
      "Epoch 192/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308091648.0000 - accuracy: 0.1261 - val_loss: 846581568.0000 - val_accuracy: 0.1250\n",
      "Epoch 193/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308050304.0000 - accuracy: 0.1190 - val_loss: 846539840.0000 - val_accuracy: 0.1220\n",
      "Epoch 194/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1308008704.0000 - accuracy: 0.1102 - val_loss: 846500928.0000 - val_accuracy: 0.1300\n",
      "Epoch 195/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307963520.0000 - accuracy: 0.1241 - val_loss: 846461120.0000 - val_accuracy: 0.1240\n",
      "Epoch 196/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1307923712.0000 - accuracy: 0.1264 - val_loss: 846415168.0000 - val_accuracy: 0.1250\n",
      "Epoch 197/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307878400.0000 - accuracy: 0.1307 - val_loss: 846370688.0000 - val_accuracy: 0.1250\n",
      "Epoch 198/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307835648.0000 - accuracy: 0.1198 - val_loss: 846329984.0000 - val_accuracy: 0.1250\n",
      "Epoch 199/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307792128.0000 - accuracy: 0.1338 - val_loss: 846294080.0000 - val_accuracy: 0.1250\n",
      "Epoch 200/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307754624.0000 - accuracy: 0.1253 - val_loss: 846245504.0000 - val_accuracy: 0.1250\n",
      "Epoch 201/256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 11ms/step - loss: 1307708800.0000 - accuracy: 0.1237 - val_loss: 846200064.0000 - val_accuracy: 0.1230\n",
      "Epoch 202/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307664000.0000 - accuracy: 0.1349 - val_loss: 846155392.0000 - val_accuracy: 0.1290\n",
      "Epoch 203/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307618816.0000 - accuracy: 0.1336 - val_loss: 846109376.0000 - val_accuracy: 0.1250\n",
      "Epoch 204/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307577344.0000 - accuracy: 0.1264 - val_loss: 846075328.0000 - val_accuracy: 0.1250\n",
      "Epoch 205/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1307544064.0000 - accuracy: 0.1252 - val_loss: 846021568.0000 - val_accuracy: 0.1220\n",
      "Epoch 206/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307490176.0000 - accuracy: 0.1302 - val_loss: 845979840.0000 - val_accuracy: 0.1220\n",
      "Epoch 207/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307446784.0000 - accuracy: 0.1330 - val_loss: 845937408.0000 - val_accuracy: 0.1220\n",
      "Epoch 208/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307403520.0000 - accuracy: 0.1319 - val_loss: 845898880.0000 - val_accuracy: 0.1220\n",
      "Epoch 209/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307361408.0000 - accuracy: 0.1283 - val_loss: 845852352.0000 - val_accuracy: 0.1220\n",
      "Epoch 210/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307317632.0000 - accuracy: 0.1340 - val_loss: 845800320.0000 - val_accuracy: 0.1240\n",
      "Epoch 211/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307270272.0000 - accuracy: 0.1259 - val_loss: 845756992.0000 - val_accuracy: 0.1220\n",
      "Epoch 212/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307226240.0000 - accuracy: 0.1335 - val_loss: 845723840.0000 - val_accuracy: 0.1220\n",
      "Epoch 213/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307188096.0000 - accuracy: 0.1369 - val_loss: 845681152.0000 - val_accuracy: 0.1220\n",
      "Epoch 214/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307147264.0000 - accuracy: 0.1338 - val_loss: 845650816.0000 - val_accuracy: 0.1577\n",
      "Epoch 215/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1307110016.0000 - accuracy: 0.1308 - val_loss: 845592256.0000 - val_accuracy: 0.1250\n",
      "Epoch 216/256\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 1307061632.0000 - accuracy: 0.1225 - val_loss: 845553280.0000 - val_accuracy: 0.1250\n",
      "Epoch 217/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1307019264.0000 - accuracy: 0.1296 - val_loss: 845512832.0000 - val_accuracy: 0.1240\n",
      "Epoch 218/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1306978048.0000 - accuracy: 0.1395 - val_loss: 845468928.0000 - val_accuracy: 0.1250\n",
      "Epoch 219/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306935296.0000 - accuracy: 0.1390 - val_loss: 845420160.0000 - val_accuracy: 0.1240\n",
      "Epoch 220/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306889344.0000 - accuracy: 0.1358 - val_loss: 845378304.0000 - val_accuracy: 0.1240\n",
      "Epoch 221/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306845568.0000 - accuracy: 0.1363 - val_loss: 845332160.0000 - val_accuracy: 0.1240\n",
      "Epoch 222/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306802560.0000 - accuracy: 0.1392 - val_loss: 845289664.0000 - val_accuracy: 0.1250\n",
      "Epoch 223/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1306759168.0000 - accuracy: 0.1347 - val_loss: 845240320.0000 - val_accuracy: 0.1250\n",
      "Epoch 224/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306716800.0000 - accuracy: 0.1211 - val_loss: 845200128.0000 - val_accuracy: 0.1220\n",
      "Epoch 225/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1306668544.0000 - accuracy: 0.1382 - val_loss: 845156160.0000 - val_accuracy: 0.1220\n",
      "Epoch 226/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306626816.0000 - accuracy: 0.1371 - val_loss: 845115200.0000 - val_accuracy: 0.1230\n",
      "Epoch 227/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306583808.0000 - accuracy: 0.1390 - val_loss: 845073920.0000 - val_accuracy: 0.1319\n",
      "Epoch 228/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306541952.0000 - accuracy: 0.1414 - val_loss: 845031616.0000 - val_accuracy: 0.1379\n",
      "Epoch 229/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306499968.0000 - accuracy: 0.1395 - val_loss: 844992640.0000 - val_accuracy: 0.1657\n",
      "Epoch 230/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1306455680.0000 - accuracy: 0.1447 - val_loss: 844942400.0000 - val_accuracy: 0.1240\n",
      "Epoch 231/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306413824.0000 - accuracy: 0.1376 - val_loss: 844901696.0000 - val_accuracy: 0.1240\n",
      "Epoch 232/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306372864.0000 - accuracy: 0.1417 - val_loss: 844861440.0000 - val_accuracy: 0.1399\n",
      "Epoch 233/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306331264.0000 - accuracy: 0.1384 - val_loss: 844815808.0000 - val_accuracy: 0.1240\n",
      "Epoch 234/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1306287232.0000 - accuracy: 0.1461 - val_loss: 844776192.0000 - val_accuracy: 0.1617\n",
      "Epoch 235/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306245120.0000 - accuracy: 0.1464 - val_loss: 844737024.0000 - val_accuracy: 0.1647\n",
      "Epoch 236/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306223360.0000 - accuracy: 0.1200 - val_loss: 844690944.0000 - val_accuracy: 0.1250\n",
      "Epoch 237/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306177024.0000 - accuracy: 0.1277 - val_loss: 844646912.0000 - val_accuracy: 0.1220\n",
      "Epoch 238/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306132992.0000 - accuracy: 0.1237 - val_loss: 844603520.0000 - val_accuracy: 0.1220\n",
      "Epoch 239/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1306089088.0000 - accuracy: 0.1292 - val_loss: 844560064.0000 - val_accuracy: 0.1220\n",
      "Epoch 240/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1306043392.0000 - accuracy: 0.1252 - val_loss: 844515008.0000 - val_accuracy: 0.1210\n",
      "Epoch 241/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1305998080.0000 - accuracy: 0.1283 - val_loss: 844470272.0000 - val_accuracy: 0.1230\n",
      "Epoch 242/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1305952768.0000 - accuracy: 0.1316 - val_loss: 844425344.0000 - val_accuracy: 0.1329\n",
      "Epoch 243/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1305915392.0000 - accuracy: 0.1189 - val_loss: 844384064.0000 - val_accuracy: 0.1171\n",
      "Epoch 244/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1305869696.0000 - accuracy: 0.1123 - val_loss: 844340864.0000 - val_accuracy: 0.1161\n",
      "Epoch 245/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1305827712.0000 - accuracy: 0.1226 - val_loss: 844298752.0000 - val_accuracy: 0.1250\n",
      "Epoch 246/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1305786752.0000 - accuracy: 0.1113 - val_loss: 844253376.0000 - val_accuracy: 0.1220\n",
      "Epoch 247/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1305738880.0000 - accuracy: 0.1324 - val_loss: 844206848.0000 - val_accuracy: 0.1161\n",
      "Epoch 248/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1305693952.0000 - accuracy: 0.1220 - val_loss: 844164608.0000 - val_accuracy: 0.1230\n",
      "Epoch 249/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1305651328.0000 - accuracy: 0.1231 - val_loss: 844119552.0000 - val_accuracy: 0.1032\n",
      "Epoch 250/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1305609344.0000 - accuracy: 0.0956 - val_loss: 844080640.0000 - val_accuracy: 0.1151\n",
      "Epoch 251/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1305568000.0000 - accuracy: 0.1069 - val_loss: 844042240.0000 - val_accuracy: 0.1399\n",
      "Epoch 252/256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 11ms/step - loss: 1305523840.0000 - accuracy: 0.1237 - val_loss: 843992704.0000 - val_accuracy: 0.1210\n",
      "Epoch 253/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1305479808.0000 - accuracy: 0.1230 - val_loss: 843948352.0000 - val_accuracy: 0.1002\n",
      "Epoch 254/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1305436928.0000 - accuracy: 0.1068 - val_loss: 843903488.0000 - val_accuracy: 0.1171\n",
      "Epoch 255/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1305391232.0000 - accuracy: 0.1126 - val_loss: 843862016.0000 - val_accuracy: 0.1190\n",
      "Epoch 256/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1305347328.0000 - accuracy: 0.1275 - val_loss: 843822336.0000 - val_accuracy: 0.0962\n",
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_8 (InputLayer)            [(None, 72, 8)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_14 (LSTM)                  [(None, 256), (None, 271360      input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_7 (RepeatVector)  (None, 24, 256)      0           lstm_14[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_15 (LSTM)                  [(None, 24, 256), (N 525312      repeat_vector_7[0][0]            \n",
      "                                                                 lstm_14[0][1]                    \n",
      "                                                                 lstm_14[0][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 24, 1)        257         lstm_15[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 796,929\n",
      "Trainable params: 796,929\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Took 19.94 sec for training the model\n",
      "{'train_losses': [1316863104.0, 1316392576.0, 1316294912.0, 1316238592.0, 1316191104.0, 1316143616.0, 1316099584.0, 1316058240.0, 1316015872.0, 1315971968.0, 1315928320.0, 1315884800.0, 1315841024.0, 1315797248.0, 1315754112.0, 1315714048.0, 1315672832.0, 1315627520.0, 1315587840.0, 1315546880.0, 1315504128.0, 1315462144.0, 1315456640.0, 1315385984.0, 1315334016.0, 1315292288.0, 1315245952.0, 1315199232.0, 1315155968.0, 1315116032.0, 1315072256.0, 1315027328.0, 1314982528.0, 1314939392.0, 1314895872.0, 1314853632.0, 1314809600.0, 1314763264.0, 1314721152.0, 1314675840.0, 1314631680.0, 1314588928.0, 1314542208.0, 1314502400.0, 1314457856.0, 1314411520.0, 1314371072.0, 1314328704.0, 1314284800.0, 1314244864.0, 1314200320.0, 1314158464.0, 1314114944.0, 1314068864.0, 1314027008.0, 1313983104.0, 1313937920.0, 1313895168.0, 1313852544.0, 1313807488.0, 1313763840.0, 1313721856.0, 1313680768.0, 1313633536.0, 1313594496.0, 1313551872.0, 1313509888.0, 1313464960.0, 1313423104.0, 1313376768.0, 1313334016.0, 1313292416.0, 1313247744.0, 1313202304.0, 1313156992.0, 1313117824.0, 1313073664.0, 1313029504.0, 1312986752.0, 1312941312.0, 1312899712.0, 1312856960.0, 1312813440.0, 1312770688.0, 1312725120.0, 1312684288.0, 1312638592.0, 1312595712.0, 1312552192.0, 1312507264.0, 1312464384.0, 1312422144.0, 1312379904.0, 1312335872.0, 1312290304.0, 1312245760.0, 1312203648.0, 1312158720.0, 1312115712.0, 1312073216.0, 1312030976.0, 1311985664.0, 1311943808.0, 1313146496.0, 1311864320.0, 1311819392.0, 1311775872.0, 1311728768.0, 1311686784.0, 1311644032.0, 1311602432.0, 1311559936.0, 1311513728.0, 1311471232.0, 1311429760.0, 1311385984.0, 1311341824.0, 1311300352.0, 1311255680.0, 1311210368.0, 1311168256.0, 1311124864.0, 1311081600.0, 1311036544.0, 1310992256.0, 1310950912.0, 1310905216.0, 1310861184.0, 1310819840.0, 1310774144.0, 1310732032.0, 1310689536.0, 1310648192.0, 1310604928.0, 1310561152.0, 1310518016.0, 1310471680.0, 1310429440.0, 1310384768.0, 1310342784.0, 1310300160.0, 1310255488.0, 1310214912.0, 1310173312.0, 1310129152.0, 1310086912.0, 1310040448.0, 1309995648.0, 1309952128.0, 1309906688.0, 1309865856.0, 1309822464.0, 1309778048.0, 1309731712.0, 1309691392.0, 1309651968.0, 1309609344.0, 1309563392.0, 1309521280.0, 1309478656.0, 1309433216.0, 1309395712.0, 1309349248.0, 1309305472.0, 1309259392.0, 1309216640.0, 1309170048.0, 1309132928.0, 1309092224.0, 1309048320.0, 1309001600.0, 1308958336.0, 1308917504.0, 1308872320.0, 1308831232.0, 1308785152.0, 1308741888.0, 1308703360.0, 1308657536.0, 1308616960.0, 1308573440.0, 1308530048.0, 1308483200.0, 1308439040.0, 1308395264.0, 1308354304.0, 1308307968.0, 1308261888.0, 1308220544.0, 1308176896.0, 1308133376.0, 1308091648.0, 1308050304.0, 1308008704.0, 1307963520.0, 1307923712.0, 1307878400.0, 1307835648.0, 1307792128.0, 1307754624.0, 1307708800.0, 1307664000.0, 1307618816.0, 1307577344.0, 1307544064.0, 1307490176.0, 1307446784.0, 1307403520.0, 1307361408.0, 1307317632.0, 1307270272.0, 1307226240.0, 1307188096.0, 1307147264.0, 1307110016.0, 1307061632.0, 1307019264.0, 1306978048.0, 1306935296.0, 1306889344.0, 1306845568.0, 1306802560.0, 1306759168.0, 1306716800.0, 1306668544.0, 1306626816.0, 1306583808.0, 1306541952.0, 1306499968.0, 1306455680.0, 1306413824.0, 1306372864.0, 1306331264.0, 1306287232.0, 1306245120.0, 1306223360.0, 1306177024.0, 1306132992.0, 1306089088.0, 1306043392.0, 1305998080.0, 1305952768.0, 1305915392.0, 1305869696.0, 1305827712.0, 1305786752.0, 1305738880.0, 1305693952.0, 1305651328.0, 1305609344.0, 1305568000.0, 1305523840.0, 1305479808.0, 1305436928.0, 1305391232.0, 1305347328.0], 'val_losses': [855009792.0, 854877120.0, 854816448.0, 854767808.0, 854719232.0, 854674304.0, 854633024.0, 854591168.0, 854546560.0, 854502464.0, 854458496.0, 854414592.0, 854370112.0, 854326208.0, 854286464.0, 854245504.0, 854199424.0, 854160064.0, 854119168.0, 854076096.0, 854032704.0, 854004864.0, 853972992.0, 853904320.0, 853863168.0, 853816640.0, 853768384.0, 853725056.0, 853685376.0, 853642176.0, 853596928.0, 853551808.0, 853507968.0, 853464512.0, 853422464.0, 853378176.0, 853331008.0, 853288832.0, 853242816.0, 853198336.0, 853156160.0, 853107840.0, 853068480.0, 853024000.0, 852975808.0, 852935744.0, 852893376.0, 852849216.0, 852809600.0, 852764480.0, 852722560.0, 852679360.0, 852631936.0, 852590016.0, 852546432.0, 852500672.0, 852457472.0, 852414976.0, 852369536.0, 852325440.0, 852283392.0, 852242624.0, 852193600.0, 852153664.0, 852112512.0, 852070592.0, 852025024.0, 851983488.0, 851936384.0, 851893504.0, 851852352.0, 851806912.0, 851761280.0, 851714816.0, 851676416.0, 851631808.0, 851587264.0, 851544384.0, 851498112.0, 851456512.0, 851413184.0, 851369792.0, 851326656.0, 851280448.0, 851239872.0, 851193728.0, 851150464.0, 851106560.0, 851061120.0, 851017920.0, 850975616.0, 850932992.0, 850889408.0, 850843264.0, 850797632.0, 850756096.0, 850709760.0, 850667136.0, 850624384.0, 850582080.0, 850536320.0, 850494336.0, 855704256.0, 850414720.0, 850369664.0, 850326080.0, 850277312.0, 850235584.0, 850192256.0, 850151040.0, 850108736.0, 850061504.0, 850018624.0, 849977152.0, 849933184.0, 849888512.0, 849846848.0, 849802176.0, 849756032.0, 849713728.0, 849669824.0, 849626816.0, 849581120.0, 849536448.0, 849495296.0, 849448960.0, 849404480.0, 849363520.0, 849316608.0, 849274368.0, 849232576.0, 849190912.0, 849146816.0, 849103168.0, 849084608.0, 849012352.0, 848970112.0, 848925056.0, 848883840.0, 848846080.0, 848801472.0, 848754880.0, 848736064.0, 848668992.0, 848626944.0, 848579264.0, 848534016.0, 848491072.0, 848445568.0, 848404480.0, 848360768.0, 848316096.0, 848269312.0, 848228928.0, 848189440.0, 848152896.0, 848104512.0, 848056704.0, 848015360.0, 847970432.0, 847938688.0, 847884288.0, 847841984.0, 847800832.0, 847752896.0, 847707584.0, 847669568.0, 847629760.0, 847587456.0, 847537664.0, 847492800.0, 847458880.0, 847408384.0, 847376704.0, 847320192.0, 847280448.0, 847270848.0, 847191872.0, 847153920.0, 847111808.0, 847063808.0, 847018880.0, 846979200.0, 846932672.0, 846893568.0, 846845184.0, 846797504.0, 846757504.0, 846713728.0, 846669120.0, 846629056.0, 846581568.0, 846539840.0, 846500928.0, 846461120.0, 846415168.0, 846370688.0, 846329984.0, 846294080.0, 846245504.0, 846200064.0, 846155392.0, 846109376.0, 846075328.0, 846021568.0, 845979840.0, 845937408.0, 845898880.0, 845852352.0, 845800320.0, 845756992.0, 845723840.0, 845681152.0, 845650816.0, 845592256.0, 845553280.0, 845512832.0, 845468928.0, 845420160.0, 845378304.0, 845332160.0, 845289664.0, 845240320.0, 845200128.0, 845156160.0, 845115200.0, 845073920.0, 845031616.0, 844992640.0, 844942400.0, 844901696.0, 844861440.0, 844815808.0, 844776192.0, 844737024.0, 844690944.0, 844646912.0, 844603520.0, 844560064.0, 844515008.0, 844470272.0, 844425344.0, 844384064.0, 844340864.0, 844298752.0, 844253376.0, 844206848.0, 844164608.0, 844119552.0, 844080640.0, 844042240.0, 843992704.0, 843948352.0, 843903488.0, 843862016.0, 843822336.0], 'train_accs': [0.13160377740859985, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.007075472269207239, 0.0, 0.0, 0.0009433962404727936, 0.0, 0.0018867924809455872, 0.0, 0.0037735849618911743, 0.0, 0.0004716981202363968, 0.0004716981202363968, 0.10833333432674408, 0.004088050685822964, 0.005188679788261652, 0.004402515944093466, 0.0045597488060593605, 0.0045597488060593605, 0.005503144580870867, 0.004874213598668575, 0.0059748427011072636, 0.005974842235445976, 0.004874214064329863, 0.007547169923782349, 0.005188679322600365, 0.007389937061816454, 0.007547169923782349, 0.004716981668025255, 0.0072327046655118465, 0.011006289161741734, 0.007547169923782349, 0.005188679322600365, 0.009748428128659725, 0.009748428128659725, 0.008018868044018745, 0.011320755816996098, 0.003930817823857069, 0.015880504623055458, 0.004716981202363968, 0.00676100654527545, 0.012264151126146317, 0.008962264284491539, 0.008333333767950535, 0.010220126248896122, 0.008805031888186932, 0.008490567095577717, 0.008018868044018745, 0.011006289161741734, 0.01147798728197813, 0.016509434208273888, 0.030345913022756577, 0.01745283044874668, 0.02295597456395626, 0.021855344995856285, 0.014465410262346268, 0.041352204978466034, 0.04308176040649414, 0.03977987542748451, 0.049056608229875565, 0.00644654082134366, 0.009591195732355118, 0.020283019170165062, 0.04528301954269409, 0.044811323285102844, 0.044654086232185364, 0.04921383783221245, 0.07421384006738663, 0.03977987542748451, 0.05204402655363083, 0.05896226689219475, 0.05283019319176674, 0.037893082946538925, 0.044025156646966934, 0.06069182604551315, 0.0691823959350586, 0.07421384006738663, 0.060220133513212204, 0.07405661046504974, 0.08349056541919708, 0.08223270624876022, 0.07720126211643219, 0.07641509175300598, 0.09622641652822495, 0.09764151275157928, 0.10487420856952667, 0.10707547515630722, 0.09323900192975998, 0.09937107563018799, 0.10880503803491592, 0.1125786155462265, 0.09418239444494247, 0.11556603759527206, 0.11729560792446136, 0.12028302252292633, 0.12279874831438065, 0.12389937788248062, 0.12437108159065247, 0.12830188870429993, 0.12547169625759125, 0.13081762194633484, 0.12610061466693878, 0.11902516335248947, 0.11022012680768967, 0.1240566149353981, 0.12641508877277374, 0.13066036999225616, 0.11981132626533508, 0.133805051445961, 0.12531445920467377, 0.12374214082956314, 0.13490566611289978, 0.13364779949188232, 0.12641508877277374, 0.12515723705291748, 0.13018867373466492, 0.1330188661813736, 0.131918266415596, 0.12830188870429993, 0.1339622586965561, 0.1259434074163437, 0.13349056243896484, 0.13694968819618225, 0.1338050365447998, 0.13081762194633484, 0.12248428910970688, 0.12955975532531738, 0.13946543633937836, 0.13899371027946472, 0.13584907352924347, 0.13632076978683472, 0.1391509473323822, 0.1347484588623047, 0.12106919288635254, 0.1382075399160385, 0.13710692524909973, 0.13899371027946472, 0.14135220646858215, 0.13946542143821716, 0.14465409517288208, 0.13757862150669098, 0.14166666567325592, 0.1383647918701172, 0.14606919884681702, 0.14638365805149078, 0.11996855586767197, 0.1276729702949524, 0.12374214082956314, 0.12924528121948242, 0.12515723705291748, 0.12830188870429993, 0.13160377740859985, 0.11886793375015259, 0.11226414889097214, 0.12264151126146317, 0.11132075637578964, 0.13238994777202606, 0.12201257050037384, 0.12311320751905441, 0.09559749066829681, 0.10691823810338974, 0.12374214082956314, 0.12295598536729813, 0.10676100850105286, 0.1125786155462265, 0.1275157332420349], 'val_accs': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3859127163887024, 0.01884920708835125, 0.02083333395421505, 0.02083333395421505, 0.02083333395421505, 0.02083333395421505, 0.0218253992497921, 0.02281746082007885, 0.02579365111887455, 0.02579365111887455, 0.02678571455180645, 0.02876984141767025, 0.0277777798473835, 0.032738097012043, 0.0317460335791111, 0.0317460335791111, 0.0347222276031971, 0.0367063507437706, 0.0307539701461792, 0.032738097012043, 0.0376984179019928, 0.0347222276031971, 0.0337301604449749, 0.0337301604449749, 0.02083333395421505, 0.0406746082007885, 0.01388888992369175, 0.0277777798473835, 0.0416666679084301, 0.02083333395421505, 0.0277777798473835, 0.0406746082007885, 0.0912698432803154, 0.0277777798473835, 0.0367063507437706, 0.0406746082007885, 0.042658731341362, 0.0575396828353405, 0.072420634329319, 0.0406746082007885, 0.09920634329319, 0.0416666679084301, 0.0406746082007885, 0.042658731341362, 0.0505952388048172, 0.0466269887983799, 0.068452388048172, 0.02579365111887455, 0.0337301604449749, 0.0396825410425663, 0.0406746082007885, 0.0595238134264946, 0.075396828353405, 0.0912698432803154, 0.0892857164144516, 0.068452388048172, 0.0793650820851326, 0.0714285746216774, 0.0982142835855484, 0.0763888955116272, 0.0793650820851326, 0.1001984179019928, 0.0763888955116272, 0.0902777761220932, 0.0982142835855484, 0.1001984179019928, 0.09920634329319, 0.085317462682724, 0.0773809552192688, 0.1121031790971756, 0.09920634329319, 0.1230158805847168, 0.0912698432803154, 0.1240079402923584, 0.1666666716337204, 0.0942460373044014, 0.122023805975914, 0.1230158805847168, 0.092261902987957, 0.1240079402923584, 0.125, 0.125, 0.125, 0.1240079402923584, 0.122023805975914, 0.1259920746088028, 0.125, 0.125, 0.125, 0.125, 0.122023805975914, 0.1299603283405304, 0.1240079402923584, 0.125, 0.125, 0.125, 0.125, 0.125, 0.1230158805847168, 0.1289682686328888, 0.125, 0.125, 0.122023805975914, 0.122023805975914, 0.122023805975914, 0.122023805975914, 0.122023805975914, 0.1240079402923584, 0.122023805975914, 0.122023805975914, 0.122023805975914, 0.1577380895614624, 0.125, 0.125, 0.1240079402923584, 0.125, 0.1240079402923584, 0.1240079402923584, 0.1240079402923584, 0.125, 0.125, 0.122023805975914, 0.122023805975914, 0.1230158805847168, 0.1319444477558136, 0.1378968358039856, 0.1656746119260788, 0.1240079402923584, 0.1240079402923584, 0.1398809552192688, 0.1240079402923584, 0.1617063581943512, 0.1646825522184372, 0.125, 0.122023805975914, 0.122023805975914, 0.122023805975914, 0.1210317462682724, 0.1230158805847168, 0.1329365074634552, 0.1170634999871254, 0.1160714253783226, 0.125, 0.122023805975914, 0.1160714253783226, 0.1230158805847168, 0.1031746044754982, 0.115079365670681, 0.1398809552192688, 0.1210317462682724, 0.1001984179019928, 0.1170634999871254, 0.1190476194024086, 0.0962301641702652], 'train_acc': 0.04856463923715637, 'val_acc': 0.05573769338661805, 'test_nrmse': 0.9894380834319716, 'y_test': [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1200.0, 2500.0, 3300.0, 11300.0, 13800.0, 12200.0, 8100.0, 4400.0, 2500.0, 3000.0, 3700.0, 300.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1300.0, 5800.0, 11300.0, 23400.0, 44600.0, 63500.0, 57800.0, 63900.0, 38600.0, 32400.0, 19400.0, 24300.0, 9700.0, 600.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 1100.0, 5000.0, 14500.0, 42800.0, 57800.0, 72500.0, 76200.0, 61500.0, 48100.0, 51700.0, 20400.0, 11100.0, 8400.0, 2000.0, 1100.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 700.0, 9100.0, 13200.0, 20300.0, 28900.0, 26800.0, 40600.0, 52300.0, 36200.0, 29900.0, 41400.0, 30500.0, 19300.0, 8300.0, 700.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2600.0, 4500.0, 6900.0, 6600.0, 17000.0, 16300.0, 32100.0, 22500.0, 14000.0, 9100.0, 5000.0, 4500.0, 400.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 400.0, 2800.0, 5100.0, 11700.0, 21900.0, 14800.0, 12900.0, 24100.0, 18200.0, 13200.0, 15500.0, 10600.0, 4700.0, 2100.0, 700.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 500.0, 7700.0, 18600.0, 14500.0, 22800.0, 34500.0, 23900.0, 46400.0, 25200.0, 20700.0, 19600.0, 28200.0, 14100.0, 6500.0, 1800.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1500.0, 4300.0, 6200.0, 17500.0, 11300.0, 9600.0, 10600.0, 11800.0, 7700.0, 3700.0, 3700.0, 3500.0, 2100.0, 900.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 400.0, 4100.0, 13300.0, 29500.0, 54500.0, 48100.0, 59800.0, 68100.0, 63900.0, 50800.0, 55000.0, 34800.0, 11000.0, 1600.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 400.0, 4600.0, 20100.0, 37100.0, 50200.0, 62400.0, 49300.0, 52100.0, 47400.0, 57700.0, 45600.0, 22000.0, 12600.0, 6500.0, 800.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 400.0, 4700.0, 7700.0, 29200.0, 28200.0, 29100.0, 42000.0, 41400.0, 26800.0, 13400.0, 6500.0, 3400.0, 900.0, 200.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 900.0, 4900.0, 9800.0, 13500.0, 25300.0, 29700.0, 41500.0, 24900.0, 8400.0, 17300.0, 14100.0, 2200.0, 500.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 300.0, 5600.0, 12200.0, 22100.0, 28200.0, 32800.0, 48700.0, 38200.0, 42600.0, 30200.0, 28600.0, 21100.0, 16000.0, 8000.0, 400.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 100.0, 700.0, 1900.0, 4000.0, 5500.0, 2700.0, 4300.0, 4600.0, 4100.0, 3800.0, 1800.0, 1000.0, 1000.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 400.0, 1200.0, 4300.0, 4300.0, 6000.0, 3700.0, 2000.0, 5300.0, 2800.0, 1200.0, 400.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 400.0, 3200.0, 6900.0, 12100.0, 31800.0, 31700.0, 44200.0, 34900.0, 24800.0, 32300.0, 21000.0, 16600.0, 7000.0, 3300.0, 200.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1400.0, 5100.0, 12300.0, 13700.0, 13200.0, 9700.0, 15500.0, 12700.0, 8200.0, 11100.0, 8300.0, 5200.0, 1200.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5200.0, 14100.0, 17500.0, 8400.0, 9800.0, 26200.0, 48100.0, 63700.0, 46200.0, 38200.0, 26100.0, 14000.0, 7200.0, 700.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1500.0, 8100.0, 19000.0, 22500.0, 22100.0, 53000.0, 41900.0, 33200.0, 50300.0, 43700.0, 35100.0, 20800.0, 6100.0, 800.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2000.0, 8200.0, 8100.0, 14400.0, 35800.0, 27800.0, 25000.0, 23000.0, 9000.0, 12300.0, 22200.0, 9800.0, 2200.0, 100.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 700.0, 2000.0, 4800.0, 5800.0, 7500.0, 6200.0, 8800.0, 9800.0, 7300.0, 6000.0, 4100.0, 1300.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 100.0, 600.0, 6400.0, 9800.0, 5400.0, 22000.0, 29800.0, 34600.0, 34400.0, 27500.0, 16100.0, 6300.0, 3500.0, 800.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 400.0, 8400.0, 7500.0, 8500.0, 22200.0, 28400.0, 30500.0, 34800.0, 40100.0, 52300.0, 32100.0, 26000.0, 9800.0, 2100.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1500.0, 5200.0, 6200.0, 8400.0, 10800.0, 10700.0, 10700.0, 12900.0, 14000.0, 10700.0, 14700.0, 7300.0, 3900.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 700.0, 500.0, 4700.0, 3200.0, 2400.0, 2100.0, 2100.0, 3100.0, 2000.0, 1400.0, 2100.0, 400.0, 400.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1200.0, 2100.0, 2600.0, 6900.0, 8100.0, 11100.0, 6500.0, 3000.0, 11400.0, 16600.0, 8100.0, 4700.0, 5000.0, 700.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 100.0, 2300.0, 4300.0, 15000.0, 15100.0, 27600.0, 32000.0, 56800.0, 19500.0, 32900.0, 25600.0, 9600.0, 20500.0, 2500.0, 100.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4200.0, 11100.0, 29600.0, 40300.0, 50900.0, 28700.0, 50700.0, 27300.0, 32500.0, 37200.0, 22900.0, 17800.0, 4000.0, 200.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1400.0, 4600.0, 6900.0, 11400.0, 15900.0, 23200.0, 19200.0, 15300.0, 5200.0, 5200.0, 1100.0, 1200.0, 200.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1700.0, 7700.0, 12500.0, 14000.0, 18700.0, 14500.0, 14300.0, 17900.0, 10400.0, 5900.0, 11400.0, 4200.0, 700.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 100.0, 2500.0, 6000.0, 19200.0, 20500.0, 16900.0, 15900.0, 18400.0, 9800.0, 8100.0, 7400.0, 8500.0, 3600.0, 6900.0, 100.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1700.0, 6000.0, 6400.0, 22200.0, 41100.0, 27600.0, 25900.0, 29600.0, 18500.0, 6900.0, 2500.0, 4000.0, 3900.0, 100.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3600.0, 11800.0, 29000.0, 39600.0, 58800.0, 61400.0, 44100.0, 45200.0, 46000.0, 28000.0, 29900.0, 8200.0, 2700.0, 400.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2600.0, 10400.0, 26400.0, 42400.0, 54500.0, 57900.0, 49900.0, 35700.0, 20600.0, 17300.0, 10700.0, 8500.0, 3900.0, 300.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1400.0, 11900.0, 21100.0, 22900.0, 46500.0, 35400.0, 44000.0, 43200.0, 31300.0, 20700.0, 13300.0, 8500.0, 4100.0, 300.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2100.0, 12700.0, 8700.0, 19600.0, 17900.0, 17800.0, 33400.0, 34900.0, 28400.0, 13700.0, 7700.0, 10900.0, 3000.0, 100.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3200.0, 10600.0, 19700.0, 21300.0, 34300.0, 35200.0, 36900.0, 38900.0, 40000.0, 15700.0, 8400.0, 6900.0, 2800.0, 100.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1500.0, 7600.0, 13000.0, 12000.0, 6000.0, 11000.0, 13900.0, 15300.0, 10200.0, 21100.0, 10200.0, 6100.0, 1300.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 800.0, 900.0, 1000.0, 2000.0, 2400.0, 4400.0, 3200.0, 2000.0, 3300.0, 3000.0, 5700.0, 1000.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 500.0, 2200.0, 1900.0, 3400.0, 4600.0, 5200.0, 3700.0, 3900.0, 400.0, 100.0, 100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 900.0, 6600.0, 100.0, 800.0, 1800.0, 10500.0, 4200.0, 7000.0, 2400.0, 2700.0, 1900.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3100.0, 10400.0, 23800.0, 30300.0, 67400.0, 36400.0, 34800.0, 56300.0, 31600.0, 25100.0, 14500.0, 7700.0, 1300.0, 650.0, 0.0, 0.0, 0.0, 0.0]], 'y_pred': [[0.0, 0.0, 0.0, 8.992700576782227, 52.566139221191406, 195.3734893798828, 345.71478271484375, 346.70184326171875, 346.8335876464844, 346.85150146484375, 346.8538818359375, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875], [0.0, 0.0, 0.0, 13.761828422546387, 67.52513885498047, 251.07803344726562, 345.6065368652344, 346.6839904785156, 346.8311462402344, 346.8511657714844, 346.8538513183594, 346.854248046875, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531], [0.0, 0.0, 0.0, 10.604461669921875, 57.5007438659668, 204.14527893066406, 345.6498718261719, 346.6915588378906, 346.8321838378906, 346.85125732421875, 346.8538513183594, 346.85418701171875, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531], [0.0, 0.0, 0.0, 36.247093200683594, 127.35698699951172, 343.4408264160156, 346.541259765625, 346.8117980957031, 346.84844970703125, 346.8534851074219, 346.8541259765625, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875], [35.94111633300781, 0.0, 0.0, 0.0, 39.34757995605469, 124.95865631103516, 340.1062927246094, 346.43994140625, 346.79791259765625, 346.8466491699219, 346.8532409667969, 346.8541259765625, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531], [119.91802978515625, 294.1759948730469, 338.881103515625, 345.75250244140625, 346.7046203613281, 346.83404541015625, 346.8515319824219, 346.8539123535156, 346.854248046875, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531], [0.0, 0.0, 0.0, 13.426770210266113, 56.000850677490234, 184.98828125, 346.0168151855469, 346.7461853027344, 346.8396301269531, 346.852294921875, 346.85400390625, 346.8542175292969, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531], [0.0, 0.0, 0.0, 33.86235809326172, 99.92833709716797, 336.8104553222656, 346.6051330566406, 346.8204345703125, 346.84967041015625, 346.8536071777344, 346.8541259765625, 346.85418701171875, 346.8542175292969, 346.8542175292969, 346.8542175292969, 346.8542175292969, 346.8542175292969, 346.8542175292969, 346.8542175292969, 346.8542175292969, 346.8542175292969, 346.8542175292969, 346.8542175292969, 346.8542175292969], [0.0, 0.0, 0.0, 11.87649917602539, 57.42534637451172, 210.7231903076172, 345.9521179199219, 346.732666015625, 346.8377990722656, 346.8520202636719, 346.8539733886719, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875], [0.0, 0.0, 0.0, 19.16134262084961, 68.3799057006836, 271.63525390625, 346.2543029785156, 346.7728576660156, 346.84326171875, 346.8527526855469, 346.8540344238281, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875], [0.0, 0.0, 0.0, 9.40458869934082, 53.72226333618164, 203.22706604003906, 345.7099914550781, 346.7001647949219, 346.8333435058594, 346.8514404296875, 346.8538818359375, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875], [0.0, 0.0, 0.0, 14.401602745056152, 67.9225082397461, 252.93247985839844, 345.765625, 346.705810546875, 346.8341369628906, 346.8515319824219, 346.8539123535156, 346.854248046875, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531], [0.0, 0.0, 0.0, 11.25268840789795, 59.157066345214844, 219.99826049804688, 345.7339172363281, 346.7021179199219, 346.8336486816406, 346.8514709472656, 346.8538818359375, 346.854248046875, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531], [0.0, 0.0, 0.0, 9.157115936279297, 52.70384216308594, 197.5748748779297, 345.719482421875, 346.70220947265625, 346.83367919921875, 346.85150146484375, 346.8538818359375, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875], [0.0, 0.0, 0.0, 12.529740333557129, 65.95964050292969, 240.7391815185547, 345.4141540527344, 346.6575012207031, 346.82757568359375, 346.8507080078125, 346.8537902832031, 346.85418701171875, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531], [154.6977081298828, 320.6919250488281, 343.1356506347656, 346.3465576171875, 346.785400390625, 346.8450012207031, 346.85302734375, 346.8540954589844, 346.854248046875, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531], [0.0, 0.0, 6.548648834228516, 42.13615417480469, 127.12145233154297, 344.18316650390625, 346.6824645996094, 346.8309020996094, 346.8510437011719, 346.853759765625, 346.8541259765625, 346.85418701171875, 346.8542175292969, 346.8542175292969, 346.8542175292969, 346.8542175292969, 346.8542175292969, 346.8542175292969, 346.8542175292969, 346.8542175292969, 346.8542175292969, 346.8542175292969, 346.8542175292969, 346.8542175292969], [0.0, 0.0, 19.140483856201172, 67.39434051513672, 264.5626525878906, 346.1244812011719, 346.7553405761719, 346.84088134765625, 346.8524169921875, 346.8539733886719, 346.85418701171875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875], [0.0, 0.0, 0.0, 10.3718900680542, 53.84233474731445, 183.33261108398438, 345.8150329589844, 346.71868896484375, 346.83587646484375, 346.8517150878906, 346.85394287109375, 346.8542175292969, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531], [0.0, 0.0, 0.0, 13.898024559020996, 59.23784637451172, 225.13229370117188, 346.0726318359375, 346.7486877441406, 346.8399658203125, 346.8523254394531, 346.8540344238281, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875], [0.0, 0.0, 0.0, 12.128777503967285, 62.29027557373047, 228.30421447753906, 345.63079833984375, 346.6876525878906, 346.8316955566406, 346.8512268066406, 346.8538513183594, 346.854248046875, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531], [0.0, 0.0, 0.0, 10.052262306213379, 54.54432678222656, 198.6495361328125, 345.8067626953125, 346.7139587402344, 346.83526611328125, 346.8516845703125, 346.85394287109375, 346.854248046875, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531], [0.0, 0.0, 0.0, 13.431018829345703, 59.797569274902344, 233.53387451171875, 345.974365234375, 346.7349548339844, 346.83807373046875, 346.85205078125, 346.8539733886719, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875], [0.0, 0.0, 0.0, 8.809199333190918, 53.03453063964844, 198.86236572265625, 345.6235046386719, 346.688720703125, 346.83184814453125, 346.8512268066406, 346.8538818359375, 346.854248046875, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531], [0.0, 0.0, 0.0, 13.946429252624512, 65.8784408569336, 248.551025390625, 345.8224792480469, 346.7137451171875, 346.8351745605469, 346.8517150878906, 346.8539123535156, 346.854248046875, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531], [0.0, 0.0, 0.0, 11.960140228271484, 63.15172576904297, 231.11068725585938, 345.5332946777344, 346.674072265625, 346.82989501953125, 346.8509521484375, 346.85382080078125, 346.854248046875, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531], [11.308832168579102, 0.0, 0.0, 3.795468330383301, 47.716373443603516, 158.50514221191406, 344.1016845703125, 346.51690673828125, 346.8084411621094, 346.84808349609375, 346.85345458984375, 346.8541564941406, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531], [0.0, 0.0, 0.0, 11.287799835205078, 56.797027587890625, 204.7952423095703, 345.8631896972656, 346.7209167480469, 346.836181640625, 346.851806640625, 346.85394287109375, 346.854248046875, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531], [0.0, 0.0, 0.0, 10.400484085083008, 55.00043487548828, 206.25799560546875, 345.8431701660156, 346.7182312011719, 346.8358154296875, 346.85174560546875, 346.85394287109375, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875], [0.0, 0.0, 0.0, 9.429454803466797, 58.47880554199219, 208.3776397705078, 345.2331848144531, 346.6336364746094, 346.8243103027344, 346.8502197265625, 346.8537292480469, 346.85418701171875, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531], [0.0, 0.0, 0.0, 9.562453269958496, 53.333740234375, 196.83438110351562, 345.7861022949219, 346.7114562988281, 346.83489990234375, 346.8516540527344, 346.85394287109375, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875], [0.0, 0.0, 0.0, 10.797036170959473, 56.9833869934082, 217.96664428710938, 345.775146484375, 346.70806884765625, 346.8344421386719, 346.8515930175781, 346.8538818359375, 346.854248046875, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531], [0.0, 0.0, 0.0, 12.21180534362793, 59.73863983154297, 229.5289764404297, 345.8605041503906, 346.71929931640625, 346.83599853515625, 346.85174560546875, 346.85394287109375, 346.854248046875, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531], [0.0, 0.0, 0.0, 11.998092651367188, 57.35734939575195, 219.7869873046875, 345.89324951171875, 346.72418212890625, 346.8366394042969, 346.85186767578125, 346.85394287109375, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875], [0.0, 0.0, 0.0, 12.943541526794434, 59.183319091796875, 229.9771270751953, 345.9177551269531, 346.7272644042969, 346.8370361328125, 346.8519287109375, 346.8539733886719, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875], [0.0, 0.0, 0.0, 16.232444763183594, 65.82866668701172, 259.4365539550781, 346.0714416503906, 346.74786376953125, 346.8398742675781, 346.8523254394531, 346.85400390625, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875], [0.0, 0.0, 0.0, 17.08963966369629, 67.49378204345703, 266.62213134765625, 346.10552978515625, 346.75250244140625, 346.8404846191406, 346.8524169921875, 346.8540344238281, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875], [0.0, 0.0, 0.0, 18.022686004638672, 69.19022369384766, 274.1322937011719, 346.1412658691406, 346.75738525390625, 346.84112548828125, 346.8525085449219, 346.8540344238281, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875], [0.0, 0.0, 0.0, 19.993310928344727, 74.03062438964844, 291.06787109375, 346.20367431640625, 346.765869140625, 346.84228515625, 346.8526306152344, 346.8540344238281, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875], [0.0, 0.0, 0.0, 17.756757736206055, 69.45362091064453, 273.5762023925781, 346.1209411621094, 346.75457763671875, 346.84075927734375, 346.85247802734375, 346.8540344238281, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875, 346.854248046875], [0.0, 0.0, 0.0, 15.887272834777832, 67.48350524902344, 262.3494873046875, 346.0147705078125, 346.7400817871094, 346.8387756347656, 346.8521728515625, 346.85400390625, 346.854248046875, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531], [0.0, 0.0, 0.0, 11.051619529724121, 57.38412094116211, 217.97802734375, 345.78759765625, 346.7096862792969, 346.8346862792969, 346.85162353515625, 346.8539123535156, 346.854248046875, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531, 346.8542785644531]], 'exp_name': 'solar power prediction using weather features', 'plant': 126, 'spot': 174, 'start_date': '20190820', 'end_date': '20200809', 'batch_size': 64, 'x_frames': 3, 'y_frames': 1, 'hid_dim': 256, 'optim': 'RMSprop', 'activation': 'relu', 'lss': 'MSE', 'lr': 0.001, 'epochs': 256, 'early_stop': 30, 'evaluation': 'NRMSE', 'features': \"[<FeatureType.SUNSHINE: '일조(hr)'>, <FeatureType.HUMIDITY: '습도(%)'>, <FeatureType.WIND_SPEED: '풍속(m/s)'>, <FeatureType.VISIBILITY: '시정(10m)'>, <FeatureType.GROUND_TEMPERATURE: '지면온도(°C)'>, <FeatureType.WIND_DIRECTION: '풍향(16방위)'>, <FeatureType.STEAM_PRESSURE: '현지기압(hPa)'>, <FeatureType.TEMPERATURE: '기온(°C)'>]\"}\n",
      "\n",
      "Namespace(activation='relu', batch_size=64, early_stop=30, end_date='20200809', epochs=256, evaluation='NRMSE', exp_name='solar power prediction using weather features', features=\"[<FeatureType.SUNSHINE: '일조(hr)'>, <FeatureType.HUMIDITY: '습도(%)'>, <FeatureType.WIND_SPEED: '풍속(m/s)'>, <FeatureType.VISIBILITY: '시정(10m)'>, <FeatureType.GROUND_TEMPERATURE: '지면온도(°C)'>, <FeatureType.WIND_DIRECTION: '풍향(16방위)'>, <FeatureType.STEAM_PRESSURE: '현지기압(hPa)'>, <FeatureType.TEMPERATURE: '기온(°C)'>, <FeatureType.PRECIPITATION: '강수량(mm)'>]\", hid_dim=256, lr=0.001, lss='MSE', optim='RMSprop', plant=126, spot=174, start_date='20190820', x_frames=3, y_frames=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/256\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 1316909184.0000 - accuracy: 0.1511 - val_loss: 855054848.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/256\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 1316430720.0000 - accuracy: 0.0000e+00 - val_loss: 854906176.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1316323328.0000 - accuracy: 0.0000e+00 - val_loss: 854844864.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1316266880.0000 - accuracy: 0.0000e+00 - val_loss: 854796672.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/256\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1316219776.0000 - accuracy: 0.0000e+00 - val_loss: 854748864.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1316173184.0000 - accuracy: 0.0000e+00 - val_loss: 854704320.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1316129536.0000 - accuracy: 0.0000e+00 - val_loss: 854663360.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1316088448.0000 - accuracy: 0.0000e+00 - val_loss: 854621632.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1316046336.0000 - accuracy: 0.0000e+00 - val_loss: 854576960.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1316001536.0000 - accuracy: 0.0000e+00 - val_loss: 854531776.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1315957632.0000 - accuracy: 0.0000e+00 - val_loss: 854487808.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315913856.0000 - accuracy: 0.0000e+00 - val_loss: 854443328.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315869696.0000 - accuracy: 0.0000e+00 - val_loss: 854398656.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315825792.0000 - accuracy: 0.0000e+00 - val_loss: 854354304.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315780864.0000 - accuracy: 0.0000e+00 - val_loss: 854312576.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315739904.0000 - accuracy: 0.0000e+00 - val_loss: 854271104.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315698560.0000 - accuracy: 0.0000e+00 - val_loss: 854226240.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315654272.0000 - accuracy: 0.0000e+00 - val_loss: 854186880.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315614720.0000 - accuracy: 0.0000e+00 - val_loss: 854146112.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1315574016.0000 - accuracy: 0.0000e+00 - val_loss: 854103104.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/256\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1315531008.0000 - accuracy: 0.0000e+00 - val_loss: 854058880.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315487360.0000 - accuracy: 0.0000e+00 - val_loss: 854019008.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315446656.0000 - accuracy: 0.0000e+00 - val_loss: 853981056.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315839744.0000 - accuracy: 0.1517 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 25/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1317137152.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 26/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1317137152.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 27/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1317137024.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 28/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1317137152.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 29/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1317137152.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 30/256\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1317137024.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 31/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1317137152.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 32/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1317137280.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 33/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1317137024.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 34/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1317137024.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 35/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1317137152.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 36/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1317137024.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 37/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1317137024.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 38/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1317137152.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 39/256\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1317137024.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 40/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1317137152.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 41/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1317137152.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 42/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1317137152.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 43/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1317137152.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 44/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1317137152.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 45/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1317137152.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 46/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1317137152.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 47/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1317137152.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 48/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1317137152.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 49/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1317137152.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 50/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1317137024.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 51/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1317137152.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1317137152.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 53/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1317137024.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Model: \"model_8\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_9 (InputLayer)            [(None, 72, 9)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_16 (LSTM)                  [(None, 256), (None, 272384      input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_8 (RepeatVector)  (None, 24, 256)      0           lstm_16[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_17 (LSTM)                  [(None, 24, 256), (N 525312      repeat_vector_8[0][0]            \n",
      "                                                                 lstm_16[0][1]                    \n",
      "                                                                 lstm_16[0][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 24, 1)        257         lstm_17[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 797,953\n",
      "Trainable params: 797,953\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Took 6.40 sec for training the model\n",
      "{'train_losses': [1316909184.0, 1316430720.0, 1316323328.0, 1316266880.0, 1316219776.0, 1316173184.0, 1316129536.0, 1316088448.0, 1316046336.0, 1316001536.0, 1315957632.0, 1315913856.0, 1315869696.0, 1315825792.0, 1315780864.0, 1315739904.0, 1315698560.0, 1315654272.0, 1315614720.0, 1315574016.0, 1315531008.0, 1315487360.0, 1315446656.0, 1315839744.0, 1317137152.0, 1317137152.0, 1317137024.0, 1317137152.0, 1317137152.0, 1317137024.0, 1317137152.0, 1317137280.0, 1317137024.0, 1317137024.0, 1317137152.0, 1317137024.0, 1317137024.0, 1317137152.0, 1317137024.0, 1317137152.0, 1317137152.0, 1317137152.0, 1317137152.0, 1317137152.0, 1317137152.0, 1317137152.0, 1317137152.0, 1317137152.0, 1317137152.0, 1317137024.0, 1317137152.0, 1317137152.0, 1317137024.0], 'val_losses': [855054848.0, 854906176.0, 854844864.0, 854796672.0, 854748864.0, 854704320.0, 854663360.0, 854621632.0, 854576960.0, 854531776.0, 854487808.0, 854443328.0, 854398656.0, 854354304.0, 854312576.0, 854271104.0, 854226240.0, 854186880.0, 854146112.0, 854103104.0, 854058880.0, 854019008.0, 853981056.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0], 'train_accs': [0.15110063552856445, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.151729553937912, 0.5380503535270691, 0.5380503535270691, 0.5380503535270691, 0.5380503535270691, 0.5380502939224243, 0.5380503535270691, 0.5380502939224243, 0.5380503535270691, 0.5380502939224243, 0.5380503535270691, 0.5380502939224243, 0.5380503535270691, 0.5380502939224243, 0.5380503535270691, 0.5380503535270691, 0.5380502939224243, 0.5380502939224243, 0.5380502939224243, 0.5380503535270691, 0.5380503535270691, 0.5380503535270691, 0.5380503535270691, 0.5380503535270691, 0.5380503535270691, 0.5380503535270691, 0.5380503535270691, 0.5380503535270691, 0.5380502939224243, 0.5380503535270691], 'val_accs': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024], 'train_acc': 0.30011867745867316, 'val_acc': 0.21844116022002022, 'test_nrmse': 1.0, 'y_test': [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1200.0, 2500.0, 3300.0, 11300.0, 13800.0, 12200.0, 8100.0, 4400.0, 2500.0, 3000.0, 3700.0, 300.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1300.0, 5800.0, 11300.0, 23400.0, 44600.0, 63500.0, 57800.0, 63900.0, 38600.0, 32400.0, 19400.0, 24300.0, 9700.0, 600.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 1100.0, 5000.0, 14500.0, 42800.0, 57800.0, 72500.0, 76200.0, 61500.0, 48100.0, 51700.0, 20400.0, 11100.0, 8400.0, 2000.0, 1100.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 700.0, 9100.0, 13200.0, 20300.0, 28900.0, 26800.0, 40600.0, 52300.0, 36200.0, 29900.0, 41400.0, 30500.0, 19300.0, 8300.0, 700.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2600.0, 4500.0, 6900.0, 6600.0, 17000.0, 16300.0, 32100.0, 22500.0, 14000.0, 9100.0, 5000.0, 4500.0, 400.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 400.0, 2800.0, 5100.0, 11700.0, 21900.0, 14800.0, 12900.0, 24100.0, 18200.0, 13200.0, 15500.0, 10600.0, 4700.0, 2100.0, 700.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 500.0, 7700.0, 18600.0, 14500.0, 22800.0, 34500.0, 23900.0, 46400.0, 25200.0, 20700.0, 19600.0, 28200.0, 14100.0, 6500.0, 1800.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1500.0, 4300.0, 6200.0, 17500.0, 11300.0, 9600.0, 10600.0, 11800.0, 7700.0, 3700.0, 3700.0, 3500.0, 2100.0, 900.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 400.0, 4100.0, 13300.0, 29500.0, 54500.0, 48100.0, 59800.0, 68100.0, 63900.0, 50800.0, 55000.0, 34800.0, 11000.0, 1600.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 400.0, 4600.0, 20100.0, 37100.0, 50200.0, 62400.0, 49300.0, 52100.0, 47400.0, 57700.0, 45600.0, 22000.0, 12600.0, 6500.0, 800.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 400.0, 4700.0, 7700.0, 29200.0, 28200.0, 29100.0, 42000.0, 41400.0, 26800.0, 13400.0, 6500.0, 3400.0, 900.0, 200.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 900.0, 4900.0, 9800.0, 13500.0, 25300.0, 29700.0, 41500.0, 24900.0, 8400.0, 17300.0, 14100.0, 2200.0, 500.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 300.0, 5600.0, 12200.0, 22100.0, 28200.0, 32800.0, 48700.0, 38200.0, 42600.0, 30200.0, 28600.0, 21100.0, 16000.0, 8000.0, 400.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 100.0, 700.0, 1900.0, 4000.0, 5500.0, 2700.0, 4300.0, 4600.0, 4100.0, 3800.0, 1800.0, 1000.0, 1000.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 400.0, 1200.0, 4300.0, 4300.0, 6000.0, 3700.0, 2000.0, 5300.0, 2800.0, 1200.0, 400.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 400.0, 3200.0, 6900.0, 12100.0, 31800.0, 31700.0, 44200.0, 34900.0, 24800.0, 32300.0, 21000.0, 16600.0, 7000.0, 3300.0, 200.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1400.0, 5100.0, 12300.0, 13700.0, 13200.0, 9700.0, 15500.0, 12700.0, 8200.0, 11100.0, 8300.0, 5200.0, 1200.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5200.0, 14100.0, 17500.0, 8400.0, 9800.0, 26200.0, 48100.0, 63700.0, 46200.0, 38200.0, 26100.0, 14000.0, 7200.0, 700.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1500.0, 8100.0, 19000.0, 22500.0, 22100.0, 53000.0, 41900.0, 33200.0, 50300.0, 43700.0, 35100.0, 20800.0, 6100.0, 800.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2000.0, 8200.0, 8100.0, 14400.0, 35800.0, 27800.0, 25000.0, 23000.0, 9000.0, 12300.0, 22200.0, 9800.0, 2200.0, 100.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 700.0, 2000.0, 4800.0, 5800.0, 7500.0, 6200.0, 8800.0, 9800.0, 7300.0, 6000.0, 4100.0, 1300.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 100.0, 600.0, 6400.0, 9800.0, 5400.0, 22000.0, 29800.0, 34600.0, 34400.0, 27500.0, 16100.0, 6300.0, 3500.0, 800.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 400.0, 8400.0, 7500.0, 8500.0, 22200.0, 28400.0, 30500.0, 34800.0, 40100.0, 52300.0, 32100.0, 26000.0, 9800.0, 2100.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1500.0, 5200.0, 6200.0, 8400.0, 10800.0, 10700.0, 10700.0, 12900.0, 14000.0, 10700.0, 14700.0, 7300.0, 3900.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 700.0, 500.0, 4700.0, 3200.0, 2400.0, 2100.0, 2100.0, 3100.0, 2000.0, 1400.0, 2100.0, 400.0, 400.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1200.0, 2100.0, 2600.0, 6900.0, 8100.0, 11100.0, 6500.0, 3000.0, 11400.0, 16600.0, 8100.0, 4700.0, 5000.0, 700.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 100.0, 2300.0, 4300.0, 15000.0, 15100.0, 27600.0, 32000.0, 56800.0, 19500.0, 32900.0, 25600.0, 9600.0, 20500.0, 2500.0, 100.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4200.0, 11100.0, 29600.0, 40300.0, 50900.0, 28700.0, 50700.0, 27300.0, 32500.0, 37200.0, 22900.0, 17800.0, 4000.0, 200.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1400.0, 4600.0, 6900.0, 11400.0, 15900.0, 23200.0, 19200.0, 15300.0, 5200.0, 5200.0, 1100.0, 1200.0, 200.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1700.0, 7700.0, 12500.0, 14000.0, 18700.0, 14500.0, 14300.0, 17900.0, 10400.0, 5900.0, 11400.0, 4200.0, 700.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 100.0, 2500.0, 6000.0, 19200.0, 20500.0, 16900.0, 15900.0, 18400.0, 9800.0, 8100.0, 7400.0, 8500.0, 3600.0, 6900.0, 100.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1700.0, 6000.0, 6400.0, 22200.0, 41100.0, 27600.0, 25900.0, 29600.0, 18500.0, 6900.0, 2500.0, 4000.0, 3900.0, 100.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3600.0, 11800.0, 29000.0, 39600.0, 58800.0, 61400.0, 44100.0, 45200.0, 46000.0, 28000.0, 29900.0, 8200.0, 2700.0, 400.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2600.0, 10400.0, 26400.0, 42400.0, 54500.0, 57900.0, 49900.0, 35700.0, 20600.0, 17300.0, 10700.0, 8500.0, 3900.0, 300.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1400.0, 11900.0, 21100.0, 22900.0, 46500.0, 35400.0, 44000.0, 43200.0, 31300.0, 20700.0, 13300.0, 8500.0, 4100.0, 300.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2100.0, 12700.0, 8700.0, 19600.0, 17900.0, 17800.0, 33400.0, 34900.0, 28400.0, 13700.0, 7700.0, 10900.0, 3000.0, 100.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3200.0, 10600.0, 19700.0, 21300.0, 34300.0, 35200.0, 36900.0, 38900.0, 40000.0, 15700.0, 8400.0, 6900.0, 2800.0, 100.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1500.0, 7600.0, 13000.0, 12000.0, 6000.0, 11000.0, 13900.0, 15300.0, 10200.0, 21100.0, 10200.0, 6100.0, 1300.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 800.0, 900.0, 1000.0, 2000.0, 2400.0, 4400.0, 3200.0, 2000.0, 3300.0, 3000.0, 5700.0, 1000.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 500.0, 2200.0, 1900.0, 3400.0, 4600.0, 5200.0, 3700.0, 3900.0, 400.0, 100.0, 100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 900.0, 6600.0, 100.0, 800.0, 1800.0, 10500.0, 4200.0, 7000.0, 2400.0, 2700.0, 1900.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3100.0, 10400.0, 23800.0, 30300.0, 67400.0, 36400.0, 34800.0, 56300.0, 31600.0, 25100.0, 14500.0, 7700.0, 1300.0, 650.0, 0.0, 0.0, 0.0, 0.0]], 'y_pred': [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]], 'exp_name': 'solar power prediction using weather features', 'plant': 126, 'spot': 174, 'start_date': '20190820', 'end_date': '20200809', 'batch_size': 64, 'x_frames': 3, 'y_frames': 1, 'hid_dim': 256, 'optim': 'RMSprop', 'activation': 'relu', 'lss': 'MSE', 'lr': 0.001, 'epochs': 256, 'early_stop': 30, 'evaluation': 'NRMSE', 'features': \"[<FeatureType.SUNSHINE: '일조(hr)'>, <FeatureType.HUMIDITY: '습도(%)'>, <FeatureType.WIND_SPEED: '풍속(m/s)'>, <FeatureType.VISIBILITY: '시정(10m)'>, <FeatureType.GROUND_TEMPERATURE: '지면온도(°C)'>, <FeatureType.WIND_DIRECTION: '풍향(16방위)'>, <FeatureType.STEAM_PRESSURE: '현지기압(hPa)'>, <FeatureType.TEMPERATURE: '기온(°C)'>, <FeatureType.PRECIPITATION: '강수량(mm)'>]\"}\n",
      "\n",
      "Namespace(activation='relu', batch_size=64, early_stop=30, end_date='20200809', epochs=256, evaluation='NRMSE', exp_name='solar power prediction using weather features', features=\"[<FeatureType.SUNSHINE: '일조(hr)'>, <FeatureType.HUMIDITY: '습도(%)'>, <FeatureType.WIND_SPEED: '풍속(m/s)'>, <FeatureType.VISIBILITY: '시정(10m)'>, <FeatureType.GROUND_TEMPERATURE: '지면온도(°C)'>, <FeatureType.WIND_DIRECTION: '풍향(16방위)'>, <FeatureType.STEAM_PRESSURE: '현지기압(hPa)'>, <FeatureType.TEMPERATURE: '기온(°C)'>, <FeatureType.PRECIPITATION: '강수량(mm)'>, <FeatureType.DEW_POINT_TEMPERATURE: '이슬점온도(°C)'>]\", hid_dim=256, lr=0.001, lss='MSE', optim='RMSprop', plant=126, spot=174, start_date='20190820', x_frames=3, y_frames=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/256\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 1316860416.0000 - accuracy: 0.1341 - val_loss: 854982976.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1316373632.0000 - accuracy: 0.0000e+00 - val_loss: 854868928.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1316287104.0000 - accuracy: 0.0000e+00 - val_loss: 854805760.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1316227328.0000 - accuracy: 0.0000e+00 - val_loss: 854755840.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1316179072.0000 - accuracy: 0.0000e+00 - val_loss: 854707648.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1316132096.0000 - accuracy: 0.0000e+00 - val_loss: 854662464.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1316087552.0000 - accuracy: 0.0000e+00 - val_loss: 854620480.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1316045440.0000 - accuracy: 0.0000e+00 - val_loss: 854578048.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1316002816.0000 - accuracy: 0.0000e+00 - val_loss: 854533184.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/256\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1315958528.0000 - accuracy: 0.0000e+00 - val_loss: 854488960.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315914752.0000 - accuracy: 0.0000e+00 - val_loss: 854444544.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315870720.0000 - accuracy: 0.0000e+00 - val_loss: 854399936.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315826304.0000 - accuracy: 0.0000e+00 - val_loss: 854354624.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315781888.0000 - accuracy: 0.0000e+00 - val_loss: 854310144.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315737984.0000 - accuracy: 0.0000e+00 - val_loss: 854269760.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315697408.0000 - accuracy: 0.0000e+00 - val_loss: 854228288.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315655424.0000 - accuracy: 0.0000e+00 - val_loss: 854182464.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315610624.0000 - accuracy: 0.0000e+00 - val_loss: 854142592.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1315570432.0000 - accuracy: 0.0000e+00 - val_loss: 854101248.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/256\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1315529088.0000 - accuracy: 0.0000e+00 - val_loss: 854057664.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315485696.0000 - accuracy: 0.0000e+00 - val_loss: 854013440.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315443968.0000 - accuracy: 0.0000e+00 - val_loss: 854034240.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315437184.0000 - accuracy: 0.0000e+00 - val_loss: 853926656.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315355776.0000 - accuracy: 0.0000e+00 - val_loss: 853883008.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315312640.0000 - accuracy: 0.0000e+00 - val_loss: 853841536.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315270784.0000 - accuracy: 0.0000e+00 - val_loss: 853795520.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315225216.0000 - accuracy: 0.0000e+00 - val_loss: 853748224.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315179008.0000 - accuracy: 0.0000e+00 - val_loss: 853705088.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1315136128.0000 - accuracy: 0.0000e+00 - val_loss: 853665216.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315095936.0000 - accuracy: 0.0000e+00 - val_loss: 853622208.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315052928.0000 - accuracy: 0.0000e+00 - val_loss: 853579072.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1315010048.0000 - accuracy: 0.0000e+00 - val_loss: 853535616.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314966784.0000 - accuracy: 0.0000e+00 - val_loss: 853492096.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314923264.0000 - accuracy: 0.0000e+00 - val_loss: 853448128.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1314879616.0000 - accuracy: 0.0000e+00 - val_loss: 853406400.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1314837632.0000 - accuracy: 0.0000e+00 - val_loss: 853362176.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314793728.0000 - accuracy: 0.0000e+00 - val_loss: 853315264.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314747648.0000 - accuracy: 0.0000e+00 - val_loss: 853273280.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/256\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1314705536.0000 - accuracy: 0.0000e+00 - val_loss: 853227136.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314659456.0000 - accuracy: 0.0000e+00 - val_loss: 853181952.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314615168.0000 - accuracy: 0.0000e+00 - val_loss: 853139456.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314572288.0000 - accuracy: 0.0000e+00 - val_loss: 853091200.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314525568.0000 - accuracy: 0.0000e+00 - val_loss: 853051776.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314485760.0000 - accuracy: 0.0000e+00 - val_loss: 853007296.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314441344.0000 - accuracy: 0.0000e+00 - val_loss: 852959104.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314394880.0000 - accuracy: 0.0000e+00 - val_loss: 852919040.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314354304.0000 - accuracy: 0.0000e+00 - val_loss: 852876608.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1314312064.0000 - accuracy: 0.0000e+00 - val_loss: 852832448.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314268032.0000 - accuracy: 0.0000e+00 - val_loss: 852792960.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 11ms/step - loss: 1314227968.0000 - accuracy: 0.0000e+00 - val_loss: 852747776.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314183808.0000 - accuracy: 0.0000e+00 - val_loss: 852705856.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314142208.0000 - accuracy: 0.0000e+00 - val_loss: 852662464.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314098432.0000 - accuracy: 0.0000e+00 - val_loss: 852615168.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314052096.0000 - accuracy: 0.0000e+00 - val_loss: 852573248.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1314010112.0000 - accuracy: 0.0000e+00 - val_loss: 852529664.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313966464.0000 - accuracy: 0.0000e+00 - val_loss: 852483904.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313921280.0000 - accuracy: 0.0000e+00 - val_loss: 852440768.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/256\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1313878528.0000 - accuracy: 0.0000e+00 - val_loss: 852398272.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313835904.0000 - accuracy: 0.0000e+00 - val_loss: 852352832.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313791104.0000 - accuracy: 0.0000e+00 - val_loss: 852308736.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313747200.0000 - accuracy: 0.0000e+00 - val_loss: 852266624.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313705344.0000 - accuracy: 0.0000e+00 - val_loss: 852225856.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313664128.0000 - accuracy: 0.0000e+00 - val_loss: 852176768.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313616896.0000 - accuracy: 0.0000e+00 - val_loss: 852137088.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313576960.0000 - accuracy: 0.0000e+00 - val_loss: 852096064.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313535232.0000 - accuracy: 0.0000e+00 - val_loss: 852053888.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1313493760.0000 - accuracy: 1.5723e-04 - val_loss: 852008384.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313448448.0000 - accuracy: 0.0000e+00 - val_loss: 851966848.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313406464.0000 - accuracy: 0.0000e+00 - val_loss: 851919616.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313360256.0000 - accuracy: 0.0000e+00 - val_loss: 851876736.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313317504.0000 - accuracy: 0.0000e+00 - val_loss: 851835456.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313275904.0000 - accuracy: 0.0000e+00 - val_loss: 851790208.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313231104.0000 - accuracy: 0.0000e+00 - val_loss: 851744384.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1313185536.0000 - accuracy: 0.0000e+00 - val_loss: 851698176.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313140224.0000 - accuracy: 0.0000e+00 - val_loss: 851659712.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313101312.0000 - accuracy: 0.0000e+00 - val_loss: 851615040.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/256\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1313056896.0000 - accuracy: 0.0000e+00 - val_loss: 851570304.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1313012864.0000 - accuracy: 0.0000e+00 - val_loss: 851527488.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312970240.0000 - accuracy: 0.0000e+00 - val_loss: 851481344.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312924544.0000 - accuracy: 0.0000e+00 - val_loss: 851439744.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312883200.0000 - accuracy: 0.0000e+00 - val_loss: 851396288.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312840832.0000 - accuracy: 0.0135 - val_loss: 851353024.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312796672.0000 - accuracy: 0.0000e+00 - val_loss: 851309888.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312753792.0000 - accuracy: 3.1447e-04 - val_loss: 851263488.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312708608.0000 - accuracy: 6.2893e-04 - val_loss: 851223104.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1312667392.0000 - accuracy: 0.0014 - val_loss: 851176896.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312622080.0000 - accuracy: 1.5723e-04 - val_loss: 851133568.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312578688.0000 - accuracy: 0.0000e+00 - val_loss: 851089728.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312535424.0000 - accuracy: 0.0000e+00 - val_loss: 851044544.0000 - val_accuracy: 0.0377\n",
      "Epoch 90/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312490752.0000 - accuracy: 0.0030 - val_loss: 851001216.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312447616.0000 - accuracy: 0.0000e+00 - val_loss: 850958848.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312405120.0000 - accuracy: 0.0011 - val_loss: 850915904.0000 - val_accuracy: 0.0079\n",
      "Epoch 93/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312362496.0000 - accuracy: 0.0165 - val_loss: 850872512.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312319104.0000 - accuracy: 0.0024 - val_loss: 850826304.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312273536.0000 - accuracy: 0.0016 - val_loss: 850780928.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1312228736.0000 - accuracy: 0.0000e+00 - val_loss: 850739328.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312186752.0000 - accuracy: 0.0000e+00 - val_loss: 850692992.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312141824.0000 - accuracy: 7.8616e-04 - val_loss: 850650240.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312098688.0000 - accuracy: 3.1447e-04 - val_loss: 850607616.0000 - val_accuracy: 0.0040\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312056192.0000 - accuracy: 0.0066 - val_loss: 850565120.0000 - val_accuracy: 0.0060\n",
      "Epoch 101/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1312013824.0000 - accuracy: 0.0077 - val_loss: 850519296.0000 - val_accuracy: 0.0159\n",
      "Epoch 102/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311968768.0000 - accuracy: 0.0102 - val_loss: 850477376.0000 - val_accuracy: 0.0228\n",
      "Epoch 103/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311926784.0000 - accuracy: 0.0049 - val_loss: 850433728.0000 - val_accuracy: 0.0417\n",
      "Epoch 104/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311883520.0000 - accuracy: 0.0138 - val_loss: 850390848.0000 - val_accuracy: 0.0417\n",
      "Epoch 105/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1311840768.0000 - accuracy: 0.0137 - val_loss: 850351808.0000 - val_accuracy: 0.0615\n",
      "Epoch 106/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311796992.0000 - accuracy: 0.0319 - val_loss: 850304256.0000 - val_accuracy: 0.0258\n",
      "Epoch 107/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311753856.0000 - accuracy: 0.0105 - val_loss: 850255744.0000 - val_accuracy: 0.0417\n",
      "Epoch 108/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311707264.0000 - accuracy: 0.0206 - val_loss: 850215808.0000 - val_accuracy: 0.0565\n",
      "Epoch 109/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311665536.0000 - accuracy: 0.0146 - val_loss: 850171712.0000 - val_accuracy: 0.0516\n",
      "Epoch 110/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311622784.0000 - accuracy: 0.0314 - val_loss: 850129856.0000 - val_accuracy: 0.0387\n",
      "Epoch 111/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311580672.0000 - accuracy: 0.0220 - val_loss: 850087616.0000 - val_accuracy: 0.0486\n",
      "Epoch 112/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311538304.0000 - accuracy: 0.0376 - val_loss: 850041216.0000 - val_accuracy: 0.0595\n",
      "Epoch 113/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311491968.0000 - accuracy: 0.0358 - val_loss: 849998016.0000 - val_accuracy: 0.0298\n",
      "Epoch 114/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311449984.0000 - accuracy: 0.0366 - val_loss: 849956480.0000 - val_accuracy: 0.0278\n",
      "Epoch 115/256\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1311408256.0000 - accuracy: 0.0208 - val_loss: 849912384.0000 - val_accuracy: 0.0387\n",
      "Epoch 116/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311364096.0000 - accuracy: 0.0267 - val_loss: 849868224.0000 - val_accuracy: 0.0546\n",
      "Epoch 117/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311320192.0000 - accuracy: 0.0473 - val_loss: 849825792.0000 - val_accuracy: 0.0446\n",
      "Epoch 118/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311278592.0000 - accuracy: 0.0464 - val_loss: 849781120.0000 - val_accuracy: 0.0437\n",
      "Epoch 119/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311233408.0000 - accuracy: 0.0412 - val_loss: 849734976.0000 - val_accuracy: 0.0546\n",
      "Epoch 120/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311188608.0000 - accuracy: 0.0440 - val_loss: 849693056.0000 - val_accuracy: 0.0565\n",
      "Epoch 121/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311145856.0000 - accuracy: 0.0645 - val_loss: 849648768.0000 - val_accuracy: 0.0387\n",
      "Epoch 122/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1311128704.0000 - accuracy: 0.0428 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 123/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1317137152.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 124/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1317137152.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 125/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1317137152.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 126/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1317137152.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 127/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1317137024.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 128/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1317137152.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 129/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1317137152.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 130/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1317137024.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 131/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1317137152.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 132/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1317137024.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 133/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1317137152.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 134/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1317137152.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 135/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1317137152.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 136/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1317137152.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 137/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1317137152.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 138/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1317137152.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 139/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1317137152.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 140/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1317137024.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 141/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1317137024.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 142/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1317137024.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 143/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1317137152.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 144/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1317137152.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 145/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1317137152.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 146/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1317137280.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 147/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1317137024.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 148/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1317137152.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 149/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1317137152.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 150/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1317137024.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 151/256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 11ms/step - loss: 1317137152.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 152/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1317137152.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Model: \"model_9\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_10 (InputLayer)           [(None, 72, 10)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_18 (LSTM)                  [(None, 256), (None, 273408      input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_9 (RepeatVector)  (None, 24, 256)      0           lstm_18[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_19 (LSTM)                  [(None, 24, 256), (N 525312      repeat_vector_9[0][0]            \n",
      "                                                                 lstm_18[0][1]                    \n",
      "                                                                 lstm_18[0][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 24, 1)        257         lstm_19[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 798,977\n",
      "Trainable params: 798,977\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Took 12.97 sec for training the model\n",
      "{'train_losses': [1316860416.0, 1316373632.0, 1316287104.0, 1316227328.0, 1316179072.0, 1316132096.0, 1316087552.0, 1316045440.0, 1316002816.0, 1315958528.0, 1315914752.0, 1315870720.0, 1315826304.0, 1315781888.0, 1315737984.0, 1315697408.0, 1315655424.0, 1315610624.0, 1315570432.0, 1315529088.0, 1315485696.0, 1315443968.0, 1315437184.0, 1315355776.0, 1315312640.0, 1315270784.0, 1315225216.0, 1315179008.0, 1315136128.0, 1315095936.0, 1315052928.0, 1315010048.0, 1314966784.0, 1314923264.0, 1314879616.0, 1314837632.0, 1314793728.0, 1314747648.0, 1314705536.0, 1314659456.0, 1314615168.0, 1314572288.0, 1314525568.0, 1314485760.0, 1314441344.0, 1314394880.0, 1314354304.0, 1314312064.0, 1314268032.0, 1314227968.0, 1314183808.0, 1314142208.0, 1314098432.0, 1314052096.0, 1314010112.0, 1313966464.0, 1313921280.0, 1313878528.0, 1313835904.0, 1313791104.0, 1313747200.0, 1313705344.0, 1313664128.0, 1313616896.0, 1313576960.0, 1313535232.0, 1313493760.0, 1313448448.0, 1313406464.0, 1313360256.0, 1313317504.0, 1313275904.0, 1313231104.0, 1313185536.0, 1313140224.0, 1313101312.0, 1313056896.0, 1313012864.0, 1312970240.0, 1312924544.0, 1312883200.0, 1312840832.0, 1312796672.0, 1312753792.0, 1312708608.0, 1312667392.0, 1312622080.0, 1312578688.0, 1312535424.0, 1312490752.0, 1312447616.0, 1312405120.0, 1312362496.0, 1312319104.0, 1312273536.0, 1312228736.0, 1312186752.0, 1312141824.0, 1312098688.0, 1312056192.0, 1312013824.0, 1311968768.0, 1311926784.0, 1311883520.0, 1311840768.0, 1311796992.0, 1311753856.0, 1311707264.0, 1311665536.0, 1311622784.0, 1311580672.0, 1311538304.0, 1311491968.0, 1311449984.0, 1311408256.0, 1311364096.0, 1311320192.0, 1311278592.0, 1311233408.0, 1311188608.0, 1311145856.0, 1311128704.0, 1317137152.0, 1317137152.0, 1317137152.0, 1317137152.0, 1317137024.0, 1317137152.0, 1317137152.0, 1317137024.0, 1317137152.0, 1317137024.0, 1317137152.0, 1317137152.0, 1317137152.0, 1317137152.0, 1317137152.0, 1317137152.0, 1317137152.0, 1317137024.0, 1317137024.0, 1317137024.0, 1317137152.0, 1317137152.0, 1317137152.0, 1317137280.0, 1317137024.0, 1317137152.0, 1317137152.0, 1317137024.0, 1317137152.0, 1317137152.0], 'val_losses': [854982976.0, 854868928.0, 854805760.0, 854755840.0, 854707648.0, 854662464.0, 854620480.0, 854578048.0, 854533184.0, 854488960.0, 854444544.0, 854399936.0, 854354624.0, 854310144.0, 854269760.0, 854228288.0, 854182464.0, 854142592.0, 854101248.0, 854057664.0, 854013440.0, 854034240.0, 853926656.0, 853883008.0, 853841536.0, 853795520.0, 853748224.0, 853705088.0, 853665216.0, 853622208.0, 853579072.0, 853535616.0, 853492096.0, 853448128.0, 853406400.0, 853362176.0, 853315264.0, 853273280.0, 853227136.0, 853181952.0, 853139456.0, 853091200.0, 853051776.0, 853007296.0, 852959104.0, 852919040.0, 852876608.0, 852832448.0, 852792960.0, 852747776.0, 852705856.0, 852662464.0, 852615168.0, 852573248.0, 852529664.0, 852483904.0, 852440768.0, 852398272.0, 852352832.0, 852308736.0, 852266624.0, 852225856.0, 852176768.0, 852137088.0, 852096064.0, 852053888.0, 852008384.0, 851966848.0, 851919616.0, 851876736.0, 851835456.0, 851790208.0, 851744384.0, 851698176.0, 851659712.0, 851615040.0, 851570304.0, 851527488.0, 851481344.0, 851439744.0, 851396288.0, 851353024.0, 851309888.0, 851263488.0, 851223104.0, 851176896.0, 851133568.0, 851089728.0, 851044544.0, 851001216.0, 850958848.0, 850915904.0, 850872512.0, 850826304.0, 850780928.0, 850739328.0, 850692992.0, 850650240.0, 850607616.0, 850565120.0, 850519296.0, 850477376.0, 850433728.0, 850390848.0, 850351808.0, 850304256.0, 850255744.0, 850215808.0, 850171712.0, 850129856.0, 850087616.0, 850041216.0, 849998016.0, 849956480.0, 849912384.0, 849868224.0, 849825792.0, 849781120.0, 849734976.0, 849693056.0, 849648768.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0], 'train_accs': [0.13411949574947357, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001572327018948272, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0135220130905509, 0.0, 0.0003144654037896544, 0.0006289308075793087, 0.0014150943607091904, 0.0001572327018948272, 0.0, 0.0, 0.0029874213505536318, 0.0, 0.0011006289860233665, 0.016509436070919037, 0.002358490601181984, 0.0015723271062597632, 0.0, 0.0, 0.0007861635531298816, 0.0003144654037896544, 0.006603773683309555, 0.007704402785748243, 0.010220126248896122, 0.004874213598668575, 0.013836478814482689, 0.013679245486855507, 0.0319182425737381, 0.010534591041505337, 0.020597483962774277, 0.0146226417273283, 0.03144654259085655, 0.022012578323483467, 0.03757862001657486, 0.035849057137966156, 0.036635223776102066, 0.020754719153046608, 0.026729559525847435, 0.04732704907655716, 0.04638364911079407, 0.04119497165083885, 0.044025156646966934, 0.06446541100740433, 0.042767297476530075, 0.5380502939224243, 0.5380502939224243, 0.5380504131317139, 0.5380503535270691, 0.5380502939224243, 0.5380503535270691, 0.5380502939224243, 0.5380502939224243, 0.5380502939224243, 0.5380503535270691, 0.5380502939224243, 0.5380502939224243, 0.5380503535270691, 0.5380503535270691, 0.5380503535270691, 0.5380503535270691, 0.5380502939224243, 0.5380503535270691, 0.5380502939224243, 0.5380503535270691, 0.5380502939224243, 0.5380503535270691, 0.5380503535270691, 0.5380502939224243, 0.5380503535270691, 0.5380503535270691, 0.5380503535270691, 0.5380502939224243, 0.5380502939224243, 0.5380502939224243], 'val_accs': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0376984179019928, 0.0, 0.0, 0.007936508394777775, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003968254197388887, 0.0059523810632526875, 0.01587301678955555, 0.02281746082007885, 0.0416666679084301, 0.0416666679084301, 0.0615079402923584, 0.02579365111887455, 0.0416666679084301, 0.0565476194024086, 0.0515873022377491, 0.0386904776096344, 0.0486111119389534, 0.0595238097012043, 0.02976190485060215, 0.0277777798473835, 0.0386904776096344, 0.0545634925365448, 0.0446428582072258, 0.0436507984995842, 0.0545634925365448, 0.0565476194024086, 0.0386904776096344, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024], 'train_acc': 0.11150798818849389, 'val_acc': 0.0849584938443609, 'test_nrmse': 1.0, 'y_test': [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1200.0, 2500.0, 3300.0, 11300.0, 13800.0, 12200.0, 8100.0, 4400.0, 2500.0, 3000.0, 3700.0, 300.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1300.0, 5800.0, 11300.0, 23400.0, 44600.0, 63500.0, 57800.0, 63900.0, 38600.0, 32400.0, 19400.0, 24300.0, 9700.0, 600.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 1100.0, 5000.0, 14500.0, 42800.0, 57800.0, 72500.0, 76200.0, 61500.0, 48100.0, 51700.0, 20400.0, 11100.0, 8400.0, 2000.0, 1100.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 700.0, 9100.0, 13200.0, 20300.0, 28900.0, 26800.0, 40600.0, 52300.0, 36200.0, 29900.0, 41400.0, 30500.0, 19300.0, 8300.0, 700.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2600.0, 4500.0, 6900.0, 6600.0, 17000.0, 16300.0, 32100.0, 22500.0, 14000.0, 9100.0, 5000.0, 4500.0, 400.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 400.0, 2800.0, 5100.0, 11700.0, 21900.0, 14800.0, 12900.0, 24100.0, 18200.0, 13200.0, 15500.0, 10600.0, 4700.0, 2100.0, 700.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 500.0, 7700.0, 18600.0, 14500.0, 22800.0, 34500.0, 23900.0, 46400.0, 25200.0, 20700.0, 19600.0, 28200.0, 14100.0, 6500.0, 1800.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1500.0, 4300.0, 6200.0, 17500.0, 11300.0, 9600.0, 10600.0, 11800.0, 7700.0, 3700.0, 3700.0, 3500.0, 2100.0, 900.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 400.0, 4100.0, 13300.0, 29500.0, 54500.0, 48100.0, 59800.0, 68100.0, 63900.0, 50800.0, 55000.0, 34800.0, 11000.0, 1600.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 400.0, 4600.0, 20100.0, 37100.0, 50200.0, 62400.0, 49300.0, 52100.0, 47400.0, 57700.0, 45600.0, 22000.0, 12600.0, 6500.0, 800.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 400.0, 4700.0, 7700.0, 29200.0, 28200.0, 29100.0, 42000.0, 41400.0, 26800.0, 13400.0, 6500.0, 3400.0, 900.0, 200.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 900.0, 4900.0, 9800.0, 13500.0, 25300.0, 29700.0, 41500.0, 24900.0, 8400.0, 17300.0, 14100.0, 2200.0, 500.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 300.0, 5600.0, 12200.0, 22100.0, 28200.0, 32800.0, 48700.0, 38200.0, 42600.0, 30200.0, 28600.0, 21100.0, 16000.0, 8000.0, 400.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 100.0, 700.0, 1900.0, 4000.0, 5500.0, 2700.0, 4300.0, 4600.0, 4100.0, 3800.0, 1800.0, 1000.0, 1000.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 400.0, 1200.0, 4300.0, 4300.0, 6000.0, 3700.0, 2000.0, 5300.0, 2800.0, 1200.0, 400.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 400.0, 3200.0, 6900.0, 12100.0, 31800.0, 31700.0, 44200.0, 34900.0, 24800.0, 32300.0, 21000.0, 16600.0, 7000.0, 3300.0, 200.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1400.0, 5100.0, 12300.0, 13700.0, 13200.0, 9700.0, 15500.0, 12700.0, 8200.0, 11100.0, 8300.0, 5200.0, 1200.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5200.0, 14100.0, 17500.0, 8400.0, 9800.0, 26200.0, 48100.0, 63700.0, 46200.0, 38200.0, 26100.0, 14000.0, 7200.0, 700.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1500.0, 8100.0, 19000.0, 22500.0, 22100.0, 53000.0, 41900.0, 33200.0, 50300.0, 43700.0, 35100.0, 20800.0, 6100.0, 800.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2000.0, 8200.0, 8100.0, 14400.0, 35800.0, 27800.0, 25000.0, 23000.0, 9000.0, 12300.0, 22200.0, 9800.0, 2200.0, 100.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 700.0, 2000.0, 4800.0, 5800.0, 7500.0, 6200.0, 8800.0, 9800.0, 7300.0, 6000.0, 4100.0, 1300.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 100.0, 600.0, 6400.0, 9800.0, 5400.0, 22000.0, 29800.0, 34600.0, 34400.0, 27500.0, 16100.0, 6300.0, 3500.0, 800.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 400.0, 8400.0, 7500.0, 8500.0, 22200.0, 28400.0, 30500.0, 34800.0, 40100.0, 52300.0, 32100.0, 26000.0, 9800.0, 2100.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1500.0, 5200.0, 6200.0, 8400.0, 10800.0, 10700.0, 10700.0, 12900.0, 14000.0, 10700.0, 14700.0, 7300.0, 3900.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 700.0, 500.0, 4700.0, 3200.0, 2400.0, 2100.0, 2100.0, 3100.0, 2000.0, 1400.0, 2100.0, 400.0, 400.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1200.0, 2100.0, 2600.0, 6900.0, 8100.0, 11100.0, 6500.0, 3000.0, 11400.0, 16600.0, 8100.0, 4700.0, 5000.0, 700.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 100.0, 2300.0, 4300.0, 15000.0, 15100.0, 27600.0, 32000.0, 56800.0, 19500.0, 32900.0, 25600.0, 9600.0, 20500.0, 2500.0, 100.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4200.0, 11100.0, 29600.0, 40300.0, 50900.0, 28700.0, 50700.0, 27300.0, 32500.0, 37200.0, 22900.0, 17800.0, 4000.0, 200.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1400.0, 4600.0, 6900.0, 11400.0, 15900.0, 23200.0, 19200.0, 15300.0, 5200.0, 5200.0, 1100.0, 1200.0, 200.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1700.0, 7700.0, 12500.0, 14000.0, 18700.0, 14500.0, 14300.0, 17900.0, 10400.0, 5900.0, 11400.0, 4200.0, 700.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 100.0, 2500.0, 6000.0, 19200.0, 20500.0, 16900.0, 15900.0, 18400.0, 9800.0, 8100.0, 7400.0, 8500.0, 3600.0, 6900.0, 100.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1700.0, 6000.0, 6400.0, 22200.0, 41100.0, 27600.0, 25900.0, 29600.0, 18500.0, 6900.0, 2500.0, 4000.0, 3900.0, 100.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3600.0, 11800.0, 29000.0, 39600.0, 58800.0, 61400.0, 44100.0, 45200.0, 46000.0, 28000.0, 29900.0, 8200.0, 2700.0, 400.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2600.0, 10400.0, 26400.0, 42400.0, 54500.0, 57900.0, 49900.0, 35700.0, 20600.0, 17300.0, 10700.0, 8500.0, 3900.0, 300.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1400.0, 11900.0, 21100.0, 22900.0, 46500.0, 35400.0, 44000.0, 43200.0, 31300.0, 20700.0, 13300.0, 8500.0, 4100.0, 300.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2100.0, 12700.0, 8700.0, 19600.0, 17900.0, 17800.0, 33400.0, 34900.0, 28400.0, 13700.0, 7700.0, 10900.0, 3000.0, 100.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3200.0, 10600.0, 19700.0, 21300.0, 34300.0, 35200.0, 36900.0, 38900.0, 40000.0, 15700.0, 8400.0, 6900.0, 2800.0, 100.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1500.0, 7600.0, 13000.0, 12000.0, 6000.0, 11000.0, 13900.0, 15300.0, 10200.0, 21100.0, 10200.0, 6100.0, 1300.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 800.0, 900.0, 1000.0, 2000.0, 2400.0, 4400.0, 3200.0, 2000.0, 3300.0, 3000.0, 5700.0, 1000.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 500.0, 2200.0, 1900.0, 3400.0, 4600.0, 5200.0, 3700.0, 3900.0, 400.0, 100.0, 100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 900.0, 6600.0, 100.0, 800.0, 1800.0, 10500.0, 4200.0, 7000.0, 2400.0, 2700.0, 1900.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3100.0, 10400.0, 23800.0, 30300.0, 67400.0, 36400.0, 34800.0, 56300.0, 31600.0, 25100.0, 14500.0, 7700.0, 1300.0, 650.0, 0.0, 0.0, 0.0, 0.0]], 'y_pred': [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]], 'exp_name': 'solar power prediction using weather features', 'plant': 126, 'spot': 174, 'start_date': '20190820', 'end_date': '20200809', 'batch_size': 64, 'x_frames': 3, 'y_frames': 1, 'hid_dim': 256, 'optim': 'RMSprop', 'activation': 'relu', 'lss': 'MSE', 'lr': 0.001, 'epochs': 256, 'early_stop': 30, 'evaluation': 'NRMSE', 'features': \"[<FeatureType.SUNSHINE: '일조(hr)'>, <FeatureType.HUMIDITY: '습도(%)'>, <FeatureType.WIND_SPEED: '풍속(m/s)'>, <FeatureType.VISIBILITY: '시정(10m)'>, <FeatureType.GROUND_TEMPERATURE: '지면온도(°C)'>, <FeatureType.WIND_DIRECTION: '풍향(16방위)'>, <FeatureType.STEAM_PRESSURE: '현지기압(hPa)'>, <FeatureType.TEMPERATURE: '기온(°C)'>, <FeatureType.PRECIPITATION: '강수량(mm)'>, <FeatureType.DEW_POINT_TEMPERATURE: '이슬점온도(°C)'>]\"}\n",
      "\n",
      "Namespace(activation='relu', batch_size=64, early_stop=30, end_date='20200809', epochs=256, evaluation='NRMSE', exp_name='solar power prediction using weather features', features=\"[<FeatureType.SUNSHINE: '일조(hr)'>, <FeatureType.HUMIDITY: '습도(%)'>, <FeatureType.WIND_SPEED: '풍속(m/s)'>, <FeatureType.VISIBILITY: '시정(10m)'>, <FeatureType.GROUND_TEMPERATURE: '지면온도(°C)'>, <FeatureType.WIND_DIRECTION: '풍향(16방위)'>, <FeatureType.STEAM_PRESSURE: '현지기압(hPa)'>, <FeatureType.TEMPERATURE: '기온(°C)'>, <FeatureType.PRECIPITATION: '강수량(mm)'>, <FeatureType.DEW_POINT_TEMPERATURE: '이슬점온도(°C)'>, <FeatureType.ATMOSPHERIC_PRESSURE: '증기압(hPa)'>]\", hid_dim=256, lr=0.001, lss='MSE', optim='RMSprop', plant=126, spot=174, start_date='20190820', x_frames=3, y_frames=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/256\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 1317137152.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 2/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1317137152.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 3/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1317137152.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 4/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1317137152.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 5/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1317137024.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 6/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1317137152.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 7/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1317137152.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 8/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1317137152.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 9/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1317137024.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 10/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1317137024.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 11/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1317137152.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 12/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1317137024.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 13/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1317137152.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 14/256\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1317137152.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 15/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1317137152.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 16/256\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1317137152.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 17/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1317137152.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 18/256\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1317137152.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 19/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1317137152.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 20/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1317137152.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 21/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1317137280.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 22/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1317137152.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 23/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1317137152.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 24/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1317137152.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 25/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1317137152.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 26/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1317137152.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 27/256\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1317137024.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 28/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1317137152.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 29/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1317137152.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 30/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1317137024.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 31/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1317137152.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 32/256\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1317137280.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 33/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1317137024.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 34/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1317137024.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Epoch 35/256\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1317137152.0000 - accuracy: 0.5381 - val_loss: 855704256.0000 - val_accuracy: 0.3859\n",
      "Model: \"model_10\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_11 (InputLayer)           [(None, 72, 11)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_20 (LSTM)                  [(None, 256), (None, 274432      input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_10 (RepeatVector) (None, 24, 256)      0           lstm_20[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_21 (LSTM)                  [(None, 24, 256), (N 525312      repeat_vector_10[0][0]           \n",
      "                                                                 lstm_20[0][1]                    \n",
      "                                                                 lstm_20[0][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 24, 1)        257         lstm_21[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 800,001\n",
      "Trainable params: 800,001\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Took 5.43 sec for training the model\n",
      "{'train_losses': [1317137152.0, 1317137152.0, 1317137152.0, 1317137152.0, 1317137024.0, 1317137152.0, 1317137152.0, 1317137152.0, 1317137024.0, 1317137024.0, 1317137152.0, 1317137024.0, 1317137152.0, 1317137152.0, 1317137152.0, 1317137152.0, 1317137152.0, 1317137152.0, 1317137152.0, 1317137152.0, 1317137280.0, 1317137152.0, 1317137152.0, 1317137152.0, 1317137152.0, 1317137152.0, 1317137024.0, 1317137152.0, 1317137152.0, 1317137024.0, 1317137152.0, 1317137280.0, 1317137024.0, 1317137024.0, 1317137152.0], 'val_losses': [855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0, 855704256.0], 'train_accs': [0.5380503535270691, 0.5380503535270691, 0.5380503535270691, 0.5380503535270691, 0.5380502939224243, 0.5380502939224243, 0.5380503535270691, 0.5380503535270691, 0.5380503535270691, 0.5380504131317139, 0.5380502939224243, 0.5380503535270691, 0.5380503535270691, 0.5380503535270691, 0.5380503535270691, 0.5380503535270691, 0.5380502939224243, 0.5380503535270691, 0.5380503535270691, 0.5380503535270691, 0.5380502939224243, 0.5380502939224243, 0.5380502939224243, 0.5380502939224243, 0.5380503535270691, 0.5380503535270691, 0.5380503535270691, 0.5380503535270691, 0.5380502939224243, 0.5380503535270691, 0.5380502939224243, 0.5380503535270691, 0.5380502939224243, 0.5380503535270691, 0.5380502939224243], 'val_accs': [0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024, 0.3859127163887024], 'train_acc': 0.5380503347941807, 'val_acc': 0.3859127163887024, 'test_nrmse': 1.0, 'y_test': [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1200.0, 2500.0, 3300.0, 11300.0, 13800.0, 12200.0, 8100.0, 4400.0, 2500.0, 3000.0, 3700.0, 300.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1300.0, 5800.0, 11300.0, 23400.0, 44600.0, 63500.0, 57800.0, 63900.0, 38600.0, 32400.0, 19400.0, 24300.0, 9700.0, 600.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 1100.0, 5000.0, 14500.0, 42800.0, 57800.0, 72500.0, 76200.0, 61500.0, 48100.0, 51700.0, 20400.0, 11100.0, 8400.0, 2000.0, 1100.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 700.0, 9100.0, 13200.0, 20300.0, 28900.0, 26800.0, 40600.0, 52300.0, 36200.0, 29900.0, 41400.0, 30500.0, 19300.0, 8300.0, 700.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2600.0, 4500.0, 6900.0, 6600.0, 17000.0, 16300.0, 32100.0, 22500.0, 14000.0, 9100.0, 5000.0, 4500.0, 400.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 400.0, 2800.0, 5100.0, 11700.0, 21900.0, 14800.0, 12900.0, 24100.0, 18200.0, 13200.0, 15500.0, 10600.0, 4700.0, 2100.0, 700.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 500.0, 7700.0, 18600.0, 14500.0, 22800.0, 34500.0, 23900.0, 46400.0, 25200.0, 20700.0, 19600.0, 28200.0, 14100.0, 6500.0, 1800.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1500.0, 4300.0, 6200.0, 17500.0, 11300.0, 9600.0, 10600.0, 11800.0, 7700.0, 3700.0, 3700.0, 3500.0, 2100.0, 900.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 400.0, 4100.0, 13300.0, 29500.0, 54500.0, 48100.0, 59800.0, 68100.0, 63900.0, 50800.0, 55000.0, 34800.0, 11000.0, 1600.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 400.0, 4600.0, 20100.0, 37100.0, 50200.0, 62400.0, 49300.0, 52100.0, 47400.0, 57700.0, 45600.0, 22000.0, 12600.0, 6500.0, 800.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 400.0, 4700.0, 7700.0, 29200.0, 28200.0, 29100.0, 42000.0, 41400.0, 26800.0, 13400.0, 6500.0, 3400.0, 900.0, 200.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 900.0, 4900.0, 9800.0, 13500.0, 25300.0, 29700.0, 41500.0, 24900.0, 8400.0, 17300.0, 14100.0, 2200.0, 500.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 300.0, 5600.0, 12200.0, 22100.0, 28200.0, 32800.0, 48700.0, 38200.0, 42600.0, 30200.0, 28600.0, 21100.0, 16000.0, 8000.0, 400.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 100.0, 700.0, 1900.0, 4000.0, 5500.0, 2700.0, 4300.0, 4600.0, 4100.0, 3800.0, 1800.0, 1000.0, 1000.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 400.0, 1200.0, 4300.0, 4300.0, 6000.0, 3700.0, 2000.0, 5300.0, 2800.0, 1200.0, 400.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 400.0, 3200.0, 6900.0, 12100.0, 31800.0, 31700.0, 44200.0, 34900.0, 24800.0, 32300.0, 21000.0, 16600.0, 7000.0, 3300.0, 200.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1400.0, 5100.0, 12300.0, 13700.0, 13200.0, 9700.0, 15500.0, 12700.0, 8200.0, 11100.0, 8300.0, 5200.0, 1200.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5200.0, 14100.0, 17500.0, 8400.0, 9800.0, 26200.0, 48100.0, 63700.0, 46200.0, 38200.0, 26100.0, 14000.0, 7200.0, 700.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1500.0, 8100.0, 19000.0, 22500.0, 22100.0, 53000.0, 41900.0, 33200.0, 50300.0, 43700.0, 35100.0, 20800.0, 6100.0, 800.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2000.0, 8200.0, 8100.0, 14400.0, 35800.0, 27800.0, 25000.0, 23000.0, 9000.0, 12300.0, 22200.0, 9800.0, 2200.0, 100.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 700.0, 2000.0, 4800.0, 5800.0, 7500.0, 6200.0, 8800.0, 9800.0, 7300.0, 6000.0, 4100.0, 1300.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 100.0, 600.0, 6400.0, 9800.0, 5400.0, 22000.0, 29800.0, 34600.0, 34400.0, 27500.0, 16100.0, 6300.0, 3500.0, 800.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 400.0, 8400.0, 7500.0, 8500.0, 22200.0, 28400.0, 30500.0, 34800.0, 40100.0, 52300.0, 32100.0, 26000.0, 9800.0, 2100.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1500.0, 5200.0, 6200.0, 8400.0, 10800.0, 10700.0, 10700.0, 12900.0, 14000.0, 10700.0, 14700.0, 7300.0, 3900.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 700.0, 500.0, 4700.0, 3200.0, 2400.0, 2100.0, 2100.0, 3100.0, 2000.0, 1400.0, 2100.0, 400.0, 400.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1200.0, 2100.0, 2600.0, 6900.0, 8100.0, 11100.0, 6500.0, 3000.0, 11400.0, 16600.0, 8100.0, 4700.0, 5000.0, 700.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 100.0, 2300.0, 4300.0, 15000.0, 15100.0, 27600.0, 32000.0, 56800.0, 19500.0, 32900.0, 25600.0, 9600.0, 20500.0, 2500.0, 100.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4200.0, 11100.0, 29600.0, 40300.0, 50900.0, 28700.0, 50700.0, 27300.0, 32500.0, 37200.0, 22900.0, 17800.0, 4000.0, 200.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1400.0, 4600.0, 6900.0, 11400.0, 15900.0, 23200.0, 19200.0, 15300.0, 5200.0, 5200.0, 1100.0, 1200.0, 200.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1700.0, 7700.0, 12500.0, 14000.0, 18700.0, 14500.0, 14300.0, 17900.0, 10400.0, 5900.0, 11400.0, 4200.0, 700.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 100.0, 2500.0, 6000.0, 19200.0, 20500.0, 16900.0, 15900.0, 18400.0, 9800.0, 8100.0, 7400.0, 8500.0, 3600.0, 6900.0, 100.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1700.0, 6000.0, 6400.0, 22200.0, 41100.0, 27600.0, 25900.0, 29600.0, 18500.0, 6900.0, 2500.0, 4000.0, 3900.0, 100.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3600.0, 11800.0, 29000.0, 39600.0, 58800.0, 61400.0, 44100.0, 45200.0, 46000.0, 28000.0, 29900.0, 8200.0, 2700.0, 400.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2600.0, 10400.0, 26400.0, 42400.0, 54500.0, 57900.0, 49900.0, 35700.0, 20600.0, 17300.0, 10700.0, 8500.0, 3900.0, 300.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1400.0, 11900.0, 21100.0, 22900.0, 46500.0, 35400.0, 44000.0, 43200.0, 31300.0, 20700.0, 13300.0, 8500.0, 4100.0, 300.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2100.0, 12700.0, 8700.0, 19600.0, 17900.0, 17800.0, 33400.0, 34900.0, 28400.0, 13700.0, 7700.0, 10900.0, 3000.0, 100.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3200.0, 10600.0, 19700.0, 21300.0, 34300.0, 35200.0, 36900.0, 38900.0, 40000.0, 15700.0, 8400.0, 6900.0, 2800.0, 100.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1500.0, 7600.0, 13000.0, 12000.0, 6000.0, 11000.0, 13900.0, 15300.0, 10200.0, 21100.0, 10200.0, 6100.0, 1300.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 800.0, 900.0, 1000.0, 2000.0, 2400.0, 4400.0, 3200.0, 2000.0, 3300.0, 3000.0, 5700.0, 1000.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 500.0, 2200.0, 1900.0, 3400.0, 4600.0, 5200.0, 3700.0, 3900.0, 400.0, 100.0, 100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 900.0, 6600.0, 100.0, 800.0, 1800.0, 10500.0, 4200.0, 7000.0, 2400.0, 2700.0, 1900.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3100.0, 10400.0, 23800.0, 30300.0, 67400.0, 36400.0, 34800.0, 56300.0, 31600.0, 25100.0, 14500.0, 7700.0, 1300.0, 650.0, 0.0, 0.0, 0.0, 0.0]], 'y_pred': [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]], 'exp_name': 'solar power prediction using weather features', 'plant': 126, 'spot': 174, 'start_date': '20190820', 'end_date': '20200809', 'batch_size': 64, 'x_frames': 3, 'y_frames': 1, 'hid_dim': 256, 'optim': 'RMSprop', 'activation': 'relu', 'lss': 'MSE', 'lr': 0.001, 'epochs': 256, 'early_stop': 30, 'evaluation': 'NRMSE', 'features': \"[<FeatureType.SUNSHINE: '일조(hr)'>, <FeatureType.HUMIDITY: '습도(%)'>, <FeatureType.WIND_SPEED: '풍속(m/s)'>, <FeatureType.VISIBILITY: '시정(10m)'>, <FeatureType.GROUND_TEMPERATURE: '지면온도(°C)'>, <FeatureType.WIND_DIRECTION: '풍향(16방위)'>, <FeatureType.STEAM_PRESSURE: '현지기압(hPa)'>, <FeatureType.TEMPERATURE: '기온(°C)'>, <FeatureType.PRECIPITATION: '강수량(mm)'>, <FeatureType.DEW_POINT_TEMPERATURE: '이슬점온도(°C)'>, <FeatureType.ATMOSPHERIC_PRESSURE: '증기압(hPa)'>]\"}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ====== Random Seed Initialization ====== #\n",
    "seed = 1234\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "args = parser.parse_args(\"\")\n",
    "args.exp_name = \"solar power prediction using weather features\"\n",
    "\n",
    "# ====== Data Loading ====== #\n",
    "args.plant = 126\n",
    "args.spot = 174\n",
    "args.start_date = \"20190820\"\n",
    "args.end_date = \"20200809\"\n",
    "args.batch_size = 64\n",
    "args.x_frames = 3\n",
    "args.y_frames = 1\n",
    "\n",
    "# ====== Model Capacity ===== #\n",
    "args.hid_dim = 256\n",
    "\n",
    "# ====== Optimizer & Training ====== #\n",
    "args.optim = 'RMSprop'\n",
    "args.activation = 'relu'\n",
    "args.lss = 'MSE'\n",
    "args.lr = 0.001\n",
    "args.epochs = 256\n",
    "args.early_stop = 30\n",
    "args.evaluation = 'NRMSE'\n",
    "\n",
    "# ====== Experiment Variable ====== #\n",
    "name_var1 = 'features'\n",
    "list_var1 = [FeatureType.SUNSHINE,\n",
    "                 FeatureType.HUMIDITY,\n",
    "                 FeatureType.WIND_SPEED,\n",
    "                 FeatureType.VISIBILITY,\n",
    "                 FeatureType.GROUND_TEMPERATURE,\n",
    "                 FeatureType.WIND_DIRECTION,\n",
    "                 FeatureType.STEAM_PRESSURE,\n",
    "                 FeatureType.TEMPERATURE,\n",
    "                 FeatureType.PRECIPITATION,\n",
    "                 FeatureType.DEW_POINT_TEMPERATURE,\n",
    "                 FeatureType.ATMOSPHERIC_PRESSURE]\n",
    "\n",
    "for i in range(len(list_var1)):\n",
    "    sub_list = list_var1[:i + 1]\n",
    "\n",
    "    setattr(args, name_var1, str(sub_list))\n",
    "    print(args)\n",
    "\n",
    "    setattr(args, name_var1, sub_list)   \n",
    "    setting, model, result = experiment(deepcopy(args))\n",
    "    save_exp_model(setting, model)\n",
    "    save_exp_result(setting, result)\n",
    "    print(result)\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
